[
    {
        "text": "I'm getting feedback about the state of the game using basic OCR now. Unfortunately the OCR that I'm using is optimized towards \"natural\" text - so it doesn't handle game UIs too well.",
        "files": [
            {
                "id": "F08J09FVAG7",
                "mode": "hidden_by_limit"
            }
        ],
        "upload": false,
        "user": "U06SS0DHZD1",
        "display_as_bot": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "vFK1a",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm getting feedback about the state of the game using basic OCR now. Unfortunately the OCR that I'm using is optimized towards \"natural\" text - so it doesn't handle game UIs too well."
                            }
                        ]
                    }
                ]
            }
        ],
        "type": "message",
        "ts": "1742398334.625809",
        "edited": {
            "user": "U06SS0DHZD1",
            "ts": "1742398364.000000"
        },
        "client_msg_id": "0b3fcebc-74d9-4ccd-9131-2f17984244eb",
        "thread_ts": "1742398334.625809",
        "reply_count": 8,
        "reply_users_count": 2,
        "latest_reply": "1742401788.646259",
        "reply_users": [
            "U02E4DAQGSZ",
            "U06SS0DHZD1"
        ],
        "replies": [
            {
                "user": "U02E4DAQGSZ",
                "ts": "1742400687.619789"
            },
            {
                "user": "U06SS0DHZD1",
                "ts": "1742400831.410039"
            },
            {
                "user": "U02E4DAQGSZ",
                "ts": "1742401087.519379"
            },
            {
                "user": "U02E4DAQGSZ",
                "ts": "1742401204.388589"
            },
            {
                "user": "U06SS0DHZD1",
                "ts": "1742401376.956429"
            },
            {
                "user": "U02E4DAQGSZ",
                "ts": "1742401537.891599"
            },
            {
                "user": "U06SS0DHZD1",
                "ts": "1742401546.813869"
            },
            {
                "user": "U02E4DAQGSZ",
                "ts": "1742401788.646259"
            }
        ],
        "is_locked": false,
        "subscribed": false
    },
    {
        "user": "U02E4DAQGSZ",
        "type": "message",
        "ts": "1742400687.619789",
        "client_msg_id": "803afca9-f5ea-45fd-b7b4-dbf2382abaf3",
        "text": "the deep learning models are now state of the art for OCR imho. they can do natural scenes as well",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "27dffd0e73bd",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-09-13\/2483463922595_27dffd0e73bd6f709927_72.gif",
            "first_name": "Tom",
            "real_name": "Tom Larkworthy",
            "display_name": "Tom Larkworthy",
            "team": "T5TCAFTA9",
            "name": "tom.larkworthy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1742398334.625809",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Gteh3",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "the deep learning models are now state of the art for OCR imho. they can do natural scenes as well"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U06SS0DHZD1",
        "type": "message",
        "ts": "1742400831.410039",
        "client_msg_id": "6fa0bc44-941d-4cf5-93da-ab75d517c228",
        "text": "I've spent some time digging through huggingface but the OCR models I've found tended to be 1GB+\n\nThe also have a ton of \"image-to-text\" models but unfortunately it's not the same as \"OCR\".\n\nI kind of wish there was a \"ocr.cpp\" repo somewhere - just like \"llama.cpp\" or \"whisper.cpp\"...",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "287ba5559ee1",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-04-04\/6922823105585_287ba5559ee1cedd6b98_72.png",
            "first_name": "Marek",
            "real_name": "Marek Rogalski",
            "display_name": "maf",
            "team": "T5TCAFTA9",
            "name": "mafikpl",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1742398334.625809",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "EWgXk",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I've spent some time digging through huggingface but the OCR models I've found tended to be 1GB+\n\nThe also have a ton of \"image-to-text\" models but unfortunately it's not the same as \"OCR\".\n\nI kind of wish there was a \"ocr.cpp\" repo somewhere - just like \"llama.cpp\" or \"whisper.cpp\"..."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U02E4DAQGSZ",
        "type": "message",
        "ts": "1742401087.519379",
        "client_msg_id": "864446b6-4e9a-4286-86d1-715bd97abaca",
        "text": "yeah I would be looking for multi-modal LLM, but definitely they are gonna be massive for local use so that would be a good reason to use classical OCR.\nThat said, Skyrim 5.6 GB so gamers are quite tolerant of large downloads.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "27dffd0e73bd",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-09-13\/2483463922595_27dffd0e73bd6f709927_72.gif",
            "first_name": "Tom",
            "real_name": "Tom Larkworthy",
            "display_name": "Tom Larkworthy",
            "team": "T5TCAFTA9",
            "name": "tom.larkworthy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1742398334.625809",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6rGO\/",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "yeah I would be looking for multi-modal LLM, but definitely they are gonna be massive for local use so that would be a good reason to use classical OCR.\nThat said, Skyrim 5.6 GB so gamers are quite tolerant of large downloads."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U02E4DAQGSZ",
        "type": "message",
        "ts": "1742401204.388589",
        "edited": {
            "user": "U02E4DAQGSZ",
            "ts": "1742401220.000000"
        },
        "client_msg_id": "42feca27-49dd-43e1-ae6c-d7269fdad357",
        "text": "\"Here's an example of how to run llama.cpp's built-in HTTP server. This example uses LLaVA v1.5-7B, a *multimodal* LLM that works with llama.cpp's recently-added support for image inputs.\" so its seems like multi modal is supported by llama.cpp now (says <https:\/\/github.com\/Mozilla-Ocho\/llamafile|llamafile's> README)",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "27dffd0e73bd",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-09-13\/2483463922595_27dffd0e73bd6f709927_72.gif",
            "first_name": "Tom",
            "real_name": "Tom Larkworthy",
            "display_name": "Tom Larkworthy",
            "team": "T5TCAFTA9",
            "name": "tom.larkworthy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1742398334.625809",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "vRFyH",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\"Here's an example of how to run llama.cpp's built-in HTTP server. This example uses LLaVA v1.5-7B, a "
                            },
                            {
                                "type": "text",
                                "text": "multimodal",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " LLM that works with llama.cpp's recently-added support for image inputs.\" so its seems like multi modal is supported by llama.cpp now (says "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/Mozilla-Ocho\/llamafile",
                                "text": "llamafile's"
                            },
                            {
                                "type": "text",
                                "text": " README)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U06SS0DHZD1",
        "type": "message",
        "ts": "1742401376.956429",
        "client_msg_id": "77877f52-20ac-4e29-a881-3652c67c0894",
        "text": "Desktop capture + Multimodal LLMs + Fake input sounds like a match made in heaven",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "287ba5559ee1",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-04-04\/6922823105585_287ba5559ee1cedd6b98_72.png",
            "first_name": "Marek",
            "real_name": "Marek Rogalski",
            "display_name": "maf",
            "team": "T5TCAFTA9",
            "name": "mafikpl",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1742398334.625809",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "VSaHT",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Desktop capture + Multimodal LLMs + Fake input sounds like a match made in heaven"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U02E4DAQGSZ",
        "type": "message",
        "ts": "1742401537.891599",
        "client_msg_id": "1ee32687-734f-472e-9870-e619d74bf9b4",
        "text": "I know one local doing something in this area  <https:\/\/github.com\/e2b-dev\/desktop>",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "27dffd0e73bd",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-09-13\/2483463922595_27dffd0e73bd6f709927_72.gif",
            "first_name": "Tom",
            "real_name": "Tom Larkworthy",
            "display_name": "Tom Larkworthy",
            "team": "T5TCAFTA9",
            "name": "tom.larkworthy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1742398334.625809",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4UwvT",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I know one local doing something in this area  "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/e2b-dev\/desktop"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U06SS0DHZD1",
        "type": "message",
        "ts": "1742401546.813869",
        "client_msg_id": "bd5ef4ee-c50c-4583-a7c9-f6586160b4ff",
        "text": "BTW Tesseract OCR that I'm using clearly hasn't been updated in quite a long time. It's docs praise the new LSTM-based engine. I wonder how a modern convnet hierarchy + attention architecture would work...",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "287ba5559ee1",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-04-04\/6922823105585_287ba5559ee1cedd6b98_72.png",
            "first_name": "Marek",
            "real_name": "Marek Rogalski",
            "display_name": "maf",
            "team": "T5TCAFTA9",
            "name": "mafikpl",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1742398334.625809",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WIKog",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "BTW Tesseract OCR that I'm using clearly hasn't been updated in quite a long time. It's docs praise the new LSTM-based engine. I wonder how a modern convnet hierarchy + attention architecture would work..."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "laughing",
                "users": [
                    "U02E4DAQGSZ"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U02E4DAQGSZ",
        "type": "message",
        "ts": "1742401788.646259",
        "edited": {
            "user": "U02E4DAQGSZ",
            "ts": "1742401809.000000"
        },
        "client_msg_id": "df77507b-fc06-4451-80ce-9d6bc2590a52",
        "text": "At work we switched out document OCR from classical to LLM and got better results. docs are literally the ideal use case for classical OCR but still LLMs seem to outperform coz they \"get\" the task and the words. For your use case the OCR is not on docs so I imagine the delta is even better.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "27dffd0e73bd",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-09-13\/2483463922595_27dffd0e73bd6f709927_72.gif",
            "first_name": "Tom",
            "real_name": "Tom Larkworthy",
            "display_name": "Tom Larkworthy",
            "team": "T5TCAFTA9",
            "name": "tom.larkworthy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1742398334.625809",
        "parent_user_id": "U06SS0DHZD1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ryALq",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "At work we switched out document OCR from classical to LLM and got better results. docs are literally the ideal use case for classical OCR but still LLMs seem to outperform coz they \"get\" the task and the words. For your use case the OCR is not on docs so I imagine the delta is even better."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "U06SS0DHZD1"
                ],
                "count": 1
            }
        ]
    }
]