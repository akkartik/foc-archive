[
    {
        "user": "UDQBTJ211",
        "type": "message",
        "ts": "1630226101.035300",
        "client_msg_id": "db8eee76-a81c-430f-9720-4dcfafb11408",
        "text": "If you are talking about live coding music like an algorave then I think you want something that somehow projects the code into a low dimensional space. In this space, \"commits\" would just be waypoint markers that are set down. So you could mark where your verse\/chorus is then explore freely and get some sense of when you were getting back close to where you were.\n\nWhile this appears ridiculous at first I've seen some really impressive dimensional reduction things on Chris Olah's blog. If you also limit yourself in terms of starting dimensionality this might work and could really add something to a live coding performance to see the path that the performer took.\n\nI went to an algorave where there was a performance by two people editing the same code. They had two cursors and their edits showed up in different colours. It meant you could see exactly how each of them was remixing each others lines and how they were both contributing. It really added to it.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "2624b1e78c0a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-14\/551655871797_2624b1e78c0a9eaed529_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Knott",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "chrisknott",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630137575.005900",
        "parent_user_id": "URLP9FWR3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2oC1",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If you are talking about live coding music like an algorave then I think you want something that somehow projects the code into a low dimensional space. In this space, \"commits\" would just be waypoint markers that are set down. So you could mark where your verse\/chorus is then explore freely and get some sense of when you were getting back close to where you were.\n\nWhile this appears ridiculous at first I've seen some really impressive dimensional reduction things on Chris Olah's blog. If you also limit yourself in terms of starting dimensionality this might work and could really add something to a live coding performance to see the path that the performer took.\n\nI went to an algorave where there was a performance by two people editing the same code. They had two cursors and their edits showed up in different colours. It meant you could see exactly how each of them was remixing each others lines and how they were both contributing. It really added to it."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UCUSW7WVD",
                    "UP00ZLX6G"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "UDQBTJ211",
        "type": "message",
        "ts": "1630227238.035500",
        "client_msg_id": "97b95415-9a50-4d87-bef9-db0b91954be2",
        "text": "My instinct would be to accept that you are ultimately going to be checking pixels and see how far you can get with that. For example, saving draw calls instead of raw pixel values, tracking dirty regions\/some kind of copy-on-write. Combining some zealous saving of state with some amount of recalculating can be pretty efficient.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "2624b1e78c0a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-14\/551655871797_2624b1e78c0a9eaed529_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Knott",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "chrisknott",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630187035.033600",
        "parent_user_id": "UCUSW7WVD",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7cFH",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "My instinct would be to accept that you are ultimately going to be checking pixels and see how far you can get with that. For example, saving draw calls instead of raw pixel values, tracking dirty regions\/some kind of copy-on-write. Combining some zealous saving of state with some amount of recalculating can be pretty efficient."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UCUSW7WVD",
        "type": "message",
        "ts": "1630242618.035900",
        "client_msg_id": "1c61128e-37b9-4c82-bd88-222ae1235f7e",
        "text": "Oh I'm actually not thinking about performance. I meant it's hard to make tests that are self evident when they're about pixel events. Extremely long lines, etc.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6e649a383cf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_72.png",
            "first_name": "Kartik",
            "real_name": "Kartik Agaram",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ak",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630187035.033600",
        "parent_user_id": "UCUSW7WVD",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MrmLj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Oh I'm actually not thinking about performance. I meant it's hard to make tests that are self evident when they're about pixel events. Extremely long lines, etc."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJZS8UUJV",
        "type": "message",
        "ts": "1630268797.036200",
        "client_msg_id": "b4537ed1-e8f9-4507-9cc8-66a418291405",
        "text": "So you’ve already decided you need to test for all these things, right? You’re just trying to figure out the best way to model the state of the screen to cover all these cases?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g62b260c347a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/962b260c347a11e19b0fdce4a97a5d49.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "Luke",
            "real_name": "Luke Persola",
            "display_name": "Luke Persola",
            "team": "T5TCAFTA9",
            "name": "lukepersola",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630187035.033600",
        "parent_user_id": "UCUSW7WVD",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "KIz",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So you’ve already decided you need to test for all these things, right? You’re just trying to figure out the best way to model the state of the screen to cover all these cases?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UCUSW7WVD",
        "type": "message",
        "ts": "1630269783.036400",
        "client_msg_id": "6a434f02-e79d-492c-bd39-5bdf297e5121",
        "text": "Yeah. It's even just the syntax. In a complex app drawing to screen what's the cleanest way to represent desired screen state in the interface and get nice error messages (that use that representation) on test failure.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6e649a383cf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_72.png",
            "first_name": "Kartik",
            "real_name": "Kartik Agaram",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ak",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630187035.033600",
        "parent_user_id": "UCUSW7WVD",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "nVn0n",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah. It's even just the syntax. In a complex app drawing to screen what's the cleanest way to represent desired screen state in the interface and get nice error messages (that use that representation) on test failure."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UJZS8UUJV"
                ],
                "count": 1
            }
        ]
    }
]