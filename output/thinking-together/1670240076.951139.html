<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #thinking-together</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <img src="https://avatars.slack-edge.com/2022-05-21/3558879757875_3e8345518ba82b825c6d_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jim Meyer</b>
<span style="margin:2em; color:#606060">2022-12-05 03:34</span><br/>
Provenance of content will be a huge challenge due to recent advancements in AI/ML. My immediate thought was "but code is in Git etc. and we know the author", but that's all void if the actual author of the code was a tool like ChatGPT/Co-Pilot and the dev was just the one that pushed it.<br/><br/>Maybe AI will be what brings about next-gen versioning systems where content provenance is managed at the AST node level during code authoring, and not just by whoever pushed the code after the fact.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670240212.422879"></a>
      <img src="https://avatars.slack-edge.com/2023-02-10/4782052692709_972d4c887a7c689aae4a_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670240212.422879" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nilesh Trivedi</b>
<span style="margin:2em; color:#606060">2022-12-05 03:36</span><br/>
Why does provenance matter? If it's good enough to pass a human review, then it's good enough. So quality/accuracy will matter more than provenance.<br/><br/>Or did you have copyright liability in mind?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670240552.221889"></a>
      <img src="https://avatars.slack-edge.com/2022-05-21/3558879757875_3e8345518ba82b825c6d_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670240552.221889" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jim Meyer</b>
<span style="margin:2em; color:#606060">2022-12-05 03:42</span><br/>
I think the review aspect is that weak part of the link. More people, with less programming knowledge will be adding code that was written by AI, and even developers are busy and will accept code that looks correct. All that code is then fed into the training set of the next round, and you've got a positive feedback loop.<br/><br/>It's the same as self-driving cars. Humans learn to trust the system, relax, and then it's all fine until it's not. I do think we'll eventually get to a good place, but right now we're in the gap between two worlds, and that's when the damage happens.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670240604.404989"></a>
      <img src="https://avatars.slack-edge.com/2022-05-21/3558879757875_3e8345518ba82b825c6d_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670240604.404989" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jim Meyer</b>
<span style="margin:2em; color:#606060">2022-12-05 03:43</span><br/>
The thread that inspired this: <a href="https://twitter.com/v21/status/1599571365556006915">https://twitter.com/v21/status/1599571365556006915</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670240775.411709"></a>
      <img src="https://avatars.slack-edge.com/2023-02-10/4782052692709_972d4c887a7c689aae4a_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670240775.411709" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nilesh Trivedi</b>
<span style="margin:2em; color:#606060">2022-12-05 03:46</span><br/>
Speaking only as a developer, we <em>cannot</em> accept code that just looks correct because we have quality review infra in place. Any code needs to pass the test cases. Can it pass test cases while being incorrect? May be, but then that's equally likely with a human.<br/><br/>So, generated code is fine. But <b>generated prose</b> is a different matter. We will need accuracy-checker, bullshit-checker etc kind of systems.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670240868.058109"></a>
      <img src="https://avatars.slack-edge.com/2022-05-21/3558879757875_3e8345518ba82b825c6d_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670240868.058109" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jim Meyer</b>
<span style="margin:2em; color:#606060">2022-12-05 03:47</span><br/>
How will the AI know the difference between well-tested code and code that's not during its training?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670240984.234009"></a>
      <img src="https://avatars.slack-edge.com/2023-02-10/4782052692709_972d4c887a7c689aae4a_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670240984.234009" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nilesh Trivedi</b>
<span style="margin:2em; color:#606060">2022-12-05 03:49</span><br/>
Not the AI, but the AI training team will very likely put quality filters for the training set. Instead of training on entire github or stackoverflow, you only train on the highly-rated repos or answers.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670241124.331109"></a>
      <img src="https://avatars.slack-edge.com/2022-05-21/3558879757875_3e8345518ba82b825c6d_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670241124.331109" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jim Meyer</b>
<span style="margin:2em; color:#606060">2022-12-05 03:52</span><br/>
I see your point, but highly-rated is a simple metric, that might be more related to popularity/hype than code-quality/correctness. It's a super difficult problem.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670241252.681229"></a>
      <img src="https://avatars.slack-edge.com/2023-02-10/4782052692709_972d4c887a7c689aae4a_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670241252.681229" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nilesh Trivedi</b>
<span style="margin:2em; color:#606060">2022-12-05 03:54</span><br/>
My point is, when it comes to code, the vicious cycle of bad quality content -&gt; bad model -&gt; bad quality content is just not there. Because our quality/rating systems work.<br/><br/>For prose, yes, this is absolutely true.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670241304.171919"></a>
      <img src="https://avatars.slack-edge.com/2022-05-21/3558879757875_3e8345518ba82b825c6d_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670241304.171919" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jim Meyer</b>
<span style="margin:2em; color:#606060">2022-12-05 03:55</span><br/>
Interesting. I think code and prose are the same in that regard :smile:
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670241558.697079"></a>
      <img src="https://avatars.slack-edge.com/2023-02-10/4782052692709_972d4c887a7c689aae4a_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670241558.697079" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nilesh Trivedi</b>
<span style="margin:2em; color:#606060">2022-12-05 03:59</span><br/>
Not really. Spam on the web is mostly prose. There are both incentives as well as lack of quality filter tools. Nobody is spamming github with incorrect code.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670242095.570469"></a>
      <img src="https://avatars.slack-edge.com/2022-05-21/3558879757875_3e8345518ba82b825c6d_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670242095.570469" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jim Meyer</b>
<span style="margin:2em; color:#606060">2022-12-05 04:08</span><br/>
Ah, yep, agreed. they're different in terms of scale and incentives.<br/><br/>I was thinking from a more fundamental level: Quality assurance of language content at scale (both code and prose are symbolic, and use/construct abstractions). They're similar problems in that regard, but we might be lucky that the incentives make training on code a less complicated practical problem.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670242165.099499"></a>
      <img src="https://avatars.slack-edge.com/2023-02-10/4782052692709_972d4c887a7c689aae4a_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670242165.099499" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nilesh Trivedi</b>
<span style="margin:2em; color:#606060">2022-12-05 04:09</span><br/>
Meanwhile, StackOverflow has temporarily banned answers by ChatGPT because they're too inaccurate: <a href="https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned">https://meta.stackoverflow.com/questions/421831/temporary-po&hellip;</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670242186.521569"></a>
      <img src="https://avatars.slack-edge.com/2022-05-21/3558879757875_3e8345518ba82b825c6d_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670242186.521569" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jim Meyer</b>
<span style="margin:2em; color:#606060">2022-12-05 04:09</span><br/>
Haha, yep it sure is confident, even while wrong :smile:
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670242985.762439"></a>
      <img src="https://avatars.slack-edge.com/2022-05-21/3558879757875_3e8345518ba82b825c6d_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670242985.762439" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jim Meyer</b>
<span style="margin:2em; color:#606060">2022-12-05 04:23</span><br/>
This actually feeds back to my initial worry. Code alone is not enough to train systems like ChatGTP. It won't know how to map natural language onto code. That comes from training on sources like StackOverflow. See how this spam makes prose and code not so different? The social systems and incentives do appear to have some overlap. This policy change is needed, but difficult to enforce at scale. Same as QA'ing spam/prose because it requires a lot of effort to know whether something is a good answer.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670243084.896449"></a>
      <img src="https://avatars.slack-edge.com/2022-05-21/3558879757875_3e8345518ba82b825c6d_72.jpg" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670243084.896449" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jim Meyer</b>
<span style="margin:2em; color:#606060">2022-12-05 04:24</span><br/>
Humans talking about code -&gt; Social systems/incentives -&gt; Humans gaming the systems with AI
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670258014.203649"></a>
      <img src="https://secure.gravatar.com/avatar/bc993d98fe7bf26c048ac0818a598d4d.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670258014.203649" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Mark Dewing</b>
<span style="margin:2em; color:#606060">2022-12-05 08:33</span><br/>
AI systems based on large language models are prone to human-like errors, both in solving logic puzzles and in writing program code.  Which gives me less confidence in code review as a quality check on AI-written code - both the AI and the human are okay with code that "looks good".   The advances in the scientific method come from developing techniques to work around limitations and drawbacks in human reasoning.  We'll need to apply these (and new ones) to AI systems.   In my view, the test suite is going to be the most important part of the code base, since an AI will write the code. (Until the AI's can write the test suite as well :slightly_smiling_face: ).
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670380342.208799"></a>
      <img src="https://secure.gravatar.com/avatar/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png" style="float:left"/>
      <a href="../thinking-together/1670240076.951139.html#1670380342.208799" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>William Taysom</b>
<span style="margin:2em; color:#606060">2022-12-06 18:32</span><br/>
Things to keep in mind:<br/>1. Part of what makes ChatGTP and improvement over plain GPT-3 comes from training for relevance rather than the first thing you would think of.  So adjusting the training criteria should then feed into...<br/>2. If an AI is writing code, it should iterate with itself running the code before coming back with an answer.  Basically, mix in some of what's done to play games.  In fact...<br/>3. We could potentially see quick improvement with these chat systems if well engineered prompts can go back into the training of the system.  For example, one reason why "in the style of" prompts get more pleasant output from ChatGTP is that they steer the system away from its default middling BS mode.<br/>Curiously, one good use of ChatGTP is to help discover likely misconceptions that students learning technical subjects are likely to have.  In conversations so far, I've seen ChatGTP be fuzzy on the distinctions between:<br/>1. Continuity and uncountability in math, and<br/>2. block and procs in Ruby.<br/>To the credit of incorporating so much training data, ChatGTP is conversant on so many topics.  It's kind of interesting how OpenAI has put a filter on this so as to avoid avoid answering questions where ChatGTP's knowledge might be limited.
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
