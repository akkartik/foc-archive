[
    {
        "user": "U01JNTE35QS",
        "type": "message",
        "ts": "1679857701.783789",
        "client_msg_id": "395f1ade-b434-4a27-8f81-db9c624eb1e3",
        "text": "Not sure you’d have that choice. If people around you use AI to get 10x productivity you’d likely have to do the same…",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "97155db555c2",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-01-13\/1631845309525_97155db555c2091ecd20_72.jpg",
            "first_name": "",
            "real_name": "Vijay Chakravarthy",
            "display_name": "Vijay Chakravarthy",
            "team": "T5TCAFTA9",
            "name": "vchakrav",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "wy+lU",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Not sure you’d have that choice. If people around you use AI to get 10x productivity you’d likely have to do the same…"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "subtype": "thread_broadcast",
        "user": "U6KQ2S410",
        "thread_ts": "1679642239.661619",
        "root": {
            "user": "UA14TGLTC",
            "type": "message",
            "ts": "1679642239.661619",
            "client_msg_id": "53df656f-b6b5-4ef6-a470-c1af29f870e6",
            "text": "Friends, I don't know what to make of developments in AI these days.  Having worked on dialog systems in the aughts and having loosely followed developments since (I recall preparing a talk around 2010 which left me pretty enthusiastic about ML applications in contrast to the App-and-Facebookification of \"tech\" — that was on time horizon of a few years, which ended up being a decade plus), every day I check in on Twitter I see more exciting stuff than I can possibly process.  I was just writing someone yesterday about how in six months time, we'll have LLMs acting as the front-end to knowledge bases and rigorous computational systems, and then we'll need to focus on getting the human, AI, and formal model all on the same page.\n\nAs has already been noted in <#C5U3SEW6A|> today, my estimate was off by roughly six months.  Consider, \"I've developed a lot of plugin systems, and the OpenAI ChatGPT plugin interface might be the damn craziest and most impressive approach I've ever seen in computing in my entire life. For those who aren't aware: you write an OpenAPI manifest for your API, use human language descriptions for everything, and that's it. You let the model figure out how to auth, chain calls, process data in between, format it for viewing, etc. There's absolutely zero glue code\" <https:\/\/twitter.com\/mitchellh\/status\/1638967450510458882>.\n\nIf you can tolerate his prose, Stephen Wolfram has a long post <https:\/\/writings.stephenwolfram.com\/2023\/03\/chatgpt-gets-its-wolfram-superpowers\/>.  The \"Wolfram Language as the Language for Human-AI Collaboration\" section is most relevant to Future of Coding.  What do these developments mean for the Future of Coding?  And how are you all holding up?  Me?  I can hardly process what's happening, let alone what to do about it.",
            "team": "T5TCAFTA9",
            "thread_ts": "1679642239.661619",
            "reply_count": 59,
            "reply_users_count": 13,
            "latest_reply": "1684481583.998269",
            "reply_users": [
                "UJBAJNFLK",
                "UE1JQM9HQ",
                "U5STGTB3J",
                "U04LWR320HK",
                "UA14TGLTC",
                "UC2A2ARPT",
                "U016VUZGUUQ",
                "U01JNTE35QS",
                "U6KQ2S410",
                "UEBG0NPDK",
                "UCGAK10LS",
                "UE6EFEPTQ",
                "U79HM6726"
            ],
            "replies": [
                {
                    "user": "UJBAJNFLK",
                    "ts": "1679643607.301909"
                },
                {
                    "user": "UJBAJNFLK",
                    "ts": "1679643699.930779"
                },
                {
                    "user": "UJBAJNFLK",
                    "ts": "1679643773.942429"
                },
                {
                    "user": "UE1JQM9HQ",
                    "ts": "1679645429.572999"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1679647648.385719"
                },
                {
                    "user": "U04LWR320HK",
                    "ts": "1679652855.371729"
                },
                {
                    "user": "U04LWR320HK",
                    "ts": "1679653074.943419"
                },
                {
                    "user": "U04LWR320HK",
                    "ts": "1679653201.142569"
                },
                {
                    "user": "U04LWR320HK",
                    "ts": "1679653460.044379"
                },
                {
                    "user": "UA14TGLTC",
                    "ts": "1679662321.572839"
                },
                {
                    "user": "UC2A2ARPT",
                    "ts": "1679670191.352299"
                },
                {
                    "user": "UA14TGLTC",
                    "ts": "1679734459.112359"
                },
                {
                    "user": "UJBAJNFLK",
                    "ts": "1679739804.701319"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1679744980.610859"
                },
                {
                    "user": "UC2A2ARPT",
                    "ts": "1679753480.307179"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1679758571.195769"
                },
                {
                    "user": "U016VUZGUUQ",
                    "ts": "1679775047.749719"
                },
                {
                    "user": "UC2A2ARPT",
                    "ts": "1679776546.918969"
                },
                {
                    "user": "U016VUZGUUQ",
                    "ts": "1679777301.662669"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1679782798.148039"
                },
                {
                    "user": "UC2A2ARPT",
                    "ts": "1679795014.514789"
                },
                {
                    "user": "U01JNTE35QS",
                    "ts": "1679857701.783789"
                },
                {
                    "user": "U6KQ2S410",
                    "ts": "1679865409.191369"
                },
                {
                    "user": "UEBG0NPDK",
                    "ts": "1679868492.330429"
                },
                {
                    "user": "UEBG0NPDK",
                    "ts": "1679868608.783739"
                },
                {
                    "user": "UC2A2ARPT",
                    "ts": "1679870297.991809"
                },
                {
                    "user": "UEBG0NPDK",
                    "ts": "1679870503.852149"
                },
                {
                    "user": "UEBG0NPDK",
                    "ts": "1679870548.243369"
                },
                {
                    "user": "UEBG0NPDK",
                    "ts": "1679870600.200489"
                },
                {
                    "user": "UA14TGLTC",
                    "ts": "1679893322.040489"
                },
                {
                    "user": "UA14TGLTC",
                    "ts": "1679893394.029269"
                },
                {
                    "user": "UCGAK10LS",
                    "ts": "1679893634.916689"
                },
                {
                    "user": "U01JNTE35QS",
                    "ts": "1679896042.850529"
                },
                {
                    "user": "UA14TGLTC",
                    "ts": "1679896366.253479"
                },
                {
                    "user": "U04LWR320HK",
                    "ts": "1679902126.038549"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1679902332.167169"
                },
                {
                    "user": "U01JNTE35QS",
                    "ts": "1679926482.489929"
                },
                {
                    "user": "UE6EFEPTQ",
                    "ts": "1680021655.809059"
                },
                {
                    "user": "UE6EFEPTQ",
                    "ts": "1680021713.979729"
                },
                {
                    "user": "UE6EFEPTQ",
                    "ts": "1680021757.859229"
                },
                {
                    "user": "UE6EFEPTQ",
                    "ts": "1680022674.760079"
                },
                {
                    "user": "UE6EFEPTQ",
                    "ts": "1680029782.072819"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1680037224.851009"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1680037336.462609"
                },
                {
                    "user": "UE6EFEPTQ",
                    "ts": "1680043645.267109"
                },
                {
                    "user": "UE6EFEPTQ",
                    "ts": "1680043681.323419"
                },
                {
                    "user": "U79HM6726",
                    "ts": "1683106741.986779"
                },
                {
                    "user": "UA14TGLTC",
                    "ts": "1683150274.780029"
                },
                {
                    "user": "U79HM6726",
                    "ts": "1683199124.327219"
                },
                {
                    "user": "U016VUZGUUQ",
                    "ts": "1683230960.602079"
                },
                {
                    "user": "U016VUZGUUQ",
                    "ts": "1683231431.915559"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1683232897.013519"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1683284833.301809"
                },
                {
                    "user": "UA14TGLTC",
                    "ts": "1684306739.419379"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1684322884.709189"
                },
                {
                    "user": "UA14TGLTC",
                    "ts": "1684377794.941889"
                },
                {
                    "user": "UA14TGLTC",
                    "ts": "1684378654.355689"
                },
                {
                    "user": "U5STGTB3J",
                    "ts": "1684396439.041129"
                },
                {
                    "user": "UA14TGLTC",
                    "ts": "1684481583.998269"
                }
            ],
            "is_locked": false,
            "subscribed": false,
            "blocks": [
                {
                    "type": "rich_text",
                    "block_id": "Bvp",
                    "elements": [
                        {
                            "type": "rich_text_section",
                            "elements": [
                                {
                                    "type": "text",
                                    "text": "Friends, I don't know what to make of developments in AI these days.  Having worked on dialog systems in the aughts and having loosely followed developments since (I recall preparing a talk around 2010 which left me pretty enthusiastic about ML applications in contrast to the App-and-Facebookification of \"tech\" — that was on time horizon of a few years, which ended up being a decade plus), every day I check in on Twitter I see more exciting stuff than I can possibly process.  I was just writing someone yesterday about how in six months time, we'll have LLMs acting as the front-end to knowledge bases and rigorous computational systems, and then we'll need to focus on getting the human, AI, and formal model all on the same page.\n\nAs has already been noted in "
                                },
                                {
                                    "type": "channel",
                                    "channel_id": "C5U3SEW6A"
                                },
                                {
                                    "type": "text",
                                    "text": " today, my estimate was off by roughly six months.  Consider, \"I've developed a lot of plugin systems, and the OpenAI ChatGPT plugin interface might be the damn craziest and most impressive approach I've ever seen in computing in my entire life. For those who aren't aware: you write an OpenAPI manifest for your API, use human language descriptions for everything, and that's it. You let the model figure out how to auth, chain calls, process data in between, format it for viewing, etc. There's absolutely zero glue code\" "
                                },
                                {
                                    "type": "link",
                                    "url": "https:\/\/twitter.com\/mitchellh\/status\/1638967450510458882"
                                },
                                {
                                    "type": "text",
                                    "text": ".\n\nIf you can tolerate his prose, Stephen Wolfram has a long post "
                                },
                                {
                                    "type": "link",
                                    "url": "https:\/\/writings.stephenwolfram.com\/2023\/03\/chatgpt-gets-its-wolfram-superpowers\/"
                                },
                                {
                                    "type": "text",
                                    "text": ".  The \"Wolfram Language as the Language for Human-AI Collaboration\" section is most relevant to Future of Coding.  What do these developments mean for the Future of Coding?  And how are you all holding up?  Me?  I can hardly process what's happening, let alone what to do about it."
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        "type": "message",
        "ts": "1679865409.191369",
        "client_msg_id": "4e3e3ffa-4adb-4482-80b6-2cfe0f3f81ac",
        "text": "GPT feels like an existential crisis for the future of programming, if not an extinction event. I am having to rationalize to myself about why that probably isn’t true so I can keep working. The scary truth is that no one knows. We have no idea where we are on the scaling curve or even what constraints will limit it.",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uuOW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "GPT feels like an existential crisis for the future of programming, if not an extinction event. I am having to rationalize to myself about why that probably isn’t true so I can keep working. The scary truth is that no one knows. We have no idea where we are on the scaling curve or even what constraints will limit it."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UCUSW7WVD",
                    "U03R0B9U1GD",
                    "UEBG0NPDK",
                    "UA14TGLTC",
                    "UPVBV34EL",
                    "UJBAJNFLK"
                ],
                "count": 6
            }
        ]
    },
    {
        "user": "UEBG0NPDK",
        "type": "message",
        "ts": "1679868492.330429",
        "edited": {
            "user": "UEBG0NPDK",
            "ts": "1679870718.000000"
        },
        "client_msg_id": "6e1ce1c1-4772-4bcc-be33-bfec1d002f35",
        "text": "There’s work to do, but I think it’ll be commoditized in the span of weeks to months (if not days in some cases!) As a result, I think we’re witnessing the start of one of the greatest consolidations we’ve ever seen and relatively few (tech, white-collar?) businesses will survive it. It’s going to be a very interesting next couple of years. Josh and I have decided to step away from the really cool work we were doing and instead focus on being in a good position to take advantage of whatever happens.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "9e85c7bdd45b",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-11-25\/487455880658_9e85c7bdd45b1d2d4721_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Granger",
            "display_name": "ibdknox",
            "team": "T5TCAFTA9",
            "name": "ibdknox",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "gvO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "There’s work to do, but I think it’ll be commoditized in the span of weeks to months (if not days in some cases!) As a result, I think we’re witnessing the start of one of the greatest consolidations we’ve ever seen and relatively few (tech, white-collar?) businesses will survive it. It’s going to be a very interesting next couple of years. Josh and I have decided to step away from the really cool work we were doing and instead focus on being in a good position to take advantage of whatever happens."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEBG0NPDK",
        "type": "message",
        "ts": "1679868608.783739",
        "edited": {
            "user": "UEBG0NPDK",
            "ts": "1679869028.000000"
        },
        "client_msg_id": "358ab85c-e1d1-4d32-a577-015ca17e48b1",
        "text": "We’ve spent the last ~8 years trying to make something like this happen; it’ll be really wild to see how much of what we came up with becomes real.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "9e85c7bdd45b",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-11-25\/487455880658_9e85c7bdd45b1d2d4721_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Granger",
            "display_name": "ibdknox",
            "team": "T5TCAFTA9",
            "name": "ibdknox",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Mhip",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "We’ve spent the last ~8 years trying to make something like this happen; it’ll be really wild to see how much of what we came up with becomes real."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1679870297.991809",
        "client_msg_id": "fe942407-667a-43ad-ad6e-bb1cb92b8464",
        "text": "&gt; relatively few businesses will survive it\nCan you put some bounds on that statement? Like, I don't see AI taking over food service or hospitality any time soon.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "Ivan Reese",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Pq1u",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "relatively few businesses will survive it"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nCan you put some bounds on that statement? Like, I don't see AI taking over food service or hospitality any time soon."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U79HM6726"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UEBG0NPDK",
        "type": "message",
        "ts": "1679870503.852149",
        "client_msg_id": "dd32f2b7-129f-4e2a-84b0-e8f051d2746c",
        "text": "Ah yeah, should’ve been more clear. I believe that with the technology that currently exists, the majority of businesses that don’t have established moats around either data access (e.g mapping data), capability (e.g. twilio providing telephone capabilities), or physical manifestation (pepsi, plumbing, etc) are going to have a rough time.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "9e85c7bdd45b",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-11-25\/487455880658_9e85c7bdd45b1d2d4721_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Granger",
            "display_name": "ibdknox",
            "team": "T5TCAFTA9",
            "name": "ibdknox",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4\/5o8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Ah yeah, should’ve been more clear. I believe that with the technology that currently exists, the majority of businesses that don’t have established moats around either data access (e.g mapping data), capability (e.g. twilio providing telephone capabilities), or physical manifestation (pepsi, plumbing, etc) are going to have a rough time."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEBG0NPDK",
        "type": "message",
        "ts": "1679870548.243369",
        "client_msg_id": "a6a8c0bb-de24-4d83-a2fc-3f07fc627644",
        "text": "That’s unlikely to be a change overnight or anything, but perhaps more pertinent to this group is that it destroys a lot of the nascent opportunities.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "9e85c7bdd45b",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-11-25\/487455880658_9e85c7bdd45b1d2d4721_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Granger",
            "display_name": "ibdknox",
            "team": "T5TCAFTA9",
            "name": "ibdknox",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Rg1",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "That’s unlikely to be a change overnight or anything, but perhaps more pertinent to this group is that it destroys a lot of the nascent opportunities."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEBG0NPDK",
        "type": "message",
        "ts": "1679870600.200489",
        "edited": {
            "user": "UEBG0NPDK",
            "ts": "1679872580.000000"
        },
        "client_msg_id": "0a57a26a-bfc0-411c-b8c1-d3cdfe22accf",
        "text": "For example, the ChatGPT plugins release nuked a good portion of the current YC class a week and a half before demo day. Who knows what the implications of that will be.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "9e85c7bdd45b",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-11-25\/487455880658_9e85c7bdd45b1d2d4721_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Granger",
            "display_name": "ibdknox",
            "team": "T5TCAFTA9",
            "name": "ibdknox",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "r2NH",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "For example, the ChatGPT plugins release nuked a good portion of the current YC class a week and a half before demo day. Who knows what the implications of that will be."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UCGAK10LS",
        "type": "message",
        "ts": "1679892669.316079",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1679895554.000000"
        },
        "client_msg_id": "f6c5c68b-63a7-4b04-b17f-07a4542bd0fa",
        "text": "Here's my perspective on LLMs and the future of programming.\n\nI don't believe that the introduction of LLMs that can write code is going to obviate programming. And I don't believe that it is now pointless to develop new programming languages. Instead, I think LLMs are going to make programming and FoC research _better_, by automating one of the least interesting parts of programming: fiddling with the minutiae of syntax, language constructs, and libraries.\n\nI think programmers will still have plenty of work to do. The profession is not doomed. But to justify this, we have to take a step back and consider all of the activities involved in programming.\n\nFirstly, what is a \"program\"? A program is nothing more than:\n• _A formal specification_ of the behaviour of an interactive system\n• ...that computer hardware can execute (after translating it into machine code).\nTo emphasise this, I will use the term \"formal spec\" in place of \"program\" for the remainder of this discussion.\n\nGPT-4 can understand formal specs, and also everyday English. Thus, if we can describe the functionality of a system in everyday English, GPT-4 can (attempt to) translate it into a formal spec. But writing the formal spec is just _one_ activity of programming.\n\nAltogether, programming (or perhaps \"software development\") involves several activities:\n1. Determining what functionality the system being developed \"should\" have. This is done either by talking with relevant stakeholders (e.g. the future users), or by directly observing deficiencies with their current practices.\n2. Expressing that functionality as a formal specification, i.e. \"coding\".\n3. Verifying that the specification correctly implements all of the functionality of step 1. This includes practices such as reading and reviewing the specification, as well as testing the software.\n4. Validating that the implemented functionality addresses the stakeholder's problems.\n5. Repeating the first 4 steps until the stakeholders are satisfied with what has been developed.\nHere's my hypothesis: *In the next 10 years, LLMs might radically reduce the amount of work required for step 2, but _only_ step 2.*\n\nSteps 1 and 4 are very human-centered, and thus can't be automated away — at least until we are at the point where we have an omnipresent AGI that observes all human practices and automatically develops solutions to improve them.\n\nSimilarly, step 3 will not be automated any time soon, because:\n• The plain English descriptions that we give to LLMs will often be ambiguous, underspecified, and maybe even inconsistent. Thus the LLMs will have to make educated _guesses_ at what we mean. (Even if they are able to ask clarifying questions, there will always be _some_ choices that are automatically made for us.)\n• LLMs will occasionally get confused or misinterpret what we say, even if we are clear and careful. We will not have _infallible_ AIs any time soon.\nSo let's assume that LLMs can automate most of step 2. What does this mean for those of us developing tools and technologies to improve programming? Is our work obsolete now? Will the AI researchers and AI startups be taking the reigns?\n\nI don't think so! There is still a huge opportunity to develop tools that address step 3, at the very least. (Steps 1 and 4 are harder to address with technology.)\n\nIn particular, *step 3 involves the task of _reading_ source code*. When an LLM spits out 1000 lines of JavaScript, how do you know that the code implements the functionality that you wanted? You have to _verify_ that it does, and for large programs, that will be an enormous amount of work!\n\nAs we all know, no amount of testing can prove that a program is correct. Thus, we cannot verify AI-generated programs just by _using_ them. Maybe the program has a subtle bug, such as a buffer overflow, that might only be triggered 5 years after the program is deployed. Or less insidiously: maybe the program just doesn't handle certain edge-cases in the way you would like it to. Either way, a human should probably read through the entire program with a keen eye, to check that all of the logic _makes sense_.\n\nThere's clearly an opportunity for FoC researchers here: we can make languages and tools that make _reading_ and _verifying_ the behaviour of programs easier! Some examples:\n• We can design programming languages that are vastly easier to _read_ than traditional languages. How might we do that? Well, \"higher-level\" languages are likely easier to read, since they are likely to be more concise and focus on the end-user functionality. So work on higher-level programming models will continue to be valuable. To complement this, we can (and IMO, we should) invent new syntaxes that are closer to plain English, such that the specifications that LLMs produce are accessible to a wider audience.\n• We can design programming languages where it is harder to write erroneous programs. For example, we can design programming languages that cannot crash or hang (i.e. Turing-incomplete languages), but which are still general-purpose. This reduces the kinds of errors that a human needs to consider as they verify a program.\n• We can design better tools for reading and interrogating source code. (For example, better IDE support for navigating and understanding the structure of large codebases.)\n• We can design better tools for exploring the space of behaviours of a running program. (Perhaps similar to the tools discussed in Bret Victor's <http:\/\/worrydream.com\/#!2\/LadderOfAbstraction|\"Ladder of Abstraction\"> essay.)\nOverall, I think the future is bright! I'm going to continue my own PL research project (a very high-level language) with as much vigor as ever.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6402e9775ed7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-13\/5095853045814_6402e9775ed73b75334f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679892669.316079",
        "reply_count": 17,
        "reply_users_count": 7,
        "latest_reply": "1680218359.116989",
        "reply_users": [
            "UA14TGLTC",
            "UCGAK10LS",
            "U0296ACR13M",
            "U0112C10V4Y",
            "UNCP67JSK",
            "U04MTMF6Y4W",
            "UE6EFEPTQ"
        ],
        "replies": [
            {
                "user": "UA14TGLTC",
                "ts": "1679896298.612939"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1679896811.824169"
            },
            {
                "user": "U0296ACR13M",
                "ts": "1679897153.979009"
            },
            {
                "user": "U0296ACR13M",
                "ts": "1679898374.858229"
            },
            {
                "user": "U0112C10V4Y",
                "ts": "1679929542.004789"
            },
            {
                "user": "U0112C10V4Y",
                "ts": "1679929692.502719"
            },
            {
                "user": "UNCP67JSK",
                "ts": "1679936905.902369"
            },
            {
                "user": "UNCP67JSK",
                "ts": "1679937330.895309"
            },
            {
                "user": "U04MTMF6Y4W",
                "ts": "1679941681.352839"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1679959060.869239"
            },
            {
                "user": "U0112C10V4Y",
                "ts": "1680020008.516259"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1680043249.104769"
            },
            {
                "user": "UE6EFEPTQ",
                "ts": "1680165758.277559"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1680177208.040789"
            },
            {
                "user": "UE6EFEPTQ",
                "ts": "1680181366.670179"
            },
            {
                "user": "UE6EFEPTQ",
                "ts": "1680181816.402269"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1680218359.116989"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "HQR0r",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Here's my perspective on LLMs and the future of programming.\n\nI don't believe that the introduction of LLMs that can write code is going to obviate programming. And I don't believe that it is now pointless to develop new programming languages. Instead, I think LLMs are going to make programming and FoC research "
                            },
                            {
                                "type": "text",
                                "text": "better",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", by automating one of the least interesting parts of programming: fiddling with the minutiae of syntax, language constructs, and libraries.\n\nI think programmers will still have plenty of work to do. The profession is not doomed. But to justify this, we have to take a step back and consider all of the activities involved in programming.\n\nFirstly, what is a \"program\"? A program is nothing more than:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "A formal specification",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " of the behaviour of an interactive system"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "...that computer hardware can execute (after translating it into machine code)."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nTo emphasise this, I will use the term \"formal spec\" in place of \"program\" for the remainder of this discussion.\n\nGPT-4 can understand formal specs, and also everyday English. Thus, if we can describe the functionality of a system in everyday English, GPT-4 can (attempt to) translate it into a formal spec. But writing the formal spec is just "
                            },
                            {
                                "type": "text",
                                "text": "one",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " activity of programming.\n\nAltogether, programming (or perhaps \"software development\") involves several activities:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Determining what functionality the system being developed \"should\" have. This is done either by talking with relevant stakeholders (e.g. the future users), or by directly observing deficiencies with their current practices."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Expressing that functionality as a formal specification, i.e. \"coding\"."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Verifying that the specification correctly implements all of the functionality of step 1. This includes practices such as reading and reviewing the specification, as well as testing the software."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Validating that the implemented functionality addresses the stakeholder's problems."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Repeating the first 4 steps until the stakeholders are satisfied with what has been developed."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nHere's my hypothesis: "
                            },
                            {
                                "type": "text",
                                "text": "In the next 10 years, LLMs might radically reduce the amount of work required for step 2, but ",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "only",
                                "style": {
                                    "bold": true,
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " step 2.",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\nSteps 1 and 4 are very human-centered, and thus can't be automated away — at least until we are at the point where we have an omnipresent AGI that observes all human practices and automatically develops solutions to improve them.\n\nSimilarly, step 3 will not be automated any time soon, because:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "The plain English descriptions that we give to LLMs will often be ambiguous, underspecified, and maybe even inconsistent. Thus the LLMs will have to make educated "
                                    },
                                    {
                                        "type": "text",
                                        "text": "guesses",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " at what we mean. (Even if they are able to ask clarifying questions, there will always be "
                                    },
                                    {
                                        "type": "text",
                                        "text": "some",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " choices that are automatically made for us.)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "LLMs will occasionally get confused or misinterpret what we say, even if we are clear and careful. We will not have "
                                    },
                                    {
                                        "type": "text",
                                        "text": "infallible",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " AIs any time soon."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nSo let's assume that LLMs can automate most of step 2. What does this mean for those of us developing tools and technologies to improve programming? Is our work obsolete now? Will the AI researchers and AI startups be taking the reigns?\n\nI don't think so! There is still a huge opportunity to develop tools that address step 3, at the very least. (Steps 1 and 4 are harder to address with technology.)\n\nIn particular, "
                            },
                            {
                                "type": "text",
                                "text": "step 3 involves the task of ",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "reading",
                                "style": {
                                    "bold": true,
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " source code",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". When an LLM spits out 1000 lines of JavaScript, how do you know that the code implements the functionality that you wanted? You have to "
                            },
                            {
                                "type": "text",
                                "text": "verify",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " that it does, and for large programs, that will be an enormous amount of work!\n\nAs we all know, no amount of testing can prove that a program is correct. Thus, we cannot verify AI-generated programs just by "
                            },
                            {
                                "type": "text",
                                "text": "using",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " them. Maybe the program has a subtle bug, such as a buffer overflow, that might only be triggered 5 years after the program is deployed. Or less insidiously: maybe the program just doesn't handle certain edge-cases in the way you would like it to. Either way, a human should probably read through the entire program with a keen eye, to check that all of the logic "
                            },
                            {
                                "type": "text",
                                "text": "makes sense",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ".\n\nThere's clearly an opportunity for FoC researchers here: we can make languages and tools that make "
                            },
                            {
                                "type": "text",
                                "text": "reading",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " and "
                            },
                            {
                                "type": "text",
                                "text": "verifying",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " the behaviour of programs easier! Some examples:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "We can design programming languages that are vastly easier to "
                                    },
                                    {
                                        "type": "text",
                                        "text": "read",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " than traditional languages. How might we do that? Well, \"higher-level\" languages are likely easier to read, since they are likely to be more concise and focus on the end-user functionality. So work on higher-level programming models will continue to be valuable. To complement this, we can (and IMO, we should) invent new syntaxes that are closer to plain English, such that the specifications that LLMs produce are accessible to a wider audience."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "We can design programming languages where it is harder to write erroneous programs. For example, we can design programming languages that cannot crash or hang (i.e. Turing-incomplete languages), but which are still general-purpose. This reduces the kinds of errors that a human needs to consider as they verify a program."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "We can design better tools for reading and interrogating source code. (For example, better IDE support for navigating and understanding the structure of large codebases.)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "We can design better tools for exploring the space of behaviours of a running program. (Perhaps similar to the tools discussed in Bret Victor's "
                                    },
                                    {
                                        "type": "link",
                                        "url": "http:\/\/worrydream.com\/#!2\/LadderOfAbstraction",
                                        "text": "\"Ladder of Abstraction\""
                                    },
                                    {
                                        "type": "text",
                                        "text": " essay.)"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nOverall, I think the future is bright! I'm going to continue my own PL research project (a very high-level language) with as much vigor as ever."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UA14TGLTC",
                    "U0245E9RB2B",
                    "U0296ACR13M",
                    "U04E5QAD6DD",
                    "UC2A2ARPT",
                    "U02NU8FTL5N",
                    "U02B6FQKZK8"
                ],
                "count": 7
            },
            {
                "name": "sparkle",
                "users": [
                    "U04MTMF6Y4W"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UA14TGLTC",
        "type": "message",
        "ts": "1679893322.040489",
        "client_msg_id": "70898e48-7f9f-4329-98e1-9d14f36ed64c",
        "text": "Perhaps in line with some of the sentiment here, Cory Doctorow takes a dim view of how capitalists will engage in this AI moment <https:\/\/pluralistic.net\/2023\/03\/09\/autocomplete-worshippers\/>.\n\nI wonder where are we on the S-curve?  I see so many immediate directions for improving obvious shortcomings... Frankly, at a moment like this, I now have to go check twitter to update my worldview.  Like what's the progress one putting models into hardware, today <https:\/\/twitter.com\/BrianRoemmele\/status\/1640105149099302913>?  Or can GPT-4 actually attend to feedback for real <https:\/\/twitter.com\/ericjang11\/status\/1639882111338573824>?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gae6d55db9d1",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "William Taysom",
            "display_name": "wtaysom",
            "team": "T5TCAFTA9",
            "name": "wtaysom",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "attachments": [
            {
                "from_url": "https:\/\/twitter.com\/BrianRoemmele\/status\/1640105149099302913",
                "ts": 1679866513,
                "image_url": "https:\/\/pbs.twimg.com\/media\/FsLN2jEaEAAFtOI.jpg",
                "image_width": 474,
                "image_height": 266,
                "image_bytes": 19034,
                "id": 1,
                "original_url": "https:\/\/twitter.com\/BrianRoemmele\/status\/1640105149099302913",
                "fallback": "<https:\/\/twitter.com\/BrianRoemmele|@BrianRoemmele>: Now that OpenAI Chat GPT proved that 80% of questions do not require a live internet connection to get an answer. This has been my thesis for decades.\n\nWe have been working on a single chip to hold a quantized trained model of a Chat GPT 3.5-like platforms on a local chip.\n\nBy… <https:\/\/twitter.com\/i\/web\/status\/1640105149099302913>",
                "text": "Now that OpenAI Chat GPT proved that 80% of questions do not require a live internet connection to get an answer. This has been my thesis for decades.\n\nWe have been working on a single chip to hold a quantized trained model of a Chat GPT 3.5-like platforms on a local chip.\n\nBy… <https:\/\/twitter.com\/i\/web\/status\/1640105149099302913>",
                "author_name": "Brian Roemmele",
                "author_link": "https:\/\/twitter.com\/BrianRoemmele\/status\/1640105149099302913",
                "author_icon": "https:\/\/pbs.twimg.com\/profile_images\/1492616506\/Brian-Med-Green-Fin_normal.png",
                "author_subname": "@BrianRoemmele",
                "service_name": "twitter",
                "service_url": "https:\/\/twitter.com\/",
                "footer": "Twitter",
                "footer_icon": "https:\/\/a.slack-edge.com\/80588\/img\/services\/twitter_pixel_snapped_32.png"
            },
            {
                "from_url": "https:\/\/twitter.com\/BrianRoemmele\/status\/1110187538885468161",
                "ts": 1553524310,
                "indent": true,
                "color": "32BBF3",
                "id": 2,
                "fallback": "<https:\/\/twitter.com\/BrianRoemmele|@BrianRoemmele>: With funding beyond my piggy bank VC in my garage lab. I will make the first #KnowledgeOnAChip system. This will include the entire text library of Wikipedia plus 3200 directories including first person knowledge of <https:\/\/twitter.com\/Quora|@Quora>.\n\nNo internet is needed.\n\nThis will change everything. <https:\/\/twitter.com\/BrianRoemmele\/status\/1109853516384731136>",
                "text": "With funding beyond my piggy bank VC in my garage lab. I will make the first #KnowledgeOnAChip system. This will include the entire text library of Wikipedia plus 3200 directories including first person knowledge of <https:\/\/twitter.com\/Quora|@Quora>.\n\nNo internet is needed.\n\nThis will change everything. <https:\/\/twitter.com\/BrianRoemmele\/status\/1109853516384731136>",
                "author_name": "Brian Roemmele",
                "author_link": "https:\/\/twitter.com\/BrianRoemmele\/status\/1110187538885468161",
                "author_icon": "https:\/\/pbs.twimg.com\/profile_images\/1492616506\/Brian-Med-Green-Fin_normal.png",
                "author_subname": "@BrianRoemmele",
                "service_name": "twitter",
                "service_url": "https:\/\/twitter.com\/",
                "footer": "Twitter",
                "footer_icon": "https:\/\/a.slack-edge.com\/80588\/img\/services\/twitter_pixel_snapped_32.png"
            },
            {
                "from_url": "https:\/\/twitter.com\/ericjang11\/status\/1639882111338573824",
                "ts": 1679813337,
                "id": 3,
                "original_url": "https:\/\/twitter.com\/ericjang11\/status\/1639882111338573824",
                "fallback": "<https:\/\/twitter.com\/ericjang11|@ericjang11>: Instead of finding the perfect prompt for an LLM (let's think step by step), you can ask LLMs to critique their outputs and immediately fix their own mistakes. Here's a fun example:",
                "text": "Instead of finding the perfect prompt for an LLM (let's think step by step), you can ask LLMs to critique their outputs and immediately fix their own mistakes. Here's a fun example:",
                "author_name": "Eric Jang",
                "author_link": "https:\/\/twitter.com\/ericjang11\/status\/1639882111338573824",
                "author_icon": "https:\/\/pbs.twimg.com\/profile_images\/1494315926455394308\/La_saDZ8_normal.jpg",
                "author_subname": "@ericjang11",
                "service_name": "twitter",
                "service_url": "https:\/\/twitter.com\/",
                "footer": "Twitter",
                "footer_icon": "https:\/\/a.slack-edge.com\/80588\/img\/services\/twitter_pixel_snapped_32.png"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "aVB",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Perhaps in line with some of the sentiment here, Cory Doctorow takes a dim view of how capitalists will engage in this AI moment "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/pluralistic.net\/2023\/03\/09\/autocomplete-worshippers\/"
                            },
                            {
                                "type": "text",
                                "text": ".\n\nI wonder where are we on the S-curve?  I see so many immediate directions for improving obvious shortcomings... Frankly, at a moment like this, I now have to go check twitter to update my worldview.  Like what's the progress one putting models into hardware, today "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/twitter.com\/BrianRoemmele\/status\/1640105149099302913"
                            },
                            {
                                "type": "text",
                                "text": "?  Or can GPT-4 actually attend to feedback for real "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/twitter.com\/ericjang11\/status\/1639882111338573824"
                            },
                            {
                                "type": "text",
                                "text": "?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UA14TGLTC",
        "type": "message",
        "ts": "1679893394.029269",
        "client_msg_id": "bbc1c884-5f13-420b-b89f-5923fed02405",
        "text": "So then I'm left wonder if human imagination will be a limiting factor — but then I spend a few minutes seeing what imaginative humans try out.  And so I cannot find the ceiling at the moment.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gae6d55db9d1",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "William Taysom",
            "display_name": "wtaysom",
            "team": "T5TCAFTA9",
            "name": "wtaysom",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "J4=U",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So then I'm left wonder if human imagination will be a limiting factor — but then I spend a few minutes seeing what imaginative humans try out.  And so I cannot find the ceiling at the moment."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UCGAK10LS",
        "type": "message",
        "ts": "1679893634.916689",
        "client_msg_id": "fcbc2ea5-4623-490b-877c-19d56bcbad7a",
        "text": "I posted my thoughts on LLMs in a new top-level thread. I'm more optimistic about our jobs than some other folks. I think the future is bright :heart_eyes:.\n\nMaybe we'll need _fewer_ programmers in the future, simply because it will become easier to develop complex software. But alternatively, maybe we'll just make _even more_ complex software, or a larger quantity of software.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6402e9775ed7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-13\/5095853045814_6402e9775ed73b75334f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Q+S4y",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I posted my thoughts on LLMs in a new top-level thread. I'm more optimistic about our jobs than some other folks. I think the future is bright "
                            },
                            {
                                "type": "emoji",
                                "name": "heart_eyes",
                                "unicode": "1f60d"
                            },
                            {
                                "type": "text",
                                "text": ".\n\nMaybe we'll need "
                            },
                            {
                                "type": "text",
                                "text": "fewer",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " programmers in the future, simply because it will become easier to develop complex software. But alternatively, maybe we'll just make "
                            },
                            {
                                "type": "text",
                                "text": "even more",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " complex software, or a larger quantity of software."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01JNTE35QS",
        "type": "message",
        "ts": "1679896042.850529",
        "edited": {
            "user": "U01JNTE35QS",
            "ts": "1679896154.000000"
        },
        "client_msg_id": "d9bc98d3-7235-46d6-a8dd-78e6c7347bd7",
        "text": "I agree with Nick. I also think people underestimate the human side of design and interfaces. A lot of programming is understanding the “what” and more importantly the “why” and then building artifacts that are iterated upon..",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "97155db555c2",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-01-13\/1631845309525_97155db555c2091ecd20_72.jpg",
            "first_name": "",
            "real_name": "Vijay Chakravarthy",
            "display_name": "Vijay Chakravarthy",
            "team": "T5TCAFTA9",
            "name": "vchakrav",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "yp0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I agree with Nick. I also think people underestimate the human side of design and interfaces. A lot of programming is understanding the “what” and more importantly the “why” and then building artifacts that are iterated upon.."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UA14TGLTC",
        "type": "message",
        "ts": "1679896298.612939",
        "client_msg_id": "8f0f8fe3-036c-468a-8b9e-01a49c1ae845",
        "text": "Arguably with \"coding\" (2) assisted\/automated, we can get on to the future part!  Certainly people are playing with (3), getting Chat to output Agda code for example.  But the simple fact is that if \"getting it working\" becomes easier, then we actually give attention to \"get it right.\"   I can also see AI potentially helping with the communication challenges of (4).",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gae6d55db9d1",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "William Taysom",
            "display_name": "wtaysom",
            "team": "T5TCAFTA9",
            "name": "wtaysom",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Q8cY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Arguably with \"coding\" (2) assisted\/automated, we can get on to the future part!  Certainly people are playing with (3), getting Chat to output Agda code for example.  But the simple fact is that if \"getting it working\" becomes easier, then we actually give attention to \"get it right.\"   I can also see AI potentially helping with the communication challenges of (4)."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UCGAK10LS",
                    "U03JUAWDVSR"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "UA14TGLTC",
        "type": "message",
        "ts": "1679896366.253479",
        "client_msg_id": "1b1b57cf-0f8b-4bd9-b0be-26881128a854",
        "text": "Certainly later in my projects, out of a given hour of work, the coding part might amount to 5-10%.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gae6d55db9d1",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "William Taysom",
            "display_name": "wtaysom",
            "team": "T5TCAFTA9",
            "name": "wtaysom",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZXERy",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Certainly later in my projects, out of a given hour of work, the coding part might amount to 5-10%."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UCGAK10LS",
        "type": "message",
        "ts": "1679896811.824169",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1679899023.000000"
        },
        "client_msg_id": "093293c2-033e-4429-a799-29b5f4a72aee",
        "text": "Your mention of Agda has me wanting to define the notion of \"verification\" a little more carefully. (I'm just thinking aloud here.)\n\nAgda and friends are often described as languages for writing \"verified programs\", but that term makes me uncomfortable, because it's prone to be misunderstood. (At the very least, it confused younger me.) No programming language can verify that the functionality a programmer desires has been implemented correctly. No programming language can _ever_ do that. The programmer can always specify a valid program that is different to the one they had _intended_ to specify, and the computer will happily accept it.\n\nThe best you can do is to ask the computer to verify that your program has a _particular_ property, e.g. \"this variable is never null\" or \"this program doesn't crash\". That's a merit of static typing in general.\n\nBut back to your comment: Yes I agree, Agda makes it easier for humans to verify LLM-generated code by reducing the kinds of errors that a program can have. It achieves this by having an expressive type system that can reject a lot of invalid programs. :slightly_smiling_face:\n\n(IMO, Agda's type system is too complicated for the average programmer. But I wholeheartedly believe that developing languages with expressive type systems is a worthy goal.)",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6402e9775ed7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-13\/5095853045814_6402e9775ed73b75334f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RjFkO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Your mention of Agda has me wanting to define the notion of \"verification\" a little more carefully. (I'm just thinking aloud here.)\n\nAgda and friends are often described as languages for writing \"verified programs\", but that term makes me uncomfortable, because it's prone to be misunderstood. (At the very least, it confused younger me.) No programming language can verify that the functionality a programmer desires has been implemented correctly. No programming language can "
                            },
                            {
                                "type": "text",
                                "text": "ever",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " do that. The programmer can always specify a valid program that is different to the one they had "
                            },
                            {
                                "type": "text",
                                "text": "intended",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " to specify, and the computer will happily accept it.\n\nThe best you can do is to ask the computer to verify that your program has a "
                            },
                            {
                                "type": "text",
                                "text": "particular",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " property, e.g. \"this variable is never null\" or \"this program doesn't crash\". That's a merit of static typing in general.\n\nBut back to your comment: Yes I agree, Agda makes it easier for humans to verify LLM-generated code by reducing the kinds of errors that a program can have. It achieves this by having an expressive type system that can reject a lot of invalid programs. "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            },
                            {
                                "type": "text",
                                "text": "\n\n(IMO, Agda's type system is too complicated for the average programmer. But I wholeheartedly believe that developing languages with expressive type systems is a worthy goal.)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0296ACR13M",
        "type": "message",
        "ts": "1679897153.979009",
        "edited": {
            "user": "U0296ACR13M",
            "ts": "1679897885.000000"
        },
        "client_msg_id": "6a34bf5e-303f-4ff0-a86d-119ba55831ef",
        "text": "Most of the software development work is maintaining large codebases and I'd say it's still largely unproven that LLMs can offer much help in these settings. Currently the limiting factors are at least the allowed input sizes and the cost and speed of the queries. It seems that iterating on large codebases would be very slow and difficult. Overtime, it's of course very likely that these issues will be solved, but hard to say if it will take two years or twenty years.\n\nI think LLMs will certainly increase the productivity of software development and therefore make it cheaper. This will lead into software becoming economical in more use cases, so the demand for software will increase. Hard to say how this will balance out with the increase in the supply from the productivity increase. But it could also be that LLMs increase the demand for software developers, which could in turn increase the market opportunity for FoC tools.\n\nAnd as discussed, generating traditional code with LLMs still, at the very least, requires professional programming skills to verify the output. A (good) low\/no-code tool would not.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "59de929720a2",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-09-08\/4075674207584_59de929720a2fe0a13d8_72.jpg",
            "first_name": "",
            "real_name": "Jarno Montonen",
            "display_name": "Jarno Montonen",
            "team": "T5TCAFTA9",
            "name": "jarno.montonen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "b1C",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Most of the software development work is maintaining large codebases and I'd say it's still largely unproven that LLMs can offer much help in these settings. Currently the limiting factors are at least the allowed input sizes and the cost and speed of the queries. It seems that iterating on large codebases would be very slow and difficult. Overtime, it's of course very likely that these issues will be solved, but hard to say if it will take two years or twenty years.\n\nI think LLMs will certainly increase the productivity of software development and therefore make it cheaper. This will lead into software becoming economical in more use cases, so the demand for software will increase. Hard to say how this will balance out with the increase in the supply from the productivity increase. But it could also be that LLMs increase the demand for software developers, which could in turn increase the market opportunity for FoC tools.\n\nAnd as discussed, generating traditional code with LLMs still, at the very least, requires professional programming skills to verify the output. A (good) low\/no-code tool would not."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UCGAK10LS"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U0296ACR13M",
        "type": "message",
        "ts": "1679898374.858229",
        "client_msg_id": "700ef05e-3cb4-44f0-9b4b-0e4ee65e64ac",
        "text": "But of course, if a LLM already performs better in the use case, and for the audience of your foc tool, it's probably a good idea to pivot.. You could still try to compete with price, but it's difficult to say what will the price of LLM queries be in a year.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "59de929720a2",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-09-08\/4075674207584_59de929720a2fe0a13d8_72.jpg",
            "first_name": "",
            "real_name": "Jarno Montonen",
            "display_name": "Jarno Montonen",
            "team": "T5TCAFTA9",
            "name": "jarno.montonen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679892669.316079",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zAa",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "But of course, if a LLM already performs better in the use case, and for the audience of your foc tool, it's probably a good idea to pivot.. You could still try to compete with price, but it's difficult to say what will the price of LLM queries be in a year."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]