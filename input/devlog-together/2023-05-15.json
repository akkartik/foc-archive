[
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1684134194.599299",
        "client_msg_id": "01a0e1be-6af3-4fb5-b7e9-b20ee4d819d5",
        "text": "When parallel computing arrived in scientific computing in the 1990s, there were two main reactions: (1) we need new programming paradigms to exploit these machines and (2) we'll develop automatic parallelization techniques so we can run serial code efficiently. Practitioners went for (1) because that's all they had in actual (but primitive) tools. Theoreticians went for (2) but have yet to deliver. Meaning that practitioners are stuck with the primitive tools that have hardly made progress since the 1990s.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1683907869.328429",
        "parent_user_id": "U02U0AS3J49",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "bBL9R",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "When parallel computing arrived in scientific computing in the 1990s, there were two main reactions: (1) we need new programming paradigms to exploit these machines and (2) we'll develop automatic parallelization techniques so we can run serial code efficiently. Practitioners went for (1) because that's all they had in actual (but primitive) tools. Theoreticians went for (2) but have yet to deliver. Meaning that practitioners are stuck with the primitive tools that have hardly made progress since the 1990s."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UGWUJUZHT",
        "type": "message",
        "ts": "1684188238.127499",
        "client_msg_id": "c69d25c0-1df9-4286-a278-214b3cf7afd5",
        "text": "Operating systems and thread libraries are artefacts of 1950s thinking.  They are based on the meme that “everything must run on a single CPU”.  Developers need preemption while debugging code.  End-users don’t need preemption, but, are forced to pay for it anyway.  In fact, McCarthy showed how to write preemptionless threads in 1956 - anonymous functions (later rigidified into closures).  But, this idea was ignored due to extreme allergies to Lisp and its supposed “interpretation”.  Instead, people built big, honking closures in assembler and C, using the sledge-hammer of preemption to control ad-hoc blocking caused by function calling.  Preemption encourages developers to ship buggy code, a practice that is not tolerated (by Law) in any other kinds of industries.  Shipping buggy code has been further embellished with epicycles such as CI\/CD.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "41a8bada7812",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-06\/4754627914258_41a8bada781281751d07_72.jpg",
            "first_name": "",
            "real_name": "Paul Tarvydas",
            "display_name": "guitarvydas",
            "team": "T5TCAFTA9",
            "name": "paultarvydas",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1683907869.328429",
        "parent_user_id": "U02U0AS3J49",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6H1",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Operating systems and thread libraries are artefacts of 1950s thinking.  They are based on the meme that “everything must run on a single CPU”.  Developers need preemption while debugging code.  End-users don’t need preemption, but, are forced to pay for it anyway.  In fact, McCarthy showed how to write preemptionless threads in 1956 - anonymous functions (later rigidified into closures).  But, this idea was ignored due to extreme allergies to Lisp and its supposed “interpretation”.  Instead, people built big, honking closures in assembler and C, using the sledge-hammer of preemption to control ad-hoc blocking caused by function calling.  Preemption encourages developers to ship buggy code, a practice that is not tolerated (by Law) in any other kinds of industries.  Shipping buggy code has been further embellished with epicycles such as CI\/CD."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UGWUJUZHT",
        "type": "message",
        "ts": "1684188328.579619",
        "client_msg_id": "8e6d6f00-4cb0-4db3-8a49-372a2fd3d6e5",
        "text": "Today, hardware efficiency matters a whole lot less than it did in the 1950s, except to people indoctrinated to believe that there is only one kind of efficiency.  There’s hardware efficiency, Design time efficiency, Production Engineering efficiency, Implementation time efficiency, etc., etc.\n\nAttempts at automatic parallelization will never succeed because:\n1. a specific solution will always be more “efficient” than a generalized solution (N.B. “efficiency” comes in more than one flavour) and\n2. efforts at automated parallelization are based on towers of epicycles which are based on 1950s memes.\nPreemptionless threading cuts out a lot of bloatware and hardware-supported inefficiency (it costs time to preempt a running process).  More recently, Tunney built Sector Lisp in a very pure functional style resulting in a full language in less than 512 bytes[sic], then built an even smaller language (BLC - Binary Lambda Calculus). Reducing the number of types helps a lot, too. Lambda calculus means that “everything is a function that takes exactly one input and produces exactly one output”, regardless of how you wish to spin the inner structuring of input data and output data using destructuring.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "41a8bada7812",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-06\/4754627914258_41a8bada781281751d07_72.jpg",
            "first_name": "",
            "real_name": "Paul Tarvydas",
            "display_name": "guitarvydas",
            "team": "T5TCAFTA9",
            "name": "paultarvydas",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1683907869.328429",
        "parent_user_id": "U02U0AS3J49",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "\/AXR",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Today, hardware efficiency matters a whole lot less than it did in the 1950s, except to people indoctrinated to believe that there is only one kind of efficiency.  There’s hardware efficiency, Design time efficiency, Production Engineering efficiency, Implementation time efficiency, etc., etc.\n\nAttempts at automatic parallelization will never succeed because:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "a specific solution will always be more “efficient” than a generalized solution (N.B. “efficiency” comes in more than one flavour) and"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "efforts at automated parallelization are based on towers of epicycles which are based on 1950s memes."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nPreemptionless threading cuts out a lot of bloatware and hardware-supported inefficiency (it costs time to preempt a running process).  More recently, Tunney built Sector Lisp in a very pure functional style resulting in a full language in less than 512 bytes[sic], then built an even smaller language (BLC - Binary Lambda Calculus). Reducing the number of types helps a lot, too. Lambda calculus means that “everything is a function that takes exactly one input and produces exactly one output”, regardless of how you wish to spin the inner structuring of input data and output data using destructuring."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]