<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #thinking-together</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <img src="https://avatars.slack-edge.com/2019-10-28/811814014976_259a1e56ad2e11fe3d56_72.jpg" style="float:left"/>
      <a href="../thinking-together/1609935940.429300.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Shubhadeep Roychowdhury</b>
<span style="margin:2em; color:#606060">2021-01-06 04:25</span><br/>
My critique on DALL.E (The new text to image models from OpenAI) -<br/><br/><a href="https://www.linkedin.com/posts/shubhadeep-roychowdhury_right-openai-dalle-happened-my-whole-social-activity-6752552570746744832-vnIJ">https://www.linkedin.com/posts/shubhadeep-roychowdhury_right&hellip;</a><br/><br/>Any thoughts are welcome!
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1609980915.444800"></a>
      <img src="https://avatars.slack-edge.com/2019-09-26/774747080560_0edf98a60210d3ab07ea_72.jpg" style="float:left"/>
      <a href="../thinking-together/1609935940.429300.html#1609980915.444800" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Scott Anderson</b>
<span style="margin:2em; color:#606060">2021-01-06 16:55</span><br/>
Solid critique.  I'm not sure if all the criticism of these large transformer models being basically impossible to train will stop them from happening because now it could be a <b>huge</b> competitive advantage for entrenched tech companies
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1609980982.445000"></a>
      <img src="https://avatars.slack-edge.com/2019-09-26/774747080560_0edf98a60210d3ab07ea_72.jpg" style="float:left"/>
      <a href="../thinking-together/1609935940.429300.html#1609980982.445000" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Scott Anderson</b>
<span style="margin:2em; color:#606060">2021-01-06 16:56</span><br/>
especially now that selling cloud services is all the rage.  There is big economic incentive to have powerful models hidden behind cloud services and sold
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1609981016.445200"></a>
      <img src="https://avatars.slack-edge.com/2019-09-26/774747080560_0edf98a60210d3ab07ea_72.jpg" style="float:left"/>
      <a href="../thinking-together/1609935940.429300.html#1609981016.445200" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Scott Anderson</b>
<span style="margin:2em; color:#606060">2021-01-06 16:56</span><br/>
It would be nice if they published full papers + released source + documented the hardware required to train these models
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1609981060.445400"></a>
      <img src="https://avatars.slack-edge.com/2019-09-26/774747080560_0edf98a60210d3ab07ea_72.jpg" style="float:left"/>
      <a href="../thinking-together/1609935940.429300.html#1609981060.445400" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Scott Anderson</b>
<span style="margin:2em; color:#606060">2021-01-06 16:57</span><br/>
so even if it cost like ~$5M to train one of these, theoretically it could be reproduced
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1609981074.445600"></a>
      <img src="https://avatars.slack-edge.com/2019-09-26/774747080560_0edf98a60210d3ab07ea_72.jpg" style="float:left"/>
      <a href="../thinking-together/1609935940.429300.html#1609981074.445600" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Scott Anderson</b>
<span style="margin:2em; color:#606060">2021-01-06 16:57</span><br/>
even for future generations that might have similar compute in a more accessible factor
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1610004383.445800"></a>
      <img src="https://secure.gravatar.com/avatar/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png" style="float:left"/>
      <a href="../thinking-together/1609935940.429300.html#1610004383.445800" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>William Taysom</b>
<span style="margin:2em; color:#606060">2021-01-06 23:26</span><br/>
Will the price go down though?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1610008710.446000"></a>
      <img src="https://avatars.slack-edge.com/2019-10-28/811814014976_259a1e56ad2e11fe3d56_72.jpg" style="float:left"/>
      <a href="../thinking-together/1609935940.429300.html#1610008710.446000" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Shubhadeep Roychowdhury</b>
<span style="margin:2em; color:#606060">2021-01-07 00:38</span><br/>
It is already happening. OpenAI never published their model of GPT-3 and instead selling an "API" access to people. Watson, AzureAI etc had been doing that for long. We should expect companies like DeepMind follow suit as well.<br/><br/>Here is the funny thing(according to me), it is a (somewhat) vicious circle.<br/><br/>Big Company with money -&gt; Can train big model -&gt; Can put hundreds of dollars in compute and marketing alike -&gt; Can bring media, money, attention -&gt; Bigger company -&gt; Can train bigger model...<br/><br/>Rinse and Repeat.<br/><br/>At least that is how I see it. And for that really important topics, such as Neuro Symbolic (or otherwise) models which can become really data efficient, Ethics in AI, Explainability and Interpretability, Alternative computing models for intelligence (apart form RL) etc. are never really surfacing. The reason being the circle I mentioned above.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1610014202.446200"></a>
      <img src="https://avatars.slack-edge.com/2019-10-28/811814014976_259a1e56ad2e11fe3d56_72.jpg" style="float:left"/>
      <a href="../thinking-together/1609935940.429300.html#1610014202.446200" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Shubhadeep Roychowdhury</b>
<span style="margin:2em; color:#606060">2021-01-07 02:10</span><br/>
Also let's. not forget wordseye (<a href="https://www.wordseye.com/">https://www.wordseye.com/</a>) which does the same (often much better) and predates DL.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1610386856.496500"></a>
      <img src="https://avatars.slack-edge.com/2019-12-20/882734188373_75bc4f5fbeedc5a2213e_72.jpg" style="float:left"/>
      <a href="../thinking-together/1609935940.429300.html#1610386856.496500" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Max Krieger</b>
<span style="margin:2em; color:#606060">2021-01-11 09:40</span><br/>
with regard to point #3, you realize all the permutations are pre-cached right? that's why it's not free form - it's too expensive to give an open endpoint to anyone.
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
