[
    {
        "user": "UBN9AFS0N",
        "type": "message",
        "ts": "1715940468.296629",
        "client_msg_id": "a7b2fe99-446c-4abb-86ac-0feb0650e7ef",
        "text": "&gt; &lt;https:\/\/higherorderco.com\/\n&gt; |Bend: a parallel language&gt;\n&gt; With *Bend* you can write parallel code for multi-core CPUs\/GPUs without being a C\/CUDA expert with 10 years of experience. It feels just like Python!\n&gt; No need to deal with the complexity of concurrent programming: locks, mutexes, atomics... *any* work that can be done in parallel *will* be done in parallel.\n<https:\/\/twitter.com\/VictorTaelin\/status\/1791213162525524076|Twitter announcement (includes a short video demo)>\n\n&gt; After almost 10 years of hard work, tireless research, and a dive deep into the kernels of computer science, I finally realized a dream: running a high-level language on GPUs. And I'm giving it to the world! Bend compiles modern programming features, including: \n&gt; - Lambdas with full closure support \n&gt; - Unrestricted recursion and loops \n&gt; - Fast object allocations of all kinds \n&gt; - Folds, ADTs, continuations and much more \n&gt; To HVM2, a new runtime capable of spreading that workload across 1000's of cores, in a thread-safe, low-overhead fashion. As a result, we finally have a true high-level language that runs natively on GPUs!\n",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "7f0f1c0238ec",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-07-09\/395086754178_7f0f1c0238ec02befdab_72.jpg",
            "first_name": "Mariano",
            "real_name": "Mariano Guerra",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "mariano",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1715940468.296629",
        "reply_count": 3,
        "reply_users_count": 3,
        "latest_reply": "1716092529.829259",
        "reply_users": [
            "U04R5PP8M28",
            "U05TJD2V4P2",
            "U03U0SCU5LH"
        ],
        "replies": [
            {
                "user": "U04R5PP8M28",
                "ts": "1715941723.897459"
            },
            {
                "user": "U05TJD2V4P2",
                "ts": "1715962270.672149"
            },
            {
                "user": "U03U0SCU5LH",
                "ts": "1716092529.829259"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uX7aP",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https:\/\/higherorderco.com\/\n",
                                "text": "Bend: a parallel language"
                            },
                            {
                                "type": "text",
                                "text": "\nWith "
                            },
                            {
                                "type": "text",
                                "text": "Bend",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " you can write parallel code for multi-core CPUs\/GPUs without being a C\/CUDA expert with 10 years of experience. It feels just like Python!\nNo need to deal with the complexity of concurrent programming: locks, mutexes, atomics... "
                            },
                            {
                                "type": "text",
                                "text": "any",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " work that can be done in parallel "
                            },
                            {
                                "type": "text",
                                "text": "will ",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "be done in parallel."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/twitter.com\/VictorTaelin\/status\/1791213162525524076",
                                "text": "Twitter announcement (includes a short video demo)"
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "After almost 10 years of hard work, tireless research, and a dive deep into the kernels of computer science, I finally realized a dream: running a high-level language on GPUs. And I'm giving it to the world! Bend compiles modern programming features, including: \n- Lambdas with full closure support \n- Unrestricted recursion and loops \n- Fast object allocations of all kinds \n- Folds, ADTs, continuations and much more \nTo HVM2, a new runtime capable of spreading that workload across 1000's of cores, in a thread-safe, low-overhead fashion. As a result, we finally have a true high-level language that runs natively on GPUs!"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": []
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "guitar",
                "users": [
                    "U02JQA5FY5C"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U04R5PP8M28",
        "type": "message",
        "ts": "1715941723.897459",
        "client_msg_id": "B0054C6A-B046-4A2F-B176-74424CDBEED1",
        "text": "I am really curious how they want to integrate it with the rest of the AI stack. ",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "d05472b9a7ac",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-05-09\/7093155202723_d05472b9a7ac6222ce35_72.png",
            "first_name": "Nicolay",
            "real_name": "Nicolay Gerold",
            "display_name": "Nicolay Gerold",
            "team": "T5TCAFTA9",
            "name": "nicolay.gerold",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1715940468.296629",
        "parent_user_id": "UBN9AFS0N",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MEJIG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I am really curious how they want to integrate it with the rest of the AI stack. "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UMQ6LR9NZ",
        "type": "message",
        "ts": "1715951062.588399",
        "client_msg_id": "838a9652-7df9-40d6-aa71-90f3e427b21c",
        "text": "Once upon a time somewhere here, lost to the sands of a freemium slack instance, I shared a link about research some friends of mine were doing through the developer success lab on code review anxiety. <https:\/\/developer-success-lab.gitbook.io\/code-review-anxiety-workbook-1|Today they published the workbook that they produced from that research! >",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf70d12f2630",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f70d12f2630b6c2a0854e3bef118e73c.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0020-72.png",
            "first_name": "Eli",
            "real_name": "Eli Mellen",
            "display_name": "Eli",
            "team": "T5TCAFTA9",
            "name": "eli.mellen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1715951062.588399",
        "reply_count": 1,
        "reply_users_count": 1,
        "latest_reply": "1716169471.965309",
        "reply_users": [
            "UC2A2ARPT"
        ],
        "replies": [
            {
                "user": "UC2A2ARPT",
                "ts": "1716169471.965309"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "wgsLE",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Once upon a time somewhere here, lost to the sands of a freemium slack instance, I shared a link about research some friends of mine were doing through the developer success lab on code review anxiety. "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/developer-success-lab.gitbook.io\/code-review-anxiety-workbook-1",
                                "text": "Today they published the workbook that they produced from that research! "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05TJD2V4P2",
        "type": "message",
        "ts": "1715962270.672149",
        "edited": {
            "user": "U05TJD2V4P2",
            "ts": "1715963555.000000"
        },
        "client_msg_id": "1eab68a7-fa63-4675-b9f1-aa09935968f4",
        "text": "In my experience with CUDA, you really have to be paying attention to hardware details like thread block size, banked memory layout and access patterns. I’m not sure if what I learned is still up to date, but don’t cache misses cause sequential processing?\n\nI really like the idea behind their system, I’d love to learn more about their GPU runtime in particular though. In my experience I was very grateful for C & CUDA, do others agree? Though at times I felt that even they were too high level.\n\nEDIT: This comment feels a bit pessimistic, it’s very cool, and I’m sure a large group could benefit from this.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "c62c43b01fd5",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-09-18\/5926088433521_c62c43b01fd5b63ec214_72.jpg",
            "first_name": "Jacob",
            "real_name": "Jacob Zimmerman",
            "display_name": "Jacob Zimmerman",
            "team": "T5TCAFTA9",
            "name": "jacob.zimmerman135",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1715940468.296629",
        "parent_user_id": "UBN9AFS0N",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "iOnVp",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In my experience with CUDA, you really have to be paying attention to hardware details like thread block size, banked memory layout and access patterns. I’m not sure if what I learned is still up to date, but don’t cache misses cause sequential processing?\n\nI really like the idea behind their system, I’d love to learn more about their GPU runtime in particular though. In my experience I was very grateful for C & CUDA, do others agree? Though at times I felt that even they were too high level.\n\nEDIT: This comment feels a bit pessimistic, it’s very cool, and I’m sure a large group could benefit from this."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]