<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #thinking-together</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <img src="https://avatars.slack-edge.com/2023-04-13/5095853045814_6402e9775ed73b75334f_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nick Smith</b>
<span style="margin:2em; color:#606060">2021-06-23 01:32</span><br/>
All modern programming languages apart from Rust (and I guess Swift, with its reference-counting) rely on garbage collection: a "background thread" locates memory the process has <em>forgotten about</em> and marks it as available for re-use. However, this doesn't seem to be a sensible scheme in a distributed system where multiple processing devices each have local memories. That begs the question: if you want to design a programming language that can be transparently distributed over multiple devices, does it need to have a fancy type system (like Rust's) that enforces correct manual memory management?<br/><br/>One reason I'm thinking about this: most upcoming AI chips are using a "network-on-chip" architecture, which could also be called a "distributed system on a chip". A garbage collection algorithm on these chips would have to involve a message-passing protocol wherein different parts of the chip communicate to identify <em>forgotten</em> memory. This seems like an unnecessarily complicated and expensive approach to memory management.<br/><br/>Thoughts? :unicorn_face:
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624441675.148100"></a>
      <img src="https://avatars.slack-edge.com/2017-08-20/228447816352_649181907e06ec450c64_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624441675.148100" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Stefan Lesser</b>
<span style="margin:2em; color:#606060">2021-06-23 02:47</span><br/>
Like the sentiment and think Rust and Swift are on a better path, mainly because they manage memory deterministically, but if people don't find garbage collection wasteful today in basic single-threaded CPU-bound scenarios, I doubt it'll stop anybody from bringing it to a distributed environment.<br/><br/>Classic garbage collection makes a lot of sense for a simpler, centralized memory model, like a heap. I don't know how to adapt it to a massively parallel execution environment, but I'm sure it can be done somehow, likely involving an order-of-magnitude increase in (wasted) memory along the way, but it'll be much more convenient to use I'm sure.<br/><br/>I don't know much about "AI chips", but if they are optimizing for parallel execution and work anything like modern GPUs they probably already manage memory quite differently from CPUs with explicit descriptors (a form of type system), buffer hierarchies, and thread grouping with localized access to buffers. That way memory gets bound to certain computations (shaders) and freed once these computations are finished. Well, it's a little more complex as these are subdivided into workgroups, thread groups, and subgroups, but you'll get the idea.<br/><br/>If you squint your eyes you might see some parallels to Rust's ownership model and why deterministic memory management is so attractive, even in languages that mainly target CPUs. The future is more value (move/copy) and fewer reference semantics ("objects") with clear ownership to help avoid, or at least minimize, shared state, so we can reap the benefits of parallel processing. That's a promising approach to keep complexity in check, even though it might not quite feel like that yet when you're trying to configure a shader execution pipeline today.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624451568.148300"></a>
      <img src="https://avatars.slack-edge.com/2018-07-09/395086754178_7f0f1c0238ec02befdab_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624451568.148300" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Mariano Guerra</b>
<span style="margin:2em; color:#606060">2021-06-23 05:32</span><br/>
Pony's Garbage Collection sounds the closest I can think of: <a href="https://tutorial.ponylang.io/appendices/garbage-collection.html">https://tutorial.ponylang.io/appendices/garbage-collection.html</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624451663.148500"></a>
      <img src="https://avatars.slack-edge.com/2018-07-09/395086754178_7f0f1c0238ec02befdab_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624451663.148500" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Mariano Guerra</b>
<span style="margin:2em; color:#606060">2021-06-23 05:34</span><br/>
There are some papers and talks about it
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624457980.148800"></a>
      <img src="https://avatars.slack-edge.com/2021-02-28/1803506076818_0566a74707e4edb4ea8a_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624457980.148800" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Deech</b>
<span style="margin:2em; color:#606060">2021-06-23 07:19</span><br/>
Nim &amp; ATS do this as well.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624463680.149000"></a>
      <img src="https://secure.gravatar.com/avatar/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624463680.149000" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>William Taysom</b>
<span style="margin:2em; color:#606060">2021-06-23 08:54</span><br/>
In my limited (yet significant) experience making a distributed system, the challenge wasn't so much garbage as ferrying relevant partial results between compute nodes.  So an ownership model may match bandwidth constraints better than potentially costly deferences.<br/><br/>I guess it's an eager/lazy distinction.  I mean GC is certainly a performance win if you never need to actually collect it.  Granularity matters.  A lot of programs operate in a sort of loop with a lot of objects allocated per frame or per request.  So then it makes sense to have an allocator that only tracks when references cross the boundary.  Squint and you can think of that as an eager generational collector.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624473008.149300"></a>
      <img src="https://secure.gravatar.com/avatar/bc3e6041047849518d1b042f0a29d5af.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0020-72.png" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624473008.149300" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>S.M Mukarram Nainar</b>
<span style="margin:2em; color:#606060">2021-06-23 11:30</span><br/>
I'm not sure I understand the problem—you can have actor-local heaps and run gc independently while communicating via message-passing. Erlang does this
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624496233.149800"></a>
      <img src="https://avatars.slack-edge.com/2023-04-13/5095853045814_6402e9775ed73b75334f_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624496233.149800" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nick Smith</b>
<span style="margin:2em; color:#606060">2021-06-23 17:57</span><br/>
<span style="background-color:#ccf">@S.M Mukarram Nainar</span> That's a solution if your programming model is the actor model. By "transparent distribution" I mean something more implicit: your programming language doesn't have a means to talk about "nodes" and "messages", so there are no clear boundaries for a garbage collector.<br/><br/>Note that in Erlang, you essentially have automatic memory management (GC) <em>within</em> an actor, and manual memory management <em>between</em> actors. If you have an actor that is holding data that will later be queried by other actors, you need to know when it is safe to delete the data (or even the entire actor), i.e. you need to know when other actors are no longer holding "references" to it (of some kind).<br/><br/>It seems like Pony has an approach for inter-actor memory management. Thanks <span style="background-color:#ccf">@Mariano Guerra</span> for the link. Though as I said before, the distribution model is still not quite as implicit as I had in mind :slightly_smiling_face:. I don't think you want to program a 1000-core AI chip with the actor model. ML models don't want to be written as actor systems, and general-purpose programs even less-so.<br/><br/>I'm bringing up AI chips because some of them will be capable of running general-purpose programs. Think of them as the next step beyond GPGPU. <a href="https://www.tenstorrent.com/">Tenstorrent</a> is an example. From their FAQ:<br/>• "Our computers are optimized for neural network inference and training. They can also execute other types of parallel computation."<br/>• "Network communication hardware is present in each processor, and they talk with one another directly over (on-chip) networks, instead of through DRAM."<br/>• [Compared to GPUs] "Our computers are easier to program, scale better, and are excellent at handling run-time sparsity and conditional computation."<br/>Hopefully that answers your question <span style="background-color:#ccf">@Stefan Lesser</span>: the programming model is very different to that of GPUs.<br/><br/>Note the irony that Tenstorrent's chips are an actor model at the hardware level, yet you're unlikely to want to program them using the actor model because of the sheer number of cores. What is our programming model for these machines? As stated in my original post, I think memory management needs to be explicit in the language (Rust-style), because you don't want all 1000+ cores to be running a distributed garbage collection scheme alongside the primary computation. It becomes less and less feasible the more cores you add. Tenstorrent is planning to have their chips plug directly together using high-bandwidth &amp; low-latency interconnects so that you can have 100,000 cores or more. Imagine running a garbage collector on that. Seems very much the wrong direction to go in.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624518279.165800"></a>
      <img src="https://avatars.slack-edge.com/2017-08-20/228447816352_649181907e06ec450c64_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624518279.165800" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Stefan Lesser</b>
<span style="margin:2em; color:#606060">2021-06-24 00:04</span><br/>
<span style="background-color:#ccf">@Nick Smith</span> Oh, interesting! Do you have any other pointers to more technical resources from them or about other “AI chips”? Their FAQ isn’t going very deep and the website strikes me as very marketing/VC oriented.<br/><br/>I don’t get the sense that their programming model is “very different” to that of GPUs, more like they’re building on top of that model, but maybe that’s what you mean? And they clearly know about what makes GPU programming complicated and try to differentiate themselves from it — I’m vary of their marketing lingo…<br/><br/>As they mention PyTorch one way to leverage multiple independent units could be <a href="https://pytorch.org/docs/stable/notes/ddp.html">https://pytorch.org/docs/stable/notes/ddp.html</a>.<br/><br/>This also points towards things like <a href="https://mlir.llvm.org/">https://mlir.llvm.org/</a>. In other words, more power to the compiler (and yes, fancy type systems)! :) 
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624541626.166500"></a>
      <img src="https://avatars.slack-edge.com/2021-06-21/2186437719222_d0f48a5cbd367fc3a50b_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624541626.166500" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>dnmfarrell</b>
<span style="margin:2em; color:#606060">2021-06-24 06:33</span><br/>
Do you have an example application in mind? For instance if you want a generally responsive language, memory use efficiency, perhaps some convenience routines for objects going out of scope (e.g. automatic closing of file descriptors, sockets), predictable runtime and memory use, then reference counting seems like a better fit. OTOH:: scope exit becomes slower, and is potentially unbounded (imagine reclaiming a giant graph of data), overall runtime is higher because of all the accounting busywork and cpu cache disruption (can be as much as ~30% slower but it's complicated), and concurrency becomes harder: child processes will trigger copy on write (you can minimize the impact by storing the refcount in a small object header and storing all headers in a contiguous memory block), refcounts are also a contention issue for POSIX threads.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624545723.167300"></a>
      <img src="https://avatars.slack-edge.com/2023-10-13/6057269405632_8ea58fc41bd6baa7dda6_72.png" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624545723.167300" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jack Rusher</b>
<span style="margin:2em; color:#606060">2021-06-24 07:42</span><br/>
You might want to read up on the various languages designed for the <a href="https://en.wikipedia.org/wiki/Thinking_Machines_Corporation">Thinking Machines</a> CM series, including *Lisp and CM Lisp. I worked on one of these with 768 cores, but the top models had 65,000+ cores running in a parallel machine with perfectly pleasant high level language support.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624575554.167800"></a>
      <img src="https://avatars.slack-edge.com/2023-04-13/5095853045814_6402e9775ed73b75334f_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624575554.167800" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nick Smith</b>
<span style="margin:2em; color:#606060">2021-06-24 15:59</span><br/>
<span style="background-color:#ccf">@Stefan Lesser</span> There are some interviews and videos of Tenstorrent online. Here's a recent one <a href="https://www.anandtech.com/show/16709/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller">with Anandtech</a>. Here's a long <a href="https://www.youtube.com/watch?v=G4hL5Om4IJ4">podcast episode with the CTO</a> where he talks about a bunch of computing-related stuff, including hardware architectures for AI. Here's <a href="https://www.youtube.com/watch?v=Uls3-UWm-sY">a short technical presentation</a> on how their chips work.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624576469.168200"></a>
      <img src="https://avatars.slack-edge.com/2023-04-13/5095853045814_6402e9775ed73b75334f_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624576469.168200" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nick Smith</b>
<span style="margin:2em; color:#606060">2021-06-24 16:14</span><br/>
<span style="background-color:#ccf">@dnmfarrell</span> You're mentioning a lot of issues on conventional hardware architectures (cache and thread contention) and sure, there are some trade-offs when choosing between reference counting and tracing GCs in that context. But I'm focusing more on massively-parallel architectures, which I think changes the rules a bit. For example, Tenstorrent's chips have no shared memory, no caches, and no threads. Instead they have a grid of compute units, each with a dedicated SRAM (not a cache) and capable of doing parallel matrix/tensor operations. This is my "application" if you like: writing programs that can run on this type of machine. Why? Because they're going to offer up 100x the compute power of CPUs and are more suited to heterogeneous workloads than GPUs. From what I can see, they have a chance at obsoleting the whole idea of a CPU, as long as we can program them. There is insane amounts of money pouring into these companies (for their applications to AI), and some of these chips are going to become widely-deployed in data centers and (eventually) consumer devices.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624576618.168400"></a>
      <img src="https://avatars.slack-edge.com/2023-04-13/5095853045814_6402e9775ed73b75334f_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624576618.168400" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nick Smith</b>
<span style="margin:2em; color:#606060">2021-06-24 16:16</span><br/>
<span style="background-color:#ccf">@Jack Rusher</span> I'll look them up, thank you :slightly_smiling_face:
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624746824.171400"></a>
      <img src="https://avatars.slack-edge.com/2021-04-01/1917217507589_450fb2024c928cead6b9_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624746824.171400" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Andrew Martin</b>
<span style="margin:2em; color:#606060">2021-06-26 15:33</span><br/>
<span style="background-color:#ccf">@Nick Smith</span> fyi the successor to Pony is a microsoft research project called "Project Verona". I think it's one of the most interesting research projects in the more traditional PL world right now. It might not be what you're looking for but I think the heap model it uses is a lot more generalised and flexible than the actor model.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624747117.171600"></a>
      <img src="https://avatars.slack-edge.com/2021-04-01/1917217507589_450fb2024c928cead6b9_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624747117.171600" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Andrew Martin</b>
<span style="margin:2em; color:#606060">2021-06-26 15:38</span><br/>
<a href="https://www.microsoft.com/en-us/research/project/project-verona/">https://www.microsoft.com/en-us/research/project/project-verona/</a><br/><br/>there's not much information up yet, but i think there are some talks explaining the memory model a bit, if you're interested.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624747824.171900"></a>
      <img src="https://avatars.slack-edge.com/2021-04-01/1917217507589_450fb2024c928cead6b9_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624747824.171900" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Andrew Martin</b>
<span style="margin:2em; color:#606060">2021-06-26 15:50</span><br/>
in reference to your original question, I would say that both Pony and Verona have type systems that are comparable to Rust's in fanciness (they also rely on concepts like linearity), but they aim to find a sweet spot in usability by permitting a more free-form programming style within regions.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624839859.172200"></a>
      <img src="https://avatars.slack-edge.com/2020-09-21/1361648344759_467eec5533b7281db15a_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624839859.172200" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Tom Hutchinson</b>
<span style="margin:2em; color:#606060">2021-06-27 17:24</span><br/>
Some other resources:<br/><br/>The Electric Communities Distributed Garbage Collector<br/><a href="http://erights.org/history/original-e/dgc/">http://erights.org/history/original-e/dgc/</a><br/><br/>Garbage collecting the Internet: a survey of distributed garbage collection<br/><a href="https://dl.acm.org/doi/10.1145/292469.292471">https://dl.acm.org/doi/10.1145/292469.292471</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1624849230.172400"></a>
      <img src="https://avatars.slack-edge.com/2023-04-13/5095853045814_6402e9775ed73b75334f_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1624849230.172400" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nick Smith</b>
<span style="margin:2em; color:#606060">2021-06-27 20:00</span><br/>
Thanks <span style="background-color:#ccf">@Andrew Martin</span>. I should definitely think more about region-based memory management and whether there's something "special" there.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1625727819.193300"></a>
      <img src="https://avatars.slack-edge.com/2021-07-07/2254853369060_d6900487d9109f495c79_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1625727819.193300" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Alexander Chichigin</b>
<span style="margin:2em; color:#606060">2021-07-08 00:03</span><br/>
<span style="background-color:#ccf">@Nick Smith</span> hi! I'm sorry but I lost the thread of the argument a little... :slightly_smiling_face:<br/><br/>You started asking about distributed GC, but then you write:<br/>&gt; Tenstorrent's chips have no shared memory, no caches, and no threads. Instead they have a grid of compute units, each with a dedicated SRAM (not a cache) and capable of doing parallel matrix/tensor operations.<br/>If you don't have shared memory, you don't need and can't actually have a distributed GC. You're left with "Erlang-style" per-thread (or per-core) separate GCs and memory copying between threads.<br/><br/>Then what's the problem? :slightly_smiling_face:
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1625733652.193900"></a>
      <img src="https://avatars.slack-edge.com/2023-04-13/5095853045814_6402e9775ed73b75334f_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1625733652.193900" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nick Smith</b>
<span style="margin:2em; color:#606060">2021-07-08 01:40</span><br/>
The concepts of "memory safety" and "garbage" are mostly independent of a system's memory model. Computer A can depend upon data located in the memory of computer B, and if so, computer B must not de-allocate that memory (else the system will not function correctly). Alternately, computer B may have a memory allocation that no computer will ever use again, in which case the memory should be de-allocated (else the system will consume unnecessary resources).
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1625737221.194100"></a>
      <img src="https://avatars.slack-edge.com/2021-07-07/2254853369060_d6900487d9109f495c79_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1625737221.194100" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Alexander Chichigin</b>
<span style="margin:2em; color:#606060">2021-07-08 02:40</span><br/>
I'm pretty sure "memory safety" and "garbage" are completely dependent on (at least) <em>language</em> memory model. Without Remote Direct Memory Access "Computer A" <em>can not</em> physically depend on memory of "Computer B". Or you have very abstract notion of "dependence". :slightly_smiling_face:<br/><br/>Anyway, I vaguely remember hearing about the same problem of "distributed garbage collection" in a context of distributed file systems and operating systems. The solution AFAIR was to move objects to the node with the largest number of references to the object. First, it should improve performance, but in the end the object will end up on the node that holds the last reference to it, so the node will delete it when it no longer needed. I don't have references to relevant research but maybe it will give you some food for thought anyway?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1625737680.199100"></a>
      <img src="https://avatars.slack-edge.com/2023-04-13/5095853045814_6402e9775ed73b75334f_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1625737680.199100" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nick Smith</b>
<span style="margin:2em; color:#606060">2021-07-08 02:48</span><br/>
If computer A sends a query message to computer B, and computer B sends a reply message whose contents are dependent on B’s memory, then computer A depends on computer B’s memory.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1625737778.201400"></a>
      <img src="https://avatars.slack-edge.com/2023-04-13/5095853045814_6402e9775ed73b75334f_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1625737778.201400" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nick Smith</b>
<span style="margin:2em; color:#606060">2021-07-08 02:49</span><br/>
If B responds with an error message then you do not have a memory safe system. If B holds data that nobody will ever query (e.g. because nobody knows the UUID or URL) then you have garbage.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1625738442.201600"></a>
      <img src="https://avatars.slack-edge.com/2021-07-07/2254853369060_d6900487d9109f495c79_72.jpg" style="float:left"/>
      <a href="../thinking-together/1624437161.147900.html#1625738442.201600" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Alexander Chichigin</b>
<span style="margin:2em; color:#606060">2021-07-08 03:00</span><br/>
When you say "memory" I think about RAM and that "memory pressure" can be alleviated by dumping rarely requested data to files as many memory caching systems do. If you include file storage into "memory" then yeah, but storage is pretty huge and pretty cheap nowadays, we can store almost everything almost forever... :slightly_smiling_face:
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
