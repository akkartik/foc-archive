[
    {
        "subtype": "channel_join",
        "user": "UGWUJUZHT",
        "text": "<@UGWUJUZHT> has joined the channel",
        "type": "message",
        "ts": "1680042150.081819"
    },
    {
        "subtype": "channel_join",
        "user": "U6KQ2S410",
        "text": "<@U6KQ2S410> has joined the channel",
        "type": "message",
        "ts": "1680042274.099919"
    },
    {
        "subtype": "channel_join",
        "user": "U04V9BQBQCW",
        "text": "<@U04V9BQBQCW> has joined the channel",
        "type": "message",
        "ts": "1680042313.391499"
    },
    {
        "subtype": "channel_join",
        "user": "UCGAK10LS",
        "text": "<@UCGAK10LS> has joined the channel",
        "type": "message",
        "ts": "1680042726.643859"
    },
    {
        "subtype": "channel_join",
        "user": "UE6EFEPTQ",
        "text": "<@UE6EFEPTQ> has joined the channel",
        "type": "message",
        "ts": "1680042817.161779"
    },
    {
        "subtype": "channel_join",
        "user": "U050QMQ4KJP",
        "text": "<@U050QMQ4KJP> has joined the channel",
        "type": "message",
        "ts": "1680043119.247049"
    },
    {
        "subtype": "channel_join",
        "user": "UFPRPSA4S",
        "text": "<@UFPRPSA4S> has joined the channel",
        "type": "message",
        "ts": "1680043169.841029"
    },
    {
        "user": "UE6EFEPTQ",
        "type": "message",
        "ts": "1680043207.098919",
        "client_msg_id": "831ee2ee-84af-4d34-a264-1e72da936283",
        "text": "Some links to threads I pulled together,  won't be complete of course:\n\n<https:\/\/futureofcoding.slack.com\/archives\/CLYCGTCPL\/p1679833469621219>\n<https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679642239661619>\n<https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679902227016569>\n<https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679892669316079>",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "8073c43d5d8d",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-12-18\/508431502471_8073c43d5d8dd3d3b4b2_72.jpg",
            "first_name": "Duncan",
            "real_name": "Duncan Cragg",
            "display_name": "Duncan Cragg",
            "team": "T5TCAFTA9",
            "name": "fp",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "attachments": [
            {
                "from_url": "https:\/\/futureofcoding.slack.com\/archives\/CLYCGTCPL\/p1679833469621219",
                "ts": "1679833469.621219",
                "author_id": "UE6EFEPTQ",
                "channel_id": "CLYCGTCPL",
                "channel_team": "T5TCAFTA9",
                "is_msg_unfurl": true,
                "is_thread_root_unfurl": true,
                "message_blocks": [
                    {
                        "team": "T5TCAFTA9",
                        "channel": "CLYCGTCPL",
                        "ts": "1679833469.621219",
                        "message": {
                            "blocks": [
                                {
                                    "type": "rich_text",
                                    "block_id": "IqTR+",
                                    "elements": [
                                        {
                                            "type": "rich_text_section",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "So, I'm an EUP person at heart, and this ChatGPT thing has obviously got me thinking all over again about what programming would look like to a non-technical person. At heart, I feel it should be like they're \"casting spells\" over reality (or virtual reality). This tips into the area of cognitive modelling: how close the physical manifestation needs to be to be able to be abstracted up to a satisfying cognitive model that matches the human's intention. In other words, you cast a spell \"make that banana green!\" and it comes back a lurid dayglo green, that would be a cognitive dissonance because really, you'd expect to simply get a very unripe-looking banana. What are the elements of this formalised spell-casting, this \"programming system\"? You have objects (banana, this one, not all ones), attributes (green, the correct one!), a sense of time or evolution (went from yellow to green). You start to get into Roget's Thesaurus land: what are the key concepts for describing the world, our human world?\n\nAnyway, just a splat of the stuff buzzing around my head right now. Thoughts?"
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                ],
                "id": 1,
                "original_url": "https:\/\/futureofcoding.slack.com\/archives\/CLYCGTCPL\/p1679833469621219",
                "fallback": "[March 26th, 2023 5:24 AM] fp: So, I'm an EUP person at heart, and this ChatGPT thing has obviously got me thinking all over again about what programming would look like to a non-technical person. At heart, I feel it should be like they're \"casting spells\" over reality (or virtual reality). This tips into the area of cognitive modelling: how close the physical manifestation needs to be to be able to be abstracted up to a satisfying cognitive model that matches the human's intention. In other words, you cast a spell \"make that banana green!\" and it comes back a lurid dayglo green, that would be a cognitive dissonance because really, you'd expect to simply get a very unripe-looking banana. What are the elements of this formalised spell-casting, this \"programming system\"? You have objects (banana, this one, not all ones), attributes (green, the correct one!), a sense of time or evolution (went from yellow to green). You start to get into Roget's Thesaurus land: what are the key concepts for describing the world, our human world?\n\nAnyway, just a splat of the stuff buzzing around my head right now. Thoughts?",
                "text": "So, I'm an EUP person at heart, and this ChatGPT thing has obviously got me thinking all over again about what programming would look like to a non-technical person. At heart, I feel it should be like they're \"casting spells\" over reality (or virtual reality). This tips into the area of cognitive modelling: how close the physical manifestation needs to be to be able to be abstracted up to a satisfying cognitive model that matches the human's intention. In other words, you cast a spell \"make that banana green!\" and it comes back a lurid dayglo green, that would be a cognitive dissonance because really, you'd expect to simply get a very unripe-looking banana. What are the elements of this formalised spell-casting, this \"programming system\"? You have objects (banana, this one, not all ones), attributes (green, the correct one!), a sense of time or evolution (went from yellow to green). You start to get into Roget's Thesaurus land: what are the key concepts for describing the world, our human world?\n\nAnyway, just a splat of the stuff buzzing around my head right now. Thoughts?",
                "author_name": "Duncan Cragg",
                "author_link": "https:\/\/futureofcoding.slack.com\/team\/UE6EFEPTQ",
                "author_icon": "https:\/\/avatars.slack-edge.com\/2018-12-18\/508431502471_8073c43d5d8dd3d3b4b2_48.jpg",
                "author_subname": "Duncan Cragg",
                "mrkdwn_in": [
                    "text"
                ],
                "footer": "Thread in Slack Conversation"
            },
            {
                "from_url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679642239661619",
                "ts": "1679642239.661619",
                "author_id": "UA14TGLTC",
                "channel_id": "C5T9GPWFL",
                "channel_team": "T5TCAFTA9",
                "is_msg_unfurl": true,
                "is_thread_root_unfurl": true,
                "message_blocks": [
                    {
                        "team": "T5TCAFTA9",
                        "channel": "C5T9GPWFL",
                        "ts": "1679642239.661619",
                        "message": {
                            "blocks": [
                                {
                                    "type": "rich_text",
                                    "block_id": "Bvp",
                                    "elements": [
                                        {
                                            "type": "rich_text_section",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "Friends, I don't know what to make of developments in AI these days.  Having worked on dialog systems in the aughts and having loosely followed developments since (I recall preparing a talk around 2010 which left me pretty enthusiastic about ML applications in contrast to the App-and-Facebookification of \"tech\" — that was on time horizon of a few years, which ended up being a decade plus), every day I check in on Twitter I see more exciting stuff than I can possibly process.  I was just writing someone yesterday about how in six months time, we'll have LLMs acting as the front-end to knowledge bases and rigorous computational systems, and then we'll need to focus on getting the human, AI, and formal model all on the same page.\n\nAs has already been noted in "
                                                },
                                                {
                                                    "type": "channel",
                                                    "channel_id": "C5U3SEW6A"
                                                },
                                                {
                                                    "type": "text",
                                                    "text": " today, my estimate was off by roughly six months.  Consider, \"I've developed a lot of plugin systems, and the OpenAI ChatGPT plugin interface might be the damn craziest and most impressive approach I've ever seen in computing in my entire life. For those who aren't aware: you write an OpenAPI manifest for your API, use human language descriptions for everything, and that's it. You let the model figure out how to auth, chain calls, process data in between, format it for viewing, etc. There's absolutely zero glue code\" "
                                                },
                                                {
                                                    "type": "link",
                                                    "url": "https:\/\/twitter.com\/mitchellh\/status\/1638967450510458882"
                                                },
                                                {
                                                    "type": "text",
                                                    "text": ".\n\nIf you can tolerate his prose, Stephen Wolfram has a long post "
                                                },
                                                {
                                                    "type": "link",
                                                    "url": "https:\/\/writings.stephenwolfram.com\/2023\/03\/chatgpt-gets-its-wolfram-superpowers\/"
                                                },
                                                {
                                                    "type": "text",
                                                    "text": ".  The \"Wolfram Language as the Language for Human-AI Collaboration\" section is most relevant to Future of Coding.  What do these developments mean for the Future of Coding?  And how are you all holding up?  Me?  I can hardly process what's happening, let alone what to do about it."
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                ],
                "id": 2,
                "original_url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679642239661619",
                "fallback": "[March 24th, 2023 12:17 AM] wtaysom: Friends, I don't know what to make of developments in AI these days.  Having worked on dialog systems in the aughts and having loosely followed developments since (I recall preparing a talk around 2010 which left me pretty enthusiastic about ML applications in contrast to the App-and-Facebookification of \"tech\" — that was on time horizon of a few years, which ended up being a decade plus), every day I check in on Twitter I see more exciting stuff than I can possibly process.  I was just writing someone yesterday about how in six months time, we'll have LLMs acting as the front-end to knowledge bases and rigorous computational systems, and then we'll need to focus on getting the human, AI, and formal model all on the same page.\n\nAs has already been noted in <#C5U3SEW6A|linking-together> today, my estimate was off by roughly six months.  Consider, \"I've developed a lot of plugin systems, and the OpenAI ChatGPT plugin interface might be the damn craziest and most impressive approach I've ever seen in computing in my entire life. For those who aren't aware: you write an OpenAPI manifest for your API, use human language descriptions for everything, and that's it. You let the model figure out how to auth, chain calls, process data in between, format it for viewing, etc. There's absolutely zero glue code\" <https:\/\/twitter.com\/mitchellh\/status\/1638967450510458882>.\n\nIf you can tolerate his prose, Stephen Wolfram has a long post <https:\/\/writings.stephenwolfram.com\/2023\/03\/chatgpt-gets-its-wolfram-superpowers\/>.  The \"Wolfram Language as the Language for Human-AI Collaboration\" section is most relevant to Future of Coding.  What do these developments mean for the Future of Coding?  And how are you all holding up?  Me?  I can hardly process what's happening, let alone what to do about it.",
                "text": "Friends, I don't know what to make of developments in AI these days.  Having worked on dialog systems in the aughts and having loosely followed developments since (I recall preparing a talk around 2010 which left me pretty enthusiastic about ML applications in contrast to the App-and-Facebookification of \"tech\" — that was on time horizon of a few years, which ended up being a decade plus), every day I check in on Twitter I see more exciting stuff than I can possibly process.  I was just writing someone yesterday about how in six months time, we'll have LLMs acting as the front-end to knowledge bases and rigorous computational systems, and then we'll need to focus on getting the human, AI, and formal model all on the same page.\n\nAs has already been noted in <#C5U3SEW6A|linking-together> today, my estimate was off by roughly six months.  Consider, \"I've developed a lot of plugin systems, and the OpenAI ChatGPT plugin interface might be the damn craziest and most impressive approach I've ever seen in computing in my entire life. For those who aren't aware: you write an OpenAPI manifest for your API, use human language descriptions for everything, and that's it. You let the model figure out how to auth, chain calls, process data in between, format it for viewing, etc. There's absolutely zero glue code\" <https:\/\/twitter.com\/mitchellh\/status\/1638967450510458882>.\n\nIf you can tolerate his prose, Stephen Wolfram has a long post <https:\/\/writings.stephenwolfram.com\/2023\/03\/chatgpt-gets-its-wolfram-superpowers\/>.  The \"Wolfram Language as the Language for Human-AI Collaboration\" section is most relevant to Future of Coding.  What do these developments mean for the Future of Coding?  And how are you all holding up?  Me?  I can hardly process what's happening, let alone what to do about it.",
                "author_name": "William Taysom",
                "author_link": "https:\/\/futureofcoding.slack.com\/team\/UA14TGLTC",
                "author_icon": "https:\/\/secure.gravatar.com\/avatar\/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=48&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-48.png",
                "author_subname": "William Taysom",
                "mrkdwn_in": [
                    "text"
                ],
                "footer": "Thread in Slack Conversation"
            },
            {
                "from_url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679902227016569",
                "ts": "1679902227.016569",
                "author_id": "U0296ACR13M",
                "channel_id": "C5T9GPWFL",
                "channel_team": "T5TCAFTA9",
                "is_msg_unfurl": true,
                "is_thread_root_unfurl": true,
                "message_blocks": [
                    {
                        "team": "T5TCAFTA9",
                        "channel": "C5T9GPWFL",
                        "ts": "1679902227.016569",
                        "message": {
                            "blocks": [
                                {
                                    "type": "rich_text",
                                    "block_id": "Vvnq",
                                    "elements": [
                                        {
                                            "type": "rich_text_section",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "On the heels of the \"LLMs and the future of programming\" discussion ("
                                                },
                                                {
                                                    "type": "link",
                                                    "url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679642239661619"
                                                },
                                                {
                                                    "type": "text",
                                                    "text": ", "
                                                },
                                                {
                                                    "type": "link",
                                                    "url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679892669316079"
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "), I'd like to start a more concentrated discussion around their effect on Future of Coding projects. There was already some sentiment that LLMs are going to kill FoC projects. Some yes, but certainly not all. So what kind of FoC projects LLMs will not kill?"
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                ],
                "id": 3,
                "original_url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679902227016569",
                "fallback": "[March 27th, 2023 12:30 AM] jarno.montonen: On the heels of the \"LLMs and the future of programming\" discussion (<https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679642239661619>, <https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679892669316079>), I'd like to start a more concentrated discussion around their effect on Future of Coding projects. There was already some sentiment that LLMs are going to kill FoC projects. Some yes, but certainly not all. So what kind of FoC projects LLMs will not kill?",
                "text": "On the heels of the \"LLMs and the future of programming\" discussion (<https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679642239661619>, <https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679892669316079>), I'd like to start a more concentrated discussion around their effect on Future of Coding projects. There was already some sentiment that LLMs are going to kill FoC projects. Some yes, but certainly not all. So what kind of FoC projects LLMs will not kill?",
                "author_name": "Jarno Montonen",
                "author_link": "https:\/\/futureofcoding.slack.com\/team\/U0296ACR13M",
                "author_icon": "https:\/\/avatars.slack-edge.com\/2022-09-08\/4075674207584_59de929720a2fe0a13d8_48.jpg",
                "author_subname": "Jarno Montonen",
                "mrkdwn_in": [
                    "text"
                ],
                "footer": "Thread in Slack Conversation"
            },
            {
                "from_url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679892669316079",
                "ts": "1679892669.316079",
                "author_id": "UCGAK10LS",
                "channel_id": "C5T9GPWFL",
                "channel_team": "T5TCAFTA9",
                "is_msg_unfurl": true,
                "is_thread_root_unfurl": true,
                "message_blocks": [
                    {
                        "team": "T5TCAFTA9",
                        "channel": "C5T9GPWFL",
                        "ts": "1679892669.316079",
                        "message": {
                            "blocks": [
                                {
                                    "type": "rich_text",
                                    "block_id": "HQR0r",
                                    "elements": [
                                        {
                                            "type": "rich_text_section",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "Here's my perspective on LLMs and the future of programming.\n\nI don't believe that the introduction of LLMs that can write code is going to obviate programming. And I don't believe that it is now pointless to develop new programming languages. Instead, I think LLMs are going to make programming and FoC research "
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "better",
                                                    "style": {
                                                        "italic": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": ", by automating one of the least interesting parts of programming: fiddling with the minutiae of syntax, language constructs, and libraries.\n\nI think programmers will still have plenty of work to do. The profession is not doomed. But to justify this, we have to take a step back and consider all of the activities involved in programming.\n\nFirstly, what is a \"program\"? A program is nothing more than:\n"
                                                }
                                            ]
                                        },
                                        {
                                            "type": "rich_text_list",
                                            "elements": [
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "A formal specification",
                                                            "style": {
                                                                "italic": true
                                                            }
                                                        },
                                                        {
                                                            "type": "text",
                                                            "text": " of the behaviour of an interactive system"
                                                        }
                                                    ]
                                                },
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "...that computer hardware can execute (after translating it into machine code)."
                                                        }
                                                    ]
                                                }
                                            ],
                                            "style": "bullet",
                                            "indent": 0,
                                            "border": 0
                                        },
                                        {
                                            "type": "rich_text_section",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "\nTo emphasise this, I will use the term \"formal spec\" in place of \"program\" for the remainder of this discussion.\n\nGPT-4 can understand formal specs, and also everyday English. Thus, if we can describe the functionality of a system in everyday English, GPT-4 can (attempt to) translate it into a formal spec. But writing the formal spec is just "
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "one",
                                                    "style": {
                                                        "italic": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": " activity of programming.\n\nAltogether, programming (or perhaps \"software development\") involves several activities:\n"
                                                }
                                            ]
                                        },
                                        {
                                            "type": "rich_text_list",
                                            "elements": [
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "Determining what functionality the system being developed \"should\" have. This is done either by talking with relevant stakeholders (e.g. the future users), or by directly observing deficiencies with their current practices."
                                                        }
                                                    ]
                                                },
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "Expressing that functionality as a formal specification, i.e. \"coding\"."
                                                        }
                                                    ]
                                                },
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "Verifying that the specification correctly implements all of the functionality of step 1. This includes practices such as reading and reviewing the specification, as well as testing the software."
                                                        }
                                                    ]
                                                },
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "Validating that the implemented functionality addresses the stakeholder's problems."
                                                        }
                                                    ]
                                                },
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "Repeating the first 4 steps until the stakeholders are satisfied with what has been developed."
                                                        }
                                                    ]
                                                }
                                            ],
                                            "style": "ordered",
                                            "indent": 0,
                                            "border": 0
                                        },
                                        {
                                            "type": "rich_text_section",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "\nHere's my hypothesis: "
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "In the next 10 years, LLMs might radically reduce the amount of work required for step 2, but ",
                                                    "style": {
                                                        "bold": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "only",
                                                    "style": {
                                                        "bold": true,
                                                        "italic": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": " step 2.",
                                                    "style": {
                                                        "bold": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "\n\nSteps 1 and 4 are very human-centered, and thus can't be automated away — at least until we are at the point where we have an omnipresent AGI that observes all human practices and automatically develops solutions to improve them.\n\nSimilarly, step 3 will not be automated any time soon, because:\n"
                                                }
                                            ]
                                        },
                                        {
                                            "type": "rich_text_list",
                                            "elements": [
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "The plain English descriptions that we give to LLMs will often be ambiguous, underspecified, and maybe even inconsistent. Thus the LLMs will have to make educated "
                                                        },
                                                        {
                                                            "type": "text",
                                                            "text": "guesses",
                                                            "style": {
                                                                "italic": true
                                                            }
                                                        },
                                                        {
                                                            "type": "text",
                                                            "text": " at what we mean. (Even if they are able to ask clarifying questions, there will always be "
                                                        },
                                                        {
                                                            "type": "text",
                                                            "text": "some",
                                                            "style": {
                                                                "italic": true
                                                            }
                                                        },
                                                        {
                                                            "type": "text",
                                                            "text": " choices that are automatically made for us.)"
                                                        }
                                                    ]
                                                },
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "LLMs will occasionally get confused or misinterpret what we say, even if we are clear and careful. We will not have "
                                                        },
                                                        {
                                                            "type": "text",
                                                            "text": "infallible",
                                                            "style": {
                                                                "italic": true
                                                            }
                                                        },
                                                        {
                                                            "type": "text",
                                                            "text": " AIs any time soon."
                                                        }
                                                    ]
                                                }
                                            ],
                                            "style": "bullet",
                                            "indent": 0,
                                            "border": 0
                                        },
                                        {
                                            "type": "rich_text_section",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "\nSo let's assume that LLMs can automate most of step 2. What does this mean for those of us developing tools and technologies to improve programming? Is our work obsolete now? Will the AI researchers and AI startups be taking the reigns?\n\nI don't think so! There is still a huge opportunity to develop tools that address step 3, at the very least. (Steps 1 and 4 are harder to address with technology.)\n\nIn particular, "
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "step 3 involves the task of ",
                                                    "style": {
                                                        "bold": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "reading",
                                                    "style": {
                                                        "bold": true,
                                                        "italic": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": " source code",
                                                    "style": {
                                                        "bold": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": ". When an LLM spits out 1000 lines of JavaScript, how do you know that the code implements the functionality that you wanted? You have to "
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "verify",
                                                    "style": {
                                                        "italic": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": " that it does, and for large programs, that will be an enormous amount of work!\n\nAs we all know, no amount of testing can prove that a program is correct. Thus, we cannot verify AI-generated programs just by "
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "using",
                                                    "style": {
                                                        "italic": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": " them. Maybe the program has a subtle bug, such as a buffer overflow, that might only be triggered 5 years after the program is deployed. Or less insidiously: maybe the program just doesn't handle certain edge-cases in the way you would like it to. Either way, a human should probably read through the entire program with a keen eye, to check that all of the logic "
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "makes sense",
                                                    "style": {
                                                        "italic": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": ".\n\nThere's clearly an opportunity for FoC researchers here: we can make languages and tools that make "
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "reading",
                                                    "style": {
                                                        "italic": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": " and "
                                                },
                                                {
                                                    "type": "text",
                                                    "text": "verifying",
                                                    "style": {
                                                        "italic": true
                                                    }
                                                },
                                                {
                                                    "type": "text",
                                                    "text": " the behaviour of programs easier! Some examples:\n"
                                                }
                                            ]
                                        },
                                        {
                                            "type": "rich_text_list",
                                            "elements": [
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "We can design programming languages that are vastly easier to "
                                                        },
                                                        {
                                                            "type": "text",
                                                            "text": "read",
                                                            "style": {
                                                                "italic": true
                                                            }
                                                        },
                                                        {
                                                            "type": "text",
                                                            "text": " than traditional languages. How might we do that? Well, \"higher-level\" languages are likely easier to read, since they are likely to be more concise and focus on the end-user functionality. So work on higher-level programming models will continue to be valuable. To complement this, we can (and IMO, we should) invent new syntaxes that are closer to plain English, such that the specifications that LLMs produce are accessible to a wider audience."
                                                        }
                                                    ]
                                                },
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "We can design programming languages where it is harder to write erroneous programs. For example, we can design programming languages that cannot crash or hang (i.e. Turing-incomplete languages), but which are still general-purpose. This reduces the kinds of errors that a human needs to consider as they verify a program."
                                                        }
                                                    ]
                                                },
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "We can design better tools for reading and interrogating source code. (For example, better IDE support for navigating and understanding the structure of large codebases.)"
                                                        }
                                                    ]
                                                },
                                                {
                                                    "type": "rich_text_section",
                                                    "elements": [
                                                        {
                                                            "type": "text",
                                                            "text": "We can design better tools for exploring the space of behaviours of a running program. (Perhaps similar to the tools discussed in Bret Victor's "
                                                        },
                                                        {
                                                            "type": "link",
                                                            "url": "http:\/\/worrydream.com\/#!2\/LadderOfAbstraction",
                                                            "text": "\"Ladder of Abstraction\""
                                                        },
                                                        {
                                                            "type": "text",
                                                            "text": " essay.)"
                                                        }
                                                    ]
                                                }
                                            ],
                                            "style": "bullet",
                                            "indent": 0,
                                            "border": 0
                                        },
                                        {
                                            "type": "rich_text_section",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "\nOverall, I think the future is bright! I'm going to continue my own PL research project (a very high-level language) with as much vigor as ever."
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                ],
                "id": 4,
                "original_url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679892669316079",
                "fallback": "[March 26th, 2023 9:51 PM] nmsmith65: Here's my perspective on LLMs and the future of programming.\n\nI don't believe that the introduction of LLMs that can write code is going to obviate programming. And I don't believe that it is now pointless to develop new programming languages. Instead, I think LLMs are going to make programming and FoC research _better_, by automating one of the least interesting parts of programming: fiddling with the minutiae of syntax, language constructs, and libraries.\n\nI think programmers will still have plenty of work to do. The profession is not doomed. But to justify this, we have to take a step back and consider all of the activities involved in programming.\n\nFirstly, what is a \"program\"? A program is nothing more than:\n• _A formal specification_ of the behaviour of an interactive system\n• ...that computer hardware can execute (after translating it into machine code).\nTo emphasise this, I will use the term \"formal spec\" in place of \"program\" for the remainder of this discussion.\n\nGPT-4 can understand formal specs, and also everyday English. Thus, if we can describe the functionality of a system in everyday English, GPT-4 can (attempt to) translate it into a formal spec. But writing the formal spec is just _one_ activity of programming.\n\nAltogether, programming (or perhaps \"software development\") involves several activities:\n1. Determining what functionality the system being developed \"should\" have. This is done either by talking with relevant stakeholders (e.g. the future users), or by directly observing deficiencies with their current practices.\n2. Expressing that functionality as a formal specification, i.e. \"coding\".\n3. Verifying that the specification correctly implements all of the functionality of step 1. This includes practices such as reading and reviewing the specification, as well as testing the software.\n4. Validating that the implemented functionality addresses the stakeholder's problems.\n5. Repeating the first 4 steps until the stakeholders are satisfied with what has been developed.\nHere's my hypothesis: *In the next 10 years, LLMs might radically reduce the amount of work required for step 2, but _only_ step 2.*\n\nSteps 1 and 4 are very human-centered, and thus can't be automated away — at least until we are at the point where we have an omnipresent AGI that observes all human practices and automatically develops solutions to improve them.\n\nSimilarly, step 3 will not be automated any time soon, because:\n• The plain English descriptions that we give to LLMs will often be ambiguous, underspecified, and maybe even inconsistent. Thus the LLMs will have to make educated _guesses_ at what we mean. (Even if they are able to ask clarifying questions, there will always be _some_ choices that are automatically made for us.)\n• LLMs will occasionally get confused or misinterpret what we say, even if we are clear and careful. We will not have _infallible_ AIs any time soon.\nSo let's assume that LLMs can automate most of step 2. What does this mean for those of us developing tools and technologies to improve programming? Is our work obsolete now? Will the AI researchers and AI startups be taking the reigns?\n\nI don't think so! There is still a huge opportunity to develop tools that address step 3, at the very least. (Steps 1 and 4 are harder to address with technology.)\n\nIn particular, *step 3 involves the task of _reading_ source code*. When an LLM spits out 1000 lines of JavaScript, how do you know that the code implements the functionality that you wanted? You have to _verify_ that it does, and for large programs, that will be an enormous amount of work!\n\nAs we all know, no amount of testing can prove that a program is correct. Thus, we cannot verify AI-generated programs just by _using_ them. Maybe the program has a subtle bug, such as a buffer overflow, that might only be triggered 5 years after the program is deployed. Or less insidiously: maybe the program just doesn't handle certain edge-cases in the way you would like it to. Either way, a human should probably read through the entire program with a keen eye, to check that all of the logic _makes sense_.\n\nThere's clearly an opportunity for FoC researchers here: we can make languages and tools that make _reading_ and _verifying_ the behaviour of programs easier! Some examples:\n• We can design programming languages that are vastly easier to _read_ than traditional languages. How might we do that? Well, \"higher-level\" languages are likely easier to read, since they are likely to be more concise and focus on the end-user functionality. So work on higher-level programming models will continue to be valuable. To complement this, we can (and IMO, we should) invent new syntaxes that are closer to plain English, such that the specifications that LLMs produce are accessible to a wider audience.\n• We can design programming languages where it is harder to write erroneous programs. For example, we can design programming languages that cannot crash or hang (i.e. Turing-incomplete languages), but which are still general-purpose. This reduces the kinds of errors that a human needs to consider as they verify a program.\n• We can design better tools for reading and interrogating source code. (For example, better IDE support for navigating and understanding the structure of large codebases.)\n• We can design better tools for exploring the space of behaviours of a running program. (Perhaps similar to the tools discussed in Bret Victor's <http:\/\/worrydream.com\/#!2\/LadderOfAbstraction|\"Ladder of Abstraction\"> essay.)\nOverall, I think the future is bright! I'm going to continue my own PL research project (a very high-level language) with as much vigor as ever.",
                "text": "Here's my perspective on LLMs and the future of programming.\n\nI don't believe that the introduction of LLMs that can write code is going to obviate programming. And I don't believe that it is now pointless to develop new programming languages. Instead, I think LLMs are going to make programming and FoC research _better_, by automating one of the least interesting parts of programming: fiddling with the minutiae of syntax, language constructs, and libraries.\n\nI think programmers will still have plenty of work to do. The profession is not doomed. But to justify this, we have to take a step back and consider all of the activities involved in programming.\n\nFirstly, what is a \"program\"? A program is nothing more than:\n• _A formal specification_ of the behaviour of an interactive system\n• ...that computer hardware can execute (after translating it into machine code).\nTo emphasise this, I will use the term \"formal spec\" in place of \"program\" for the remainder of this discussion.\n\nGPT-4 can understand formal specs, and also everyday English. Thus, if we can describe the functionality of a system in everyday English, GPT-4 can (attempt to) translate it into a formal spec. But writing the formal spec is just _one_ activity of programming.\n\nAltogether, programming (or perhaps \"software development\") involves several activities:\n1. Determining what functionality the system being developed \"should\" have. This is done either by talking with relevant stakeholders (e.g. the future users), or by directly observing deficiencies with their current practices.\n2. Expressing that functionality as a formal specification, i.e. \"coding\".\n3. Verifying that the specification correctly implements all of the functionality of step 1. This includes practices such as reading and reviewing the specification, as well as testing the software.\n4. Validating that the implemented functionality addresses the stakeholder's problems.\n5. Repeating the first 4 steps until the stakeholders are satisfied with what has been developed.\nHere's my hypothesis: *In the next 10 years, LLMs might radically reduce the amount of work required for step 2, but _only_ step 2.*\n\nSteps 1 and 4 are very human-centered, and thus can't be automated away — at least until we are at the point where we have an omnipresent AGI that observes all human practices and automatically develops solutions to improve them.\n\nSimilarly, step 3 will not be automated any time soon, because:\n• The plain English descriptions that we give to LLMs will often be ambiguous, underspecified, and maybe even inconsistent. Thus the LLMs will have to make educated _guesses_ at what we mean. (Even if they are able to ask clarifying questions, there will always be _some_ choices that are automatically made for us.)\n• LLMs will occasionally get confused or misinterpret what we say, even if we are clear and careful. We will not have _infallible_ AIs any time soon.\nSo let's assume that LLMs can automate most of step 2. What does this mean for those of us developing tools and technologies to improve programming? Is our work obsolete now? Will the AI researchers and AI startups be taking the reigns?\n\nI don't think so! There is still a huge opportunity to develop tools that address step 3, at the very least. (Steps 1 and 4 are harder to address with technology.)\n\nIn particular, *step 3 involves the task of _reading_ source code*. When an LLM spits out 1000 lines of JavaScript, how do you know that the code implements the functionality that you wanted? You have to _verify_ that it does, and for large programs, that will be an enormous amount of work!\n\nAs we all know, no amount of testing can prove that a program is correct. Thus, we cannot verify AI-generated programs just by _using_ them. Maybe the program has a subtle bug, such as a buffer overflow, that might only be triggered 5 years after the program is deployed. Or less insidiously: maybe the program just doesn't handle certain edge-cases in the way you would like it to. Either way, a human should probably read through the entire program with a keen eye, to check that all of the logic _makes sense_.\n\nThere's clearly an opportunity for FoC researchers here: we can make languages and tools that make _reading_ and _verifying_ the behaviour of programs easier! Some examples:\n• We can design programming languages that are vastly easier to _read_ than traditional languages. How might we do that? Well, \"higher-level\" languages are likely easier to read, since they are likely to be more concise and focus on the end-user functionality. So work on higher-level programming models will continue to be valuable. To complement this, we can (and IMO, we should) invent new syntaxes that are closer to plain English, such that the specifications that LLMs produce are accessible to a wider audience.\n• We can design programming languages where it is harder to write erroneous programs. For example, we can design programming languages that cannot crash or hang (i.e. Turing-incomplete languages), but which are still general-purpose. This reduces the kinds of errors that a human needs to consider as they verify a program.\n• We can design better tools for reading and interrogating source code. (For example, better IDE support for navigating and understanding the structure of large codebases.)\n• We can design better tools for exploring the space of behaviours of a running program. (Perhaps similar to the tools discussed in Bret Victor's <http:\/\/worrydream.com\/#!2\/LadderOfAbstraction|\"Ladder of Abstraction\"> essay.)\nOverall, I think the future is bright! I'm going to continue my own PL research project (a very high-level language) with as much vigor as ever.",
                "author_name": "Nick Smith",
                "author_link": "https:\/\/futureofcoding.slack.com\/team\/UCGAK10LS",
                "author_icon": "https:\/\/avatars.slack-edge.com\/2023-02-17\/4818540771315_49c867dc60c5fd03f1a3_48.jpg",
                "author_subname": "Nick Smith",
                "mrkdwn_in": [
                    "text"
                ],
                "footer": "Thread in Slack Conversation"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "K+bi5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Some links to threads I pulled together,  won't be complete of course:\n\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/futureofcoding.slack.com\/archives\/CLYCGTCPL\/p1679833469621219"
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679642239661619"
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679902227016569"
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/futureofcoding.slack.com\/archives\/C5T9GPWFL\/p1679892669316079"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UE6EFEPTQ",
        "type": "message",
        "ts": "1680043317.354189",
        "client_msg_id": "653d0aaf-106d-4a55-8754-188926b78bf9",
        "text": "Oh! Did I put mine first? Completely unintentional obvs.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "8073c43d5d8d",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-12-18\/508431502471_8073c43d5d8dd3d3b4b2_72.jpg",
            "first_name": "Duncan",
            "real_name": "Duncan Cragg",
            "display_name": "Duncan Cragg",
            "team": "T5TCAFTA9",
            "name": "fp",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "pbDDC",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Oh! Did I put mine first? Completely unintentional obvs."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "subtype": "channel_join",
        "user": "U03M8BYEAQ1",
        "text": "<@U03M8BYEAQ1> has joined the channel",
        "type": "message",
        "ts": "1680046583.428019"
    },
    {
        "subtype": "channel_join",
        "user": "UEBG0NPDK",
        "text": "<@UEBG0NPDK> has joined the channel",
        "type": "message",
        "ts": "1680047009.684049"
    },
    {
        "subtype": "channel_join",
        "user": "U04CU09VBC3",
        "text": "<@U04CU09VBC3> has joined the channel",
        "type": "message",
        "ts": "1680047420.126809"
    },
    {
        "subtype": "channel_join",
        "user": "U01NWARGPNC",
        "text": "<@U01NWARGPNC> has joined the channel",
        "type": "message",
        "ts": "1680047654.731259"
    },
    {
        "subtype": "channel_join",
        "user": "U03R0B9U1GD",
        "text": "<@U03R0B9U1GD> has joined the channel",
        "type": "message",
        "ts": "1680047774.451449"
    },
    {
        "subtype": "channel_join",
        "user": "U01AD80KMLK",
        "text": "<@U01AD80KMLK> has joined the channel",
        "type": "message",
        "ts": "1680047992.852039"
    },
    {
        "subtype": "channel_join",
        "user": "U04QL567693",
        "text": "<@U04QL567693> has joined the channel",
        "type": "message",
        "ts": "1680049768.909129"
    },
    {
        "subtype": "channel_join",
        "user": "U019ZJ1U69Y",
        "text": "<@U019ZJ1U69Y> has joined the channel",
        "type": "message",
        "ts": "1680050247.600489"
    }
]