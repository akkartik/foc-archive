[
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1688543100.164249",
        "client_msg_id": "84bcb88e-6512-463e-8046-cd13157b5c84",
        "text": "You say that there a no apps in the real world. Not sure I agree: I see apps as virtual tools, but tools that have grown too large and constrain their users rather than empowering them. There's a story by Cory Doctorow, about toasters that will accept only \"authorized bread\" (<https:\/\/www.defectivebydesign.org\/blog\/doctorows_novella_unauthorized_bread_explains_why_we_have_fight_drm_today_avoid_grim_future>). That's what apps would be like in the real world.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1688481543.459979",
        "parent_user_id": "UE6EFEPTQ",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "CgKC",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "You say that there a no apps in the real world. Not sure I agree: I see apps as virtual tools, but tools that have grown too large and constrain their users rather than empowering them. There's a story by Cory Doctorow, about toasters that will accept only \"authorized bread\" ("
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/www.defectivebydesign.org\/blog\/doctorows_novella_unauthorized_bread_explains_why_we_have_fight_drm_today_avoid_grim_future"
                            },
                            {
                                "type": "text",
                                "text": "). That's what apps would be like in the real world."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04E5QAD6DD",
        "type": "message",
        "ts": "1688563760.419879",
        "edited": {
            "user": "U04E5QAD6DD",
            "ts": "1688563898.000000"
        },
        "client_msg_id": "70a184d7-957b-40b9-a11b-def1666e7392",
        "text": "I haven't finished the podcast yet nor following this whole discussion, and I did <https:\/\/search.futureofcoding.org\/history\/?fromDate=2023-04-03&amp;toDate=2023-04-09&amp;channel=linking-together&amp;filter=#2023-04-06T13:09:25.555Z|share this article previously> but it connects here pretty well. My take-away from the article is that software, so far, has not had the expected impact on overall productivity, and that the challenge is that it is  _hard_ and  _expensive_ to model the real world within the constraints of programming.\n\nThe article: <https:\/\/web.archive.org\/web\/20221206161753\/https:\/\/austinvernon.eth.link\/blog\/softwareisprocess.html>\n\nSeems not unlike the legalism discussed in the podcast, but I'll keep listening. :smile:\n\n(edit: fixed links)",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e3e6bba2ae45",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-06\/5085861186081_e3e6bba2ae4575d17358_72.jpg",
            "first_name": "David",
            "real_name": "David Alan Hjelle",
            "display_name": "David Alan Hjelle",
            "team": "T5TCAFTA9",
            "name": "dahjelle_futureofcodi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1688402564.602729",
        "parent_user_id": "UC2A2ARPT",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "D3y",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I haven't finished the podcast yet nor following this whole discussion, and I did "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/search.futureofcoding.org\/history\/?fromDate=2023-04-03&toDate=2023-04-09&channel=linking-together&filter=#2023-04-06T13:09:25.555Z",
                                "text": "share this article previously"
                            },
                            {
                                "type": "text",
                                "text": " but it connects here pretty well. My take-away from the article is that software, so far, has not had the expected impact on overall productivity, and that the challenge is that it is  "
                            },
                            {
                                "type": "text",
                                "text": "hard",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " and  "
                            },
                            {
                                "type": "text",
                                "text": "expensive",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " to model the real world within the constraints of programming.\n\nThe article: "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/web.archive.org\/web\/20221206161753\/https:\/\/austinvernon.eth.link\/blog\/softwareisprocess.html"
                            },
                            {
                                "type": "text",
                                "text": "\n\nSeems not unlike the legalism discussed in the podcast, but I'll keep listening. "
                            },
                            {
                                "type": "emoji",
                                "name": "smile",
                                "unicode": "1f604"
                            },
                            {
                                "type": "text",
                                "text": "\n\n(edit: fixed links)"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U03R0B9U1GD"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UK3LH8CF5",
        "type": "message",
        "ts": "1688573168.521829",
        "client_msg_id": "65c265cd-84b4-4993-a40c-498598b68f57",
        "text": "<@U02U0AS3J49>\nThank you for the detailed feedback! I think you've made some excellent points here. And maybe as an outsider I'm conflating some things you see as related. Personally I see your project of encoding laws in a computationally understandable way as a bit of a different concern than what we were talking about in this essay. I mean they are definitely related, but nothing we talked about was meant as an argument against that project. Having worked to encode complicated medical rules in a rete based rules engine, I definitely appreciate the difficulty involved, but also the benefits it can bring.\n\nTo me the most interesting part of this essay is focusing on exactly what you are talking about below:\n\n&gt; Show me a situation where someone is trying to use software to collect and hold power over others, and I'll show you someone who is using a combination of software and law. A license, a contract, a patent, or something.\nAs software engineers, we often make systems that rely on the backdrop of the law to enforce things. But the way in which we enforce our side of those terms can be incredibly legalistic and harmful to users.\n\nFor example, recently a number of youtubers big and small have had their ability to monetize completely removed because of \"suspicious traffic\". Basically they have been accused of ad fraud. From what I've seen, even the most connected have had a difficult time solving this issue.\n\nHere I see a classic case of the kinds of confusions we as software engineers make. What we are interested in is ad fraud (in this case). We want to stop users who are created fake bot traffic from benefitting from it. But what we actually have access to in our software systems is not whether or not someone committed ad fraud. We have numbers and correlations. But use these as if we are getting at truth. We build systems for which there is no recourse.\n\nI did what to pull out a few things you said below, but if I missed something you'd want me to comment on, happy to.\n\n&gt; But what people are actually proposing to do has nothing to do with executing law programmatically.\nYeah, I don't think he is claiming that. But if we were unclear on that point, that's our bad.\n\n&gt; The idea that code is dangerous because it can be used to turn norms into laws is true, but only inside the context of non legalist structures, which means the danger is mitigated. And it is not unique to code.\nMy personal concern is that codes legalism leaks into the way we think about systems. Code's legalism is seen as a virtue to be emulated. Ambiguity (even intentional) and context-sensitivity are seen as bad. The distinction between what we are trying to achieve and the measurement of that achievement are conflated. (OKRs are a terrible idea)\n\n&gt; \"Speed of execution of code prevents the possibility of reevaluating it's terms.\" That is it's virtue. It is not without a concomitant risk that we are doing the wrong thing, but faster. But doing the wrong thing faster is an inherent risk that is mitigated by basically all of software development. You cannot take the quality of laws we have now, and assume that they will be automated as-is.\nI mean, we do that in some ways. Look at the DMCA processes our youtube content. The copywrite strikes are automated, the demonetization is automated, many times even the appeals are automated. Obviously no one thinks we are going to take all our laws and automate them. But it's hard to see how not being able to reevaluate the terms is a virtue. Getting the terms right is the hardest part about software and I don't know any system that gets those terms right from the outset.\n\n&gt; We are also taking the ex post necessity of the legal system and treating it as a virtue. The fact that you have to sue someone and ask a judge to interpret a contact is not a feature.\nYeah, I don't think anyone thinks the fact that you have to sue someone is a virtue. What is a virtue is that you have the freedom to do actions that you believe are or should be lawful and if you are arrested\/fined you have the ability to appeal that decision. Contrast this with \"cursing\" in club penguin for example. You are immediately booted, you have no recourse. (I don't actually know if there was\/is an appeal process in club penguin).\n\n&gt; We cannot pretend that laws don't need to be automated. They plainly do.\nYeah, I agree. I see that as the point of this paper. How we can automate things in a good way? What changes can we make to make sure our automations don't have legalistic problems?\n\n&gt; And raising this spectre of strong legalism in code, while it has the intent of protecting people from harm, is actually being used by -among other parties- a protectionist legal profession to argue directly against one of the most helpful things we could do right now, which is automated legal harm reduction. An automated system can literally be only better than nothing, and justified on that basis, because nothing is what so many people actually have.\nI can definitely see how this would happen. And I can see how it would be frustrating from the position you are in. For what is worth, I don't see Diver doing this, but instead proposing ways in which we can make these systems well. That's one of the things I like about his work, it isn't an argument against using code, it is a discussion about how to do it well.\n\n&gt; Sure, programming languages constrain their users. But you can just stop using them, so the constraint is voluntary. \n&gt; Fair. What I mean is that if you did stop using them, no one with any state-sponsored monopoly over violent persuasion would have anything to say about it. Which is admittedly a very low bar.\nYeah, but other people using software that you didn't explicitly decide to use can still ruin people's lives without \"state-sponsored monopoly over violent persuasion\". Imagine the company I talked about that screens applications using machine learning is used by all fast-food restaurants in your area. Imagine these are the jobs you are qualified for, but the ML model has decided you will quit the job too early. Of course, you can go try and find a job elsewhere. Of course, a similar situation could happen due to human bias. But there is something very unsettling about this version of the future. The ML model can't be convinced, it can't provide reasons. It isn't a rational process whatsoever.\n\nI think these are real harms we ought to pay attention too. I think saying people can not use software they don't like is just like saying people can move if they don't like their local laws. Both statements are generally true, but no helpful for many people.\n\n&gt; We need tools that are accessible to a much wider variety of people, that have a far smaller semantic gap between the natural language expression of the rule and the computer language expression of the rule, tools that are designed to facilitate human validation of those encodings, languages that are inherently explainable, with sophisticated reasoning, that cite their sources, that name the person whose legal interpretation was modeled, that are accessible, open source, and trustworthy.  And those tools needed to be possible to use to test and validate anything else we might like to reduce the risk of. So we don't need to change all of programming, but we do need to add to it.\nThis sounds super interesting. If you have any papers that argument against what this paper argued for and gives what you see as the alternative prospective, super interested in that. No promise we will do it on the podcast, but definitely interested. Ideally a paper a bit less in the technical details of how to do these things with code, and more arguing for their applications.\n\nIn general, I think what you've said here doesn't feel too much at odds with what I think we were trying to explore. I do think software has a role to play. I do think we need to automate things. I do totally get how these sorts of arguments might be used against projects like yours and that must suck. I don't think that's the aim of the argument here. You are definitely right that there is no discussion of how to use code to improve laws. I'd love to explore that further and am super happy there are people like you working on that. If you can help point us in that direction for some readings, I'd love to take a look :)",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "4377ee2417eb",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-12-25\/886144219253_4377ee2417eb9eaacd4b_72.jpg",
            "first_name": "Jimmy",
            "real_name": "Jimmy Miller",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "jimmyhmiller",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1688402564.602729",
        "parent_user_id": "UC2A2ARPT",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xhIvC",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U02U0AS3J49"
                            },
                            {
                                "type": "text",
                                "text": "\nThank you for the detailed feedback! I think you've made some excellent points here. And maybe as an outsider I'm conflating some things you see as related. Personally I see your project of encoding laws in a computationally understandable way as a bit of a different concern than what we were talking about in this essay. I mean they are definitely related, but nothing we talked about was meant as an argument against that project. Having worked to encode complicated medical rules in a rete based rules engine, I definitely appreciate the difficulty involved, but also the benefits it can bring.\n\nTo me the most interesting part of this essay is focusing on exactly what you are talking about below:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Show me a situation where someone is trying to use software to collect and hold power over others, and I'll show you someone who is using a combination of software and law. A license, a contract, a patent, or something."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nAs software engineers, we often make systems that rely on the backdrop of the law to enforce things. But the way in which we enforce our side of those terms can be incredibly legalistic and harmful to users.\n\nFor example, recently a number of youtubers big and small have had their ability to monetize completely removed because of \"suspicious traffic\". Basically they have been accused of ad fraud. From what I've seen, even the most connected have had a difficult time solving this issue.\n\nHere I see a classic case of the kinds of confusions we as software engineers make. What we are interested in is ad fraud (in this case). We want to stop users who are created fake bot traffic from benefitting from it. But what we actually have access to in our software systems is not whether or not someone committed ad fraud. We have numbers and correlations. But use these as if we are getting at truth. We build systems for which there is no recourse.\n\nI did what to pull out a few things you said below, but if I missed something you'd want me to comment on, happy to.\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "But what people are actually proposing to do has nothing to do with executing law programmatically."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nYeah, I don't think he is claiming that. But if we were unclear on that point, that's our bad.\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The idea that code is dangerous because it can be used to turn norms into laws is true, but only inside the context of non legalist structures, which means the danger is mitigated. And it is not unique to code."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nMy personal concern is that codes legalism leaks into the way we think about systems. Code's legalism is seen as a virtue to be emulated. Ambiguity (even intentional) and context-sensitivity are seen as bad. The distinction between what we are trying to achieve and the measurement of that achievement are conflated. (OKRs are a terrible idea)\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\"Speed of execution of code prevents the possibility of reevaluating it's terms.\" That is it's virtue. It is not without a concomitant risk that we are doing the wrong thing, but faster. But doing the wrong thing faster is an inherent risk that is mitigated by basically all of software development. You cannot take the quality of laws we have now, and assume that they will be automated as-is."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nI mean, we do that in some ways. Look at the DMCA processes our youtube content. The copywrite strikes are automated, the demonetization is automated, many times even the appeals are automated. Obviously no one thinks we are going to take all our laws and automate them. But it's hard to see how not being able to reevaluate the terms is a virtue. Getting the terms right is the hardest part about software and I don't know any system that gets those terms right from the outset.\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "We are also taking the ex post necessity of the legal system and treating it as a virtue. The fact that you have to sue someone and ask a judge to interpret a contact is not a feature."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nYeah, I don't think anyone thinks the fact that you have to sue someone is a virtue. What is a virtue is that you have the freedom to do actions that you believe are or should be lawful and if you are arrested\/fined you have the ability to appeal that decision. Contrast this with \"cursing\" in club penguin for example. You are immediately booted, you have no recourse. (I don't actually know if there was\/is an appeal process in club penguin).\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "We cannot pretend that laws don't need to be automated. They plainly do."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nYeah, I agree. I see that as the point of this paper. How we can automate things in a good way? What changes can we make to make sure our automations don't have legalistic problems?\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "And raising this spectre of strong legalism in code, while it has the intent of protecting people from harm, is actually being used by -among other parties- a protectionist legal profession to argue directly against one of the most helpful things we could do right now, which is automated legal harm reduction. An automated system can literally be only better than nothing, and justified on that basis, because nothing is what so many people actually have."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nI can definitely see how this would happen. And I can see how it would be frustrating from the position you are in. For what is worth, I don't see Diver doing this, but instead proposing ways in which we can make these systems well. That's one of the things I like about his work, it isn't an argument against using code, it is a discussion about how to do it well.\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Sure, programming languages constrain their users. But you can just stop using them, so the constraint is voluntary. \nFair. What I mean is that if you did stop using them, no one with any state-sponsored monopoly over violent persuasion would have anything to say about it. Which is admittedly a very low bar."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nYeah, but other people using software that you didn't explicitly decide to use can still ruin people's lives without \"state-sponsored monopoly over violent persuasion\". Imagine the company I talked about that screens applications using machine learning is used by all fast-food restaurants in your area. Imagine these are the jobs you are qualified for, but the ML model has decided you will quit the job too early. Of course, you can go try and find a job elsewhere. Of course, a similar situation could happen due to human bias. But there is something very unsettling about this version of the future. The ML model can't be convinced, it can't provide reasons. It isn't a rational process whatsoever.\n\nI think these are real harms we ought to pay attention too. I think saying people can not use software they don't like is just like saying people can move if they don't like their local laws. Both statements are generally true, but no helpful for many people.\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "We need tools that are accessible to a much wider variety of people, that have a far smaller semantic gap between the natural language expression of the rule and the computer language expression of the rule, tools that are designed to facilitate human validation of those encodings, languages that are inherently explainable, with sophisticated reasoning, that cite their sources, that name the person whose legal interpretation was modeled, that are accessible, open source, and trustworthy.  And those tools needed to be possible to use to test and validate anything else we might like to reduce the risk of. So we don't need to change all of programming, but we do need to add to it."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nThis sounds super interesting. If you have any papers that argument against what this paper argued for and gives what you see as the alternative prospective, super interested in that. No promise we will do it on the podcast, but definitely interested. Ideally a paper a bit less in the technical details of how to do these things with code, and more arguing for their applications.\n\nIn general, I think what you've said here doesn't feel too much at odds with what I think we were trying to explore. I do think software has a role to play. I do think we need to automate things. I do totally get how these sorts of arguments might be used against projects like yours and that must suck. I don't think that's the aim of the argument here. You are definitely right that there is no discussion of how to use code to improve laws. I'd love to explore that further and am super happy there are people like you working on that. If you can help point us in that direction for some readings, I'd love to take a look :)"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "U03R0B9U1GD"
                ],
                "count": 1
            },
            {
                "name": "+1::skin-tone-2",
                "users": [
                    "U02U0AS3J49"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U02U0AS3J49",
        "type": "message",
        "ts": "1688593592.361709",
        "client_msg_id": "ccf2d159-bcc9-405a-ab0d-24f9f8c31210",
        "text": "For clarity, you guys did great, it's the paper I'm giving feedback on. And I'm admittedly biased.\n\nI would mind less if he was responding to the automation of law in software. But he claims to be responding to \"Rules as Code.\" \"Rules as Code\" is not \"software\" is not \"automation*. He sees Rules as Code as \"let's automate our laws more with software\", when in fact it is \"let's automate our laws better with better software\", and is aimed precisely at many of the evils he is warning against.\n\nCode would make for terrible law. But \"Rules as Code\" doesn't call for that. What we should want is better laws and better code, and rules as code is a way to get both. \n\nYouTube can automate unfairly. But is that a result of making code law? No. It is an automation of the Terms of Service. If it is unfair, but within the terms of the contract you agreed to with YouTube, then it is an automation of an unfair legal rule. Or, if it is an unfair automation of a fair contract, you can sue under the contract.\n\nCode is dangerous when it impacts people negatively. That is not to do with law. The fact that you can contemplate code as a mini legalist dictatorship inside the machine is cute, I guess, but not helpful. If you come to believe encoding laws is inherently unavoidably negative, you have been lied to. If you don't, no other prescriptions logically arise from the analogy, and all the real solutions to the problem arise without it.\n\nI'm not aware of any papers arguing in this direction other than parts of my LLM thesis, and that is not a great paper. I have a small website where I post thoughts along these lines, in the hope that there might eventually be enough of them to form a collection worth reading. Happy to pass along those links if you are interested.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g5247a9c6cbb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/5247a9c6cbb943683c9e2e2cef6eba79.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-72.png",
            "first_name": "Jason",
            "real_name": "Jason Morris",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "jason",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1688402564.602729",
        "parent_user_id": "UC2A2ARPT",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WR\/Lt",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "For clarity, you guys did great, it's the paper I'm giving feedback on. And I'm admittedly biased.\n\nI would mind less if he was responding to the automation of law in software. But he claims to be responding to \"Rules as Code.\" \"Rules as Code\" is not \"software\" is not \"automation*. He sees Rules as Code as \"let's automate our laws more with software\", when in fact it is \"let's automate our laws better with better software\", and is aimed precisely at many of the evils he is warning against.\n\nCode would make for terrible law. But \"Rules as Code\" doesn't call for that. What we should want is better laws and better code, and rules as code is a way to get both. \n\nYouTube can automate unfairly. But is that a result of making code law? No. It is an automation of the Terms of Service. If it is unfair, but within the terms of the contract you agreed to with YouTube, then it is an automation of an unfair legal rule. Or, if it is an unfair automation of a fair contract, you can sue under the contract.\n\nCode is dangerous when it impacts people negatively. That is not to do with law. The fact that you can contemplate code as a mini legalist dictatorship inside the machine is cute, I guess, but not helpful. If you come to believe encoding laws is inherently unavoidably negative, you have been lied to. If you don't, no other prescriptions logically arise from the analogy, and all the real solutions to the problem arise without it.\n\nI'm not aware of any papers arguing in this direction other than parts of my LLM thesis, and that is not a great paper. I have a small website where I post thoughts along these lines, in the hope that there might eventually be enough of them to form a collection worth reading. Happy to pass along those links if you are interested."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U02U0AS3J49",
        "type": "message",
        "ts": "1688593797.428299",
        "client_msg_id": "fc83246f-5252-407f-86ae-8b41cbf48736",
        "text": "The reason that his advice is weak, is because he has precluded an actual solution to the problem by conflating it with the problem itself. Rules as Code should have been the prescription, not the problem.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g5247a9c6cbb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/5247a9c6cbb943683c9e2e2cef6eba79.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-72.png",
            "first_name": "Jason",
            "real_name": "Jason Morris",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "jason",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1688402564.602729",
        "parent_user_id": "UC2A2ARPT",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "CLKA",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The reason that his advice is weak, is because he has precluded an actual solution to the problem by conflating it with the problem itself. Rules as Code should have been the prescription, not the problem."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04E5QAD6DD",
        "type": "message",
        "ts": "1688598090.097889",
        "client_msg_id": "ea818fee-54a4-40ac-840d-7177964e9d99",
        "text": "Now that I've finished with the episode — I really enjoyed it!\n\nI'm curious what examples — both specific implementations and of categories — of less-legalistic languages people are aware of?\n\nIn terms of syntax, LISP, SmallTalk, and Forth seem to be on the minimal-syntax-so-you-build-your-own-language train, at least to some degree.\n\nIn terms of exposing the innards of the program (like Jimmy's Black example — do you have a link?), HyperCard, SmallTalk, and…I guess the web, at least the early web, did this. Perhaps not all the way down, but a lot more than most.\n\nWhat other categories of less-legalism are there?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e3e6bba2ae45",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-06\/5085861186081_e3e6bba2ae4575d17358_72.jpg",
            "first_name": "David",
            "real_name": "David Alan Hjelle",
            "display_name": "David Alan Hjelle",
            "team": "T5TCAFTA9",
            "name": "dahjelle_futureofcodi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1688402564.602729",
        "parent_user_id": "UC2A2ARPT",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "SDD",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Now that I've finished with the episode — I really enjoyed it!\n\nI'm curious what examples — both specific implementations and of categories — of less-legalistic languages people are aware of?\n\nIn terms of syntax, LISP, SmallTalk, and Forth seem to be on the minimal-syntax-so-you-build-your-own-language train, at least to some degree.\n\nIn terms of exposing the innards of the program (like Jimmy's Black example — do you have a link?), HyperCard, SmallTalk, and…I guess the web, at least the early web, did this. Perhaps not all the way down, but a lot more than most.\n\nWhat other categories of less-legalism are there?"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U02U0AS3J49",
                    "U03R0B9U1GD"
                ],
                "count": 2
            }
        ]
    }
]