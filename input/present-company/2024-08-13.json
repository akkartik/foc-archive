[
    {
        "text": "Most of the work is not per-line, but finding good approximations to np-complete problems that span entire functions.",
        "files": [
            {
                "id": "F07H67ATE1F",
                "mode": "hidden_by_limit"
            }
        ],
        "upload": false,
        "user": "U71PMQ1V0",
        "display_as_bot": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "45cRL",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Most of the work is not per-line, but finding good approximations to np-complete problems that span entire functions."
                            }
                        ]
                    }
                ]
            }
        ],
        "type": "message",
        "ts": "1723587439.918879",
        "client_msg_id": "c1e1bc0c-41e8-4c08-9eac-d47cb1d4abd3",
        "thread_ts": "1723274705.524589",
        "parent_user_id": "U03U0SCU5LH",
        "reactions": [
            {
                "name": "sunglasses",
                "users": [
                    "U03U0SCU5LH",
                    "U02QC0PPER3"
                ],
                "count": 2
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "U067RCH8NB0",
                    "U0258UX5F1C"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "U71PMQ1V0",
        "type": "message",
        "ts": "1723587808.281139",
        "client_msg_id": "f3057fd6-87f3-4b19-95e2-15c43ba00ea7",
        "text": "LLVM could certainly be faster (pointer heavy ir, lots of dynamic function calls for extensibility, mandatory linking phase even when only compiling a single compilation unit). I could believe getting a single order of magnitude improvement while achieving the same code quality.\n\nYou can also get 2-3 orders of magnitude improvement today from baseline compilers, but typically at the expense of 2-5x worse runtime performance. That's absolutely the wrong tradeoff for release builds in large deployment, since it translates directly to either increased datacenter costs or reduced battery life on laptops\/mobile.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "acf65c259768",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-12-09\/6320751143555_acf65c259768ce3a90a4_72.jpg",
            "first_name": "",
            "real_name": "Jamie Brandon",
            "display_name": "jamii",
            "team": "T5TCAFTA9",
            "name": "jamie",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1723274705.524589",
        "parent_user_id": "U03U0SCU5LH",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RflCS",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "LLVM could certainly be faster (pointer heavy ir, lots of dynamic function calls for extensibility, mandatory linking phase even when only compiling a single compilation unit). I could believe getting a single order of magnitude improvement while achieving the same code quality.\n\nYou can also get 2-3 orders of magnitude improvement today from baseline compilers, but typically at the expense of 2-5x worse runtime performance. That's absolutely the wrong tradeoff for release builds in large deployment, since it translates directly to either increased datacenter costs or reduced battery life on laptops\/mobile."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U71PMQ1V0",
        "type": "message",
        "ts": "1723587918.175699",
        "client_msg_id": "d3d79b92-ac64-4e26-84ba-dad0e60374bd",
        "text": "Another consideration that's specific to c\/c++ is that if you count how many times your includes get duplicated, the compiler is probably dealing with far more lines of code than you actually wrote.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "acf65c259768",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-12-09\/6320751143555_acf65c259768ce3a90a4_72.jpg",
            "first_name": "",
            "real_name": "Jamie Brandon",
            "display_name": "jamii",
            "team": "T5TCAFTA9",
            "name": "jamie",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1723274705.524589",
        "parent_user_id": "U03U0SCU5LH",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "pgkUR",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Another consideration that's specific to c\/c++ is that if you count how many times your includes get duplicated, the compiler is probably dealing with far more lines of code than you actually wrote."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "point_up",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            },
            {
                "name": "point_up::skin-tone-3",
                "users": [
                    "U067RCH8NB0"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U71PMQ1V0",
        "type": "message",
        "ts": "1723588237.056619",
        "client_msg_id": "72d055bd-f7af-4df3-8c03-1cde095623ad",
        "text": "&gt; let's add some cache misses\nJust a guess, but with llvm being so pointer heavy I'd not be surprised if you have many more cache misses than you're guesstimating. If you have a fairly recent intel cpu you can measure both cache misses and instructions executed with `perf stat -e cycles,instructions,cache_misses -- $BUILD_MY_THING`.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "acf65c259768",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-12-09\/6320751143555_acf65c259768ce3a90a4_72.jpg",
            "first_name": "",
            "real_name": "Jamie Brandon",
            "display_name": "jamii",
            "team": "T5TCAFTA9",
            "name": "jamie",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1723274705.524589",
        "parent_user_id": "U03U0SCU5LH",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "GNr\/F",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "let's add some cache misses"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nJust a guess, but with llvm being so pointer heavy I'd not be surprised if you have many more cache misses than you're guesstimating. If you have a fairly recent intel cpu you can measure both cache misses and instructions executed with "
                            },
                            {
                                "type": "text",
                                "text": "perf stat -e cycles,instructions,cache_misses -- $BUILD_MY_THING",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]