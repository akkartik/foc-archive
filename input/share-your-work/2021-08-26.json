[
    {
        "user": "UFPRPSA4S",
        "type": "message",
        "ts": "1630036861.000200",
        "client_msg_id": "e11be478-26c2-4d89-9104-69ea741a3e2d",
        "text": "<@U01QUBNJSEQ>  Thanks for the thoughtful response!\n\n\"You said transclusion maps to the concept of variable in logic, but stripped of its naming mechanism. I wonder how you compensate for this loss? I believe having the ability to observe live updates through direct manipulation is not enough to capture the functionality of naming. Indeed there will often be an infinite domain of updates, and thus when you discover the system you cannot be sure that there isn't some particular update that results in different contents for the two regions. One solution would be to have clear visual indicators that distinguish transclusion from evaluation relations between regions, which might just be a manifestation of the special status of identity morphisms in category theory (which in turn correspond to the variables of type theory).\"\n\n    To jump ahead a little here, what I'm really after is applying these primitives back onto symbolic math, or to use them in combination with visuals. I think to do math without any symbolic variables would probably be more challenging in many contexts, but in order to develop these ideas I don't want symbolic variables to be a crutch. So at this point it is more of an artificial restriction I'm imposing to generate general principles.\n\n    That said, one idea is to really lean into \"visible connections\" component of transclusion as Ted Nelson would put it. That is, instead of the primitive being solely visible through the behavior it produces, there is an actual line or something connecting them that you can see. This may still not be as functional as naming variables, but its sufficient for expressing formal math without named variables, no? (I'm not trying to do without function symbols at this point)\n\n    So I think transclusion plays very well by itself. But once you start mixing it with evaluation I'm not sure how to distinguish them exactly. The two ideas floating around in my mind are (1) evaluation is something associated to particular regions which you still have contents transcluded into, its just that those contents are immediately operated on, and (2) evaluation is an arrow between regions and transclusion is just the identity. (Also, whats this about identity morphisms in category theory corresponding to variables in type theory? Is that like identity morphisms correspond to objects correspond to variables?)\n\n\"Evaluation looks like reactive evaluation of (pure) functions. How do you represent the function itself though in this paradigm? Do you have some kind of intensional description, or is it purely extensional as in Conal Elliott's Tangible Functional Programming, where you can only compose from a base of primitive combinators?\"\n\n    Hmm, my logic\/cs knowledge might not be up to snuff for these questions. I'm not entirely familiar with the intensional\/extensional distinction, and I only have a shallow understanding of Conal's paper, but saying its composing from a base of primitive combinators sounds about right.\n\n    Evaluation also might not be the best term for the kind of primitive I'm thinking about because often there isn't any expression that is being evaluated. Maybe \"dynamic functions\" would be a better term? For instance you would have an evaluation that \"evaluates\" the vector (2,3) to the visual vector in the xy plane. So at least some of these functions are primitives.\n\n    I also see how it would be desirable to be able to be able to construct these evaluation relations symbolically, although I haven't thought about how you would do this. But my suspicion is that there should be primitive combinators that let you build evaluation relations from symbolic relations.\n\n\"Is it related to the problem you raise of devising a visualization for concrete static terms built with functions? This is something I've thought about as the \"generic notation problem\", and as you say I firmly believe there is no ideal solution. I would even argue that a large part of mathematical creativity boils down to finding optimal representations, in the sense that our brains can manipulate without too much pain adequately general classes of objects, given adequately general purposes.\"\n\n    I wouldn't say its so related to this problem. Its related insofar as a visualization for terms of vector algebra is an evaluation relation. So there is the question of how to regard these evaluation relations generally and the question of which evaluation relation to use for visualizing terms of vector algebra.\n\n    If the visualization of a composite term depends only on the visualization of subterms and the visualization displays each of the intermediate values then static visualizations of concrete terms give you dynamic visualizations of abstract terms. I think its interesting to ask about properties of visualizations that we wouldn't normally consider, e.g. visualizing \"proj_c(a+b)\" not as the usual image, but with vectors a, b, c, that you can change, and vectors value(a+b), and value(proj_c(a+b)) that dynamically change depending on those values (i.e. every vector eminates from the origin). Using this schema are you able to recover the symbolic expression? I believe you can, but only if you have a known set of functions you are visualizing. Otherwise behavior alone isn't sufficient and you need to have some explicit way of referencing the dynamic functions that build up the visual term.\n\n    My interest in these visual proofs is a little stranger than I think it appears. I'm not so interested in the visualizations for their own sake, but as a source of patterns for new formal relations. I think interactive visualizations can not only serve as an independent formalism for vector algebra, but that they naturally express certain kinds of formal relations that surpass the expressivity of normal symbolic math and this is something that can be imported back into and enrich symbolic math. I see this as connected with expressing intertextual math or math involving many different formalisms at once and being able to move between them. This is really unsubstantiated at this point, but that's what I'm trying to work towards. Super weird right?\n\n\"So it even seems counterproductive to me to look for a generic notation, since the more general the class of object it captures, the less efficient it will be for our brain to process. What we can do however, and this is somewhat of a trend here on FoC, is design a system for building notations. It could be some kind of API mediating between high-level graphical representations and their low-level logical encoding, a sort of \"Notation Server Protocol\". The only example I can think of that comes close to this is the FIGUE engine developed at INRIA for the (now abandoned) CtCoq project, which was quite visionary since it is now 25 years old.\"\n\n    I feel like this is such a minimum of what is needed, but that we don't is a little mind blowing. But it also makes sense. Efforts to formalize math on computers are overwhelmingly aimed at ensuring there are no serious gaps in the dizzying heights of pure math, e.g. the recent liquid tensor experiment. It's not to transform how people think about math. If your goal is merely verification then you don't need that kind of an API.\n\n\"To conclude these lengthy reflections, a little bit of self-promotion: I am currently designing a visual language for building proofs in propositional logic, based on a biochemical metaphor of charged ions and cell membranes. For the moment I am more focused on its proof-theoretical properties, but it might prove to be quite intuitive if implemented right, and would make your language completely visual :slightly_smiling_face:. Interestingly its extension to predicate logic could also make use of the concept of transclusion...\"\n\n    Awesome, you better share more at some point though!",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g5f4ac5375e5",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f5f4ac5375e539e50ceedb08f65e9dd3.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png",
            "first_name": "",
            "real_name": "Robin Allison",
            "display_name": "Robin",
            "team": "T5TCAFTA9",
            "name": "robinps2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1628924185.049200",
        "parent_user_id": "UFPRPSA4S",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "XmKf",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U01QUBNJSEQ"
                            },
                            {
                                "type": "text",
                                "text": "  Thanks for the thoughtful response!\n\n\"You said transclusion maps to the concept of variable in logic, but stripped of its naming mechanism. I wonder how you compensate for this loss? I believe having the ability to observe live updates through direct manipulation is not enough to capture the functionality of naming. Indeed there will often be an infinite domain of updates, and thus when you discover the system you cannot be sure that there isn't some particular update that results in different contents for the two regions. One solution would be to have clear visual indicators that distinguish transclusion from evaluation relations between regions, which might just be a manifestation of the special status of identity morphisms in category theory (which in turn correspond to the variables of type theory).\"\n\n    To jump ahead a little here, what I'm really after is applying these primitives back onto symbolic math, or to use them in combination with visuals. I think to do math without any symbolic variables would probably be more challenging in many contexts, but in order to develop these ideas I don't want symbolic variables to be a crutch. So at this point it is more of an artificial restriction I'm imposing to generate general principles.\n\n    That said, one idea is to really lean into \"visible connections\" component of transclusion as Ted Nelson would put it. That is, instead of the primitive being solely visible through the behavior it produces, there is an actual line or something connecting them that you can see. This may still not be as functional as naming variables, but its sufficient for expressing formal math without named variables, no? (I'm not trying to do without function symbols at this point)\n\n    So I think transclusion plays very well by itself. But once you start mixing it with evaluation I'm not sure how to distinguish them exactly. The two ideas floating around in my mind are (1) evaluation is something associated to particular regions which you still have contents transcluded into, its just that those contents are immediately operated on, and (2) evaluation is an arrow between regions and transclusion is just the identity. (Also, whats this about identity morphisms in category theory corresponding to variables in type theory? Is that like identity morphisms correspond to objects correspond to variables?)\n\n\"Evaluation looks like reactive evaluation of (pure) functions. How do you represent the function itself though in this paradigm? Do you have some kind of intensional description, or is it purely extensional as in Conal Elliott's Tangible Functional Programming, where you can only compose from a base of primitive combinators?\"\n\n    Hmm, my logic\/cs knowledge might not be up to snuff for these questions. I'm not entirely familiar with the intensional\/extensional distinction, and I only have a shallow understanding of Conal's paper, but saying its composing from a base of primitive combinators sounds about right.\n\n    Evaluation also might not be the best term for the kind of primitive I'm thinking about because often there isn't any expression that is being evaluated. Maybe \"dynamic functions\" would be a better term? For instance you would have an evaluation that \"evaluates\" the vector (2,3) to the visual vector in the xy plane. So at least some of these functions are primitives.\n\n    I also see how it would be desirable to be able to be able to construct these evaluation relations symbolically, although I haven't thought about how you would do this. But my suspicion is that there should be primitive combinators that let you build evaluation relations from symbolic relations.\n\n\"Is it related to the problem you raise of devising a visualization for concrete static terms built with functions? This is something I've thought about as the \"generic notation problem\", and as you say I firmly believe there is no ideal solution. I would even argue that a large part of mathematical creativity boils down to finding optimal representations, in the sense that our brains can manipulate without too much pain adequately general classes of objects, given adequately general purposes.\"\n\n    I wouldn't say its so related to this problem. Its related insofar as a visualization for terms of vector algebra is an evaluation relation. So there is the question of how to regard these evaluation relations generally and the question of which evaluation relation to use for visualizing terms of vector algebra.\n\n    If the visualization of a composite term depends only on the visualization of subterms and the visualization displays each of the intermediate values then static visualizations of concrete terms give you dynamic visualizations of abstract terms. I think its interesting to ask about properties of visualizations that we wouldn't normally consider, e.g. visualizing \"proj_c(a+b)\" not as the usual image, but with vectors a, b, c, that you can change, and vectors value(a+b), and value(proj_c(a+b)) that dynamically change depending on those values (i.e. every vector eminates from the origin). Using this schema are you able to recover the symbolic expression? I believe you can, but only if you have a known set of functions you are visualizing. Otherwise behavior alone isn't sufficient and you need to have some explicit way of referencing the dynamic functions that build up the visual term.\n\n    My interest in these visual proofs is a little stranger than I think it appears. I'm not so interested in the visualizations for their own sake, but as a source of patterns for new formal relations. I think interactive visualizations can not only serve as an independent formalism for vector algebra, but that they naturally express certain kinds of formal relations that surpass the expressivity of normal symbolic math and this is something that can be imported back into and enrich symbolic math. I see this as connected with expressing intertextual math or math involving many different formalisms at once and being able to move between them. This is really unsubstantiated at this point, but that's what I'm trying to work towards. Super weird right?\n\n\"So it even seems counterproductive to me to look for a generic notation, since the more general the class of object it captures, the less efficient it will be for our brain to process. What we can do however, and this is somewhat of a trend here on FoC, is design a system for building notations. It could be some kind of API mediating between high-level graphical representations and their low-level logical encoding, a sort of \"Notation Server Protocol\". The only example I can think of that comes close to this is the FIGUE engine developed at INRIA for the (now abandoned) CtCoq project, which was quite visionary since it is now 25 years old.\"\n\n    I feel like this is such a minimum of what is needed, but that we don't is a little mind blowing. But it also makes sense. Efforts to formalize math on computers are overwhelmingly aimed at ensuring there are no serious gaps in the dizzying heights of pure math, e.g. the recent liquid tensor experiment. It's not to transform how people think about math. If your goal is merely verification then you don't need that kind of an API.\n\n\"To conclude these lengthy reflections, a little bit of self-promotion: I am currently designing a visual language for building proofs in propositional logic, based on a biochemical metaphor of charged ions and cell membranes. For the moment I am more focused on its proof-theoretical properties, but it might prove to be quite intuitive if implemented right, and would make your language completely visual "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            },
                            {
                                "type": "text",
                                "text": ". Interestingly its extension to predicate logic could also make use of the concept of transclusion...\"\n\n    Awesome, you better share more at some point though!"
                            }
                        ]
                    }
                ]
            }
        ]
    }
]