<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #of-ai</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <img src="https://avatars.slack-edge.com/2019-07-14/687915485201_6e649a383cf8f9e366e3_72.png" style="float:left"/>
      <a href="../of-ai/1691705709.739999.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Kartik Agaram</b>
<span style="margin:2em; color:#606060">2023-08-10 15:15</span><br/>
<b>Grokking</b><br/><br/>&gt; In 2021, researchers made a striking discovery while training a series of tiny models on toy tasks . They found a set of models that suddenly flipped from memorizing their training data to correctly generalizing on unseen inputs after training for much longer. This phenomenon – where generalization seems to happen abruptly and long after fitting the training data – is called <em>grokking</em> and has sparked a flurry of interest .<br/><a href="https://pair.withgoogle.com/explorables/grokking">https://pair.withgoogle.com/explorables/grokking</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1693862196.473809"></a>
      <img src="https://avatars.slack-edge.com/2021-09-13/2508698086192_565c54a4fa91a0c8c75a_72.png" style="float:left"/>
      <a href="../of-ai/1691705709.739999.html#1693862196.473809" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Tom Lieber</b>
<span style="margin:2em; color:#606060">2023-09-04 14:16</span><br/>
Oh wow, this is a better overview than the first paper I read on this. Thanks!
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
