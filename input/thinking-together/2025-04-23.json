[
    {
        "user": "U055V4HCHU7",
        "type": "message",
        "ts": "1745428951.557909",
        "client_msg_id": "fbea48ff-b589-491f-817c-0487147173fb",
        "text": "I agree that technical interviews are a weak approximation of holistic ability and generally contain mixed signals. What's worse is when those misleading signals are interpreted or factored into the assessment -- typing, code style, etc. I do worry it's easy to throw the baby out with the bath water, though. Without some indication of work product, you're stuck evaluating a candidate on 'vibes'. My favorite way to evaluate a candidate is to look at existing work product. Have they contributed to an OSS project and are those contributions something you'd be excited to receive. If so, done and dusted. That's not always an option though when someone has contributed to closed-source projects the bulk of their career.\n\nI think Marek's response is the most accurate: \"define what you want to measure first\"\n\n&gt; I don't believe that the person you interact with in the interview bares even a passing resemblance to the person they'll be after working with you for a month.\nAbsolutely! But I don't think these narrow technical interviews are not meant to assess the person holistically. If you're looking for a broad signal using a narrow test, you're likely doing the candidate a disservice and not setting them up for success. But if you're focusing on narrow goals -- does the candidate have a grasp of core fundamentals required to operate on relevant systems -- I think there still is meaningful signal to extract. Question is: how? Related, I think the responses \"I'm a slow typist\" and \"it's difficult to talk through intent with new people\" are orthogonal to the issue. A qualified interviewer isn't assessing typing speed and should factor in nerves.\n\n&gt; If you are going to insist on such an artificial, imperfect test of skill, why try and restrict it even further?\nI keep coming back to thinking about AP CompSci or similar academic courses. Most of those are still pencil + paper which feels like an extreme restriction. I have to assume the goal is to extract a candidates core understanding of underlying principles without assistance. The counter argument, the content you're assessing is targeted and narrow in contrast to a job interview.\n\nTo answer the question directly: in my opinion, you might restrict the test further if the inclusion of those restrictions would further muddle or hide the signals you intend to measure. Brings it back to: \"define what you want to measure first\"\n\n&gt; \"Should students be able to use a calculator on a math test?\"\nThis absolutely feels like a faulty parallelism. You still need to understanding _what_ you're typing into a calculator to get an accurate response.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "141ca9fd8fff",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-05-04\/5210750326597_141ca9fd8fff00418f9b_72.jpg",
            "first_name": "Walker",
            "real_name": "Walker Griggs",
            "display_name": "Walker Griggs",
            "team": "T5TCAFTA9",
            "name": "walker",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "C+QlK",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I agree that technical interviews are a weak approximation of holistic ability and generally contain mixed signals. What's worse is when those misleading signals are interpreted or factored into the assessment -- typing, code style, etc. I do worry it's easy to throw the baby out with the bath water, though. Without some indication of work product, you're stuck evaluating a candidate on 'vibes'. My favorite way to evaluate a candidate is to look at existing work product. Have they contributed to an OSS project and are those contributions something you'd be excited to receive. If so, done and dusted. That's not always an option though when someone has contributed to closed-source projects the bulk of their career.\n\nI think Marek's response is the most accurate: \"define what you want to measure first\"\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I don't believe that the person you interact with in the interview bares even a passing resemblance to the person they'll be after working with you for a month."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nAbsolutely! But I don't think these narrow technical interviews are not meant to assess the person holistically. If you're looking for a broad signal using a narrow test, you're likely doing the candidate a disservice and not setting them up for success. But if you're focusing on narrow goals -- does the candidate have a grasp of core fundamentals required to operate on relevant systems -- I think there still is meaningful signal to extract. Question is: how? Related, I think the responses \"I'm a slow typist\" and \"it's difficult to talk through intent with new people\" are orthogonal to the issue. A qualified interviewer isn't assessing typing speed and should factor in nerves.\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If you are going to insist on such an artificial, imperfect test of skill, why try and restrict it even further?"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nI keep coming back to thinking about AP CompSci or similar academic courses. Most of those are still pencil + paper which feels like an extreme restriction. I have to assume the goal is to extract a candidates core understanding of underlying principles without assistance. The counter argument, the content you're assessing is targeted and narrow in contrast to a job interview.\n\nTo answer the question directly: in my opinion, you might restrict the test further if the inclusion of those restrictions would further muddle or hide the signals you intend to measure. Brings it back to: \"define what you want to measure first\"\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\"Should students be able to use a calculator on a math test?\""
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This absolutely feels like a faulty parallelism. You still need to understanding "
                            },
                            {
                                "type": "text",
                                "text": "what",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " you're typing into a calculator to get an accurate response."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05GSC0B4A0",
        "type": "message",
        "ts": "1745429660.691069",
        "client_msg_id": "22f942dd-f672-4a97-a02b-d2bdfea336bd",
        "text": "I was actually just having this conversation with someone last night, and I think the \"standard\" interview questions of the past have kind of been used incorrectly as \"here's a problem, get it right you pass, get it wrong you fail\" when that doesn't matter that much - what you're really trying to assess is something closer to what Ivan is getting at: \"do they have an enthusiastic interest in programming?\" and \"have they kept up with what the latest is with people who have enthusiastic interests in programming?\", which has changed a lot over time.\n\nAt one time it was working with pointers, later it was working with hashes\/hash maps, these days its a lot of functional\/collection-based concepts now that a lot of languages hashes are a day 1 concept...\n\nFor me, the answer to your question is that how comfortable a candidate is at using AI in the interview is the primary thing I'm looking at. What techniques have they come up with or invented, how well do they know the different tools they're choosing and so on",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g6366d8630c4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6366d8630c4e2394142efb0a9358fcc6.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "Scott",
            "real_name": "Scott",
            "display_name": "Scott",
            "team": "T5TCAFTA9",
            "name": "scott099",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "rv3Iz",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I was actually just having this conversation with someone last night, and I think the \"standard\" interview questions of the past have kind of been used incorrectly as \"here's a problem, get it right you pass, get it wrong you fail\" when that doesn't matter that much - what you're really trying to assess is something closer to what Ivan is getting at: \"do they have an enthusiastic interest in programming?\" and \"have they kept up with what the latest is with people who have enthusiastic interests in programming?\", which has changed a lot over time.\n\nAt one time it was working with pointers, later it was working with hashes\/hash maps, these days its a lot of functional\/collection-based concepts now that a lot of languages hashes are a day 1 concept...\n\nFor me, the answer to your question is that how comfortable a candidate is at using AI in the interview is the primary thing I'm looking at. What techniques have they come up with or invented, how well do they know the different tools they're choosing and so on"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U088999PF62",
        "type": "message",
        "ts": "1745430266.003449",
        "client_msg_id": "A1422017-E785-46F3-81EE-807F195BD5B8",
        "text": "I’ve always struggled with interviews, even on easyish questions. I can’t really talk with someone while coding or get the right answer straight away. When I actually code for myself, I’ll sort of vibe-out (not vibe code) and try molding what I’m doing.\nJust… super unnatural to think out-loud because if I’m explaining out-loud, I’m not thinking. I’m in some zombie presenter state. Parallel processing issue?\n\nI wish I could pass some of these interviews.\n\nshameless plug: looking for collaborations on creative cool things. Feelings of computing indeed",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "ee4ab31ddf7a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2025-01-13\/8273414548951_ee4ab31ddf7a86143d34_72.jpg",
            "first_name": "Karl",
            "real_name": "Karl Toby Rosenberg",
            "display_name": "Karl Toby Rosenberg",
            "team": "T5TCAFTA9",
            "name": "karltobyrosenberg",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Juvf8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I"
                            },
                            {
                                "type": "text",
                                "text": "’"
                            },
                            {
                                "type": "text",
                                "text": "ve always struggled with interviews, even on easyish questions. I can’t really talk with someone while coding or get the right answer straight away. When I actually code for myself, I’ll sort of vibe-out (not vibe code) and try molding what I’m doing.\nJust"
                            },
                            {
                                "type": "text",
                                "text": "…"
                            },
                            {
                                "type": "text",
                                "text": " super unnatural to think out-loud because if I’m explaining out-loud, I’m not thinking. I’m in some zombie presenter state. Parallel processing issue?\n\nI wish I could pass some of these interviews.\n\nshameless plug: looking for collaborations on creative cool things. Feelings of computing indeed"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UC2A2ARPT",
                    "U055V4HCHU7"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "U04R217NVNF",
        "type": "message",
        "ts": "1745430535.826619",
        "client_msg_id": "af99fe1a-ba6f-49a8-b0dd-4698278fa26f",
        "text": "&gt;&gt; \"Should students be able to use a calculator on a math test?\"\n&gt; This absolutely feels like a faulty parallelism. You still need to understanding _what_ you're typing into a calculator to get an accurate response.\nWell, yes, of course, which is exactly my point. If you want to test someone's ability to hand calculate, you have to remove the calculator. But if you want to test if someone knows how to approach answering the question, regardless of their ability to calculate, you probably allow a calculator (I feel like I might have been a civil engineer except for my tendency for hand written calculations in college to have an off-by-one or switched sign error, something that a computer would not have done - I was using the correct formula... but probably I'm just bitter about my own past mistakes)\n\nI actually think using an LLM can potentially tell you more about how a candidate thinks, since it may generate a solution that needs to be refactored or tweaked because it doesn't handle all of the edge cases you'd want, which is something you wouldn't see in a standard technical interview. But it's also something you have less control over as an interviewer, since you don't know what the LLM will produce.\n\nIn any case, I think this question will be less and less relevant in the future as LLMs and tools improve and eventually there will just be an expectation that everyone uses them.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gd1b75afd06b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/d1b75afd06b4c1046802cb49a05e3d7d.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "Bart",
            "real_name": "Bart Agapinan",
            "display_name": "Bart Agapinan",
            "team": "T5TCAFTA9",
            "name": "bart",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "acJM\/",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\"Should students be able to use a calculator on a math test?\""
                            }
                        ],
                        "border": 1
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This absolutely feels like a faulty parallelism. You still need to understanding "
                            },
                            {
                                "type": "text",
                                "text": "what",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " you're typing into a calculator to get an accurate response."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Well, yes, of course, which is exactly my point. If you want to test someone's ability to hand calculate, you have to remove the calculator. But if you want to test if someone knows how to approach answering the question, regardless of their ability to calculate, you probably allow a calculator (I feel like I might have been a civil engineer except for my tendency for hand written calculations in college to have an off-by-one or switched sign error, something that a computer would not have done - I was using the correct formula... but probably I'm just bitter about my own past mistakes)\n\nI actually think using an LLM can potentially tell you more about how a candidate thinks, since it may generate a solution that needs to be refactored or tweaked because it doesn't handle all of the edge cases you'd want, which is something you wouldn't see in a standard technical interview. But it's also something you have less control over as an interviewer, since you don't know what the LLM will produce.\n\nIn any case, I think this question will be less and less relevant in the future as LLMs and tools improve and eventually there will just be an expectation that everyone uses them."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "amiga-tick",
                "users": [
                    "U055V4HCHU7"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U055V4HCHU7",
        "type": "message",
        "ts": "1745430632.791599",
        "client_msg_id": "d84c843f-c5d9-43c5-9e09-d31acf49444f",
        "text": "&gt; For me, the answer to your question is that how comfortable a candidate is at using AI in the interview is the primary thing I'm looking at.\nInteresting, so you like to double down and evaluate the candidates use of AI as a tool in the modern toolbelt? That's aligned with the feedback I've heard of \"a productive engineer should always leverage the best tools\".\n\n&gt; At one time it was working with pointers, later it was working with hashes\/hash maps, these days its a lot of functional\/collection-based concepts now that a lot of languages hashes are a day 1 concept...\nI often think about this too! My framing is generally in terms of \"abstraction layers\". I like to ask myself \"does this candidate understand one or two layers below the surface\" or \"could they explain how N is meant to work.\" Sorta like Gary Bernhardt's \"Destroy All Software\" project. As we add new abstraction layers though, the relative \"fundamentals\" follow as well",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "141ca9fd8fff",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-05-04\/5210750326597_141ca9fd8fff00418f9b_72.jpg",
            "first_name": "Walker",
            "real_name": "Walker Griggs",
            "display_name": "Walker Griggs",
            "team": "T5TCAFTA9",
            "name": "walker",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "VBARq",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "For me, the answer to your question is that how comfortable a candidate is at using AI in the interview is the primary thing I'm looking at."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nInteresting, so you like to double down and evaluate the candidates use of AI as a tool in the modern toolbelt? That's aligned with the feedback I've heard of \"a productive engineer should always leverage the best tools\".\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "At one time it was working with pointers, later it was working with hashes\/hash maps, these days its a lot of functional\/collection-based concepts now that a lot of languages hashes are a day 1 concept..."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nI often think about this too! My framing is generally in terms of \"abstraction layers\". I like to ask myself \"does this candidate understand one or two layers below the surface\" or \"could they explain how N is meant to work.\" Sorta like Gary Bernhardt's \"Destroy All Software\" project. As we add new abstraction layers though, the relative \"fundamentals\" follow as well"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U088999PF62",
        "type": "message",
        "ts": "1745430701.472779",
        "edited": {
            "user": "U088999PF62",
            "ts": "1745430805.000000"
        },
        "client_msg_id": "C3030B50-A7DD-4C25-8A20-2CDE5FB7732B",
        "text": "The calculator analogy doesn’t work and I’ve seen it so many times.\n\nI think using an LLM is harder than just solving it on your own because now you have to debug the output and check for errors in something that you might not even fully understand. I’d want to evaluate someone based on how they design a solution to a problem end to end, even if there are fumbles. \n\nI wouldn’t expect everyone to use these since they can easily introduce technical debt.\n\nIf anything, you could introduce using a model\/any automation tool as part of an interview to see how someone adapts to learning a new tool. See how someone pokes at something.\n\nBut in the end I want to know how someone is when they’re thinking through something with me, as if the tools and supports weren’t there. (I wouldn’t consider an llm a great support for many problems anyway.) An ideal interview is collaborative towards solving a problem and designing something.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "ee4ab31ddf7a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2025-01-13\/8273414548951_ee4ab31ddf7a86143d34_72.jpg",
            "first_name": "Karl",
            "real_name": "Karl Toby Rosenberg",
            "display_name": "Karl Toby Rosenberg",
            "team": "T5TCAFTA9",
            "name": "karltobyrosenberg",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "8Z3MF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The calculator analogy doesn’t work and I’ve seen it so many times.\n\nI think using an LLM is harder than just solving it on your own because now you have to debug the output and check for errors in something that you might not even fully understand. I’d want to evaluate someone based on how they design a solution to a problem end to end, even if there are fumbles. \n\nI wouldn’t expect everyone to use these since they can easily introduce technical debt.\n\nIf anything, you could introduce using a model\/any automation tool as part of an interview to see how someone adapts to learning a new tool. See how someone pokes at something."
                            },
                            {
                                "type": "text",
                                "text": "\n\nBut in the end I want to know how someone is when they’re thinking through something with me, as if the tools and supports weren’t there. (I wouldn’t consider an llm a great support for many problems anyway.) An ideal interview is collaborative towards solving a problem and designing something."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U055V4HCHU7",
        "type": "message",
        "ts": "1745430957.045579",
        "client_msg_id": "2ef68f67-8ad8-4441-be9c-10e340396d2c",
        "text": "&gt;&gt; \"Should students be able to use a calculator on a math test?\"\n&gt;&gt; This absolutely feels like a faulty parallelism. You still need to understanding _what_ you're typing into a calculator to get an accurate response.\n&gt; Well, yes, of course, which is exactly my point. If you want to test someone's ability to hand calculate, you have to remove the calculator. But if you want to test if someone knows how to approach answering the question, regardless of their ability to calculate, you probably allow a calculator\nI see what you're getting at! Sorry I think I misunderstood your initial response. This framing on aligns with, I think, what I just posted about \"relative levels of abstractions.\" The \"fundamentals\" are relative to the current tools of art.\n\nDo you think it's important a candidate understands an increasing relative depth as the tools become further removed from the core technology. For example, I could argue it's important for an eng to understand the trade offs between \"passing by value vs reference\" regardless of how advanced the tools become",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "141ca9fd8fff",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-05-04\/5210750326597_141ca9fd8fff00418f9b_72.jpg",
            "first_name": "Walker",
            "real_name": "Walker Griggs",
            "display_name": "Walker Griggs",
            "team": "T5TCAFTA9",
            "name": "walker",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "oLcaL",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\"Should students be able to use a calculator on a math test?\""
                            }
                        ],
                        "border": 1
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This absolutely feels like a faulty parallelism. You still need to understanding "
                            },
                            {
                                "type": "text",
                                "text": "what",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " you're typing into a calculator to get an accurate response."
                            }
                        ],
                        "border": 1
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Well, yes, of course, which is exactly my point. If you want to test someone's ability to hand calculate, you have to remove the calculator. But if you want to test if someone knows how to approach answering the question, regardless of their ability to calculate, you probably allow a calculator"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nI see what you're getting at! Sorry I think I misunderstood your initial response. This framing on aligns with, I think, what I just posted about \"relative levels of abstractions.\" The \"fundamentals\" are relative to the current tools of art.\n\nDo you think it's important a candidate understands an increasing relative depth as the tools become further removed from the core technology. For example, I could argue it's important for an eng to understand the trade offs between \"passing by value vs reference\" regardless of how advanced the tools become"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U055V4HCHU7",
        "type": "message",
        "ts": "1745431135.596999",
        "edited": {
            "user": "U055V4HCHU7",
            "ts": "1745431163.000000"
        },
        "client_msg_id": "bed9b442-fda2-41c1-8087-cddcb2b2fe5a",
        "text": "> But in the end I want to know how someone is when they’re thinking through something with me\n:heavy_plus_sign: I've never dinged a candidate for not completing the given problem if they've demonstrated a solid understanding of the problem, have articulated their approach clearly, laid out a framework for success etc. I suppose, this is true and possible regardless if the candidate uses AI or not\n\nIn the end of the day, it's conversation. \"Does it compile and pass tests\" is a stinky approach.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "141ca9fd8fff",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-05-04\/5210750326597_141ca9fd8fff00418f9b_72.jpg",
            "first_name": "Walker",
            "real_name": "Walker Griggs",
            "display_name": "Walker Griggs",
            "team": "T5TCAFTA9",
            "name": "walker",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "9mxDT",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "But in the end I want to know how someone is when they’re thinking through something with me"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "emoji",
                                "name": "heavy_plus_sign",
                                "unicode": "2795"
                            },
                            {
                                "type": "text",
                                "text": " I've never dinged a candidate for not completing the given problem if they've demonstrated a solid understanding of the problem, have articulated their approach clearly, laid out a framework for success etc. I suppose, this is true and possible regardless if the candidate uses AI or not\n\nIn the end of the day, it's conversation. \"Does it compile and pass tests\" is a stinky approach."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U088999PF62",
        "type": "message",
        "ts": "1745431211.454329",
        "client_msg_id": "516B8096-B098-49D3-95C8-76B9F78073B5",
        "text": "Yeah, agreed, although I think using ai skips the point of explaining your thought process. Granted, I’ve struggled with multiprocessing thinking and explaining during such interviews.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "ee4ab31ddf7a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2025-01-13\/8273414548951_ee4ab31ddf7a86143d34_72.jpg",
            "first_name": "Karl",
            "real_name": "Karl Toby Rosenberg",
            "display_name": "Karl Toby Rosenberg",
            "team": "T5TCAFTA9",
            "name": "karltobyrosenberg",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "dHCPs",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah, agreed, although I think using ai skips the point of explaining your thought process. Granted, I’ve struggled with multiprocessing thinking and explaining during such interviews."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05GSC0B4A0",
        "type": "message",
        "ts": "1745431219.038029",
        "client_msg_id": "c66742a2-b43a-4833-991c-6bd0db104c78",
        "text": "&gt; Interesting, so you like to double down and evaluate the candidates use of AI as a tool in the modern toolbelt?\nYeah exactly, LLMs and LLM-based coding requires a much different mindset and is so new that best practices are still being discovered. I suspect it's going to be a long time before it feels like we really know what we're doing again, so someone who's curious and experimenting and testing out ideas (or keeping up with the latest ones and incorporating them into their process) would be my primary criteria right now...\n\n&gt; As we add new abstraction layers though, the relative \"fundamentals\" follow as well\nYeah, it's an exciting time to see this new layer form :slightly_smiling_face:",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g6366d8630c4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6366d8630c4e2394142efb0a9358fcc6.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "Scott",
            "real_name": "Scott",
            "display_name": "Scott",
            "team": "T5TCAFTA9",
            "name": "scott099",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "KqqE+",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Interesting, so you like to double down and evaluate the candidates use of AI as a tool in the modern toolbelt?"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah exactly, LLMs and LLM-based coding requires a much different mindset and is so new that best practices are still being discovered. I suspect it's going to be a long time before it feels like we really know what we're doing again, so someone who's curious and experimenting and testing out ideas (or keeping up with the latest ones and incorporating them into their process) would be my primary criteria right now...\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "As we add new abstraction layers though, the relative \"fundamentals\" follow as well"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah, it's an exciting time to see this new layer form "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04R217NVNF",
        "type": "message",
        "ts": "1745433661.271599",
        "client_msg_id": "27222589-2618-4b35-81c8-19d23073c26a",
        "text": "&gt; I think using an LLM is harder than just solving it on your own because now you have to debug the output and check for errors in something that you might not even fully understand. I’d want to evaluate someone based on how they design a solution to a problem end to end, even if there are fumbles.\nYeah, but here you're also describing \"legacy code\", which I'd assume your current code base has plenty of.\n\nBut also, I think LLMs are probably a better fit for well known domains where there's a lot of training data, and I imagine the audience of this slack may skew toward more novel domains where the LLMs just give nonsense recommendations",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gd1b75afd06b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/d1b75afd06b4c1046802cb49a05e3d7d.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "Bart",
            "real_name": "Bart Agapinan",
            "display_name": "Bart Agapinan",
            "team": "T5TCAFTA9",
            "name": "bart",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "LywqZ",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think using an LLM is harder than just solving it on your own because now you have to debug the output and check for errors in something that you might not even fully understand. I’d want to evaluate someone based on how they design a solution to a problem end to end, even if there are fumbles."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah, but here you're also describing \"legacy code\", which I'd assume your current code base has plenty of.\n\nBut also, I think LLMs are probably a better fit for well known domains where there's a lot of training data, and I imagine the audience of this slack may skew toward more novel domains where the LLMs just give nonsense recommendations"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U088999PF62",
        "type": "message",
        "ts": "1745433813.526329",
        "client_msg_id": "5C091B8C-BBB7-4244-8B19-DAE6EA360309",
        "text": "Yes, nonsense recommendations in novel domains. Also, yes, legacy code is probably comparable, but I don’t know if I’d want to evaluate someone trying to look at the equivalent of legacy code rather than coming-up with something together. An llm in the middle seems a bit weird. “Hold on interviewer, I have to inspect this code.” Leaves a bit of an awkward gap versus just showing the full thought process. I’m of course a bit guilty of disliking the common process for other reasons.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "ee4ab31ddf7a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2025-01-13\/8273414548951_ee4ab31ddf7a86143d34_72.jpg",
            "first_name": "Karl",
            "real_name": "Karl Toby Rosenberg",
            "display_name": "Karl Toby Rosenberg",
            "team": "T5TCAFTA9",
            "name": "karltobyrosenberg",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "\/r5A3",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yes, nonsense recommendations in novel domains. Also, yes, legacy code is probably comparable, but I don’t know if I’d want to evaluate someone trying to look at the equivalent of legacy code rather than coming-up with something together. An llm in the middle seems a bit weird. “Hold on interviewer, I have to inspect this code.” Leaves a bit of an awkward gap versus just showing the full thought process. I’m of course a bit guilty of disliking the common process for other reasons."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UCUSW7WVD",
        "type": "message",
        "ts": "1745437296.940499",
        "client_msg_id": "584d2e02-74a2-44da-8616-3345f54a1855",
        "text": "One thing I didn't think of when this thread was created, and now it's too late to do anything about it, but just for reference: I think this thread belongs in <#C01932BJGE8|present-company>. Not because it's about AI, but because it's about interviews.\n\nWith that assumption I have a couple of things to say:\n\n• I've always punched above my weight class in coding interviews. Which is to say, employers who hired me on the basis of a coding interview usually over-estimated my capabilities. I think this one skill has contributed more to my personal bottom line than anything else. So I'm a long-time benefactor of dysfunctional interviewing practices.\n• I'm currently preparing for an interview at a place that requires a coding interview at the level of \"leetcode medium or hard.\" Leetcode hard is _really_ hard. There is no way in hell I can do a leetcode hard problem in 60 minutes. In fact, if I get a leetcode hard problem I suspect the interviewer is mostly going to see me hemming and hawing for 60 minutes. If I wasn't stuck at a desk in front of a window containing a camera feed I'd be lying down, or pacing the room, or tossing a ball against a wall. At least in person interviews let me scribble on a whiteboard.\n• I've had to deal with leetcode hard interviews before, but it was usually a surprise in the past, and those employers weeded themselves out of my consideration. I've never tried to _train_ for this level. And it has given me greater empathy for others who haven't had my good luck, those who are penalized rather than advantaged by the current interview process. Like the people who need to toss a ball against a wall for leetcode medium problems. The problems themselves are fun, but they seem terrible in the context of an interview.\n• It's all very well to say companies aren't doing interviews right. But what matters is the practice, not the ideal. Companies hire engineers, not \"qualified interviewers.\" As an industry we have no rigorous rubric for interviewers, for their knowledge, their discernment, their curiosity about a candidate, their motivation to tease apart fine detail. For the most part, doing interviews well is not a priority for companies, and it's not clear that it should be. It doesn't obviously increase their fitness to their environment. It's not clear to me that adding LLMs changes that equation. Though it's still early days and there are going to be tons of uses for LLMs that my puny brain can't even conceive of right now.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6e649a383cf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_72.png",
            "first_name": "Kartik",
            "real_name": "Kartik Agaram",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ak",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1745342441.727629",
        "parent_user_id": "U055V4HCHU7",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "TvcOm",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "One thing I didn't think of when this thread was created, and now it's too late to do anything about it, but just for reference: I think this thread belongs in "
                            },
                            {
                                "type": "channel",
                                "channel_id": "C01932BJGE8"
                            },
                            {
                                "type": "text",
                                "text": ". Not because it's about AI, but because it's about interviews.\n\nWith that assumption I have a couple of things to say:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "I've always punched above my weight class in coding interviews. Which is to say, employers who hired me on the basis of a coding interview usually over-estimated my capabilities. I think this one skill has contributed more to my personal bottom line than anything else. So I'm a long-time benefactor of dysfunctional interviewing practices."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "I'm currently preparing for an interview at a place that requires a coding interview at the level of \"leetcode medium or hard.\" Leetcode hard is "
                                    },
                                    {
                                        "type": "text",
                                        "text": "really",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " hard. There is no way in hell I can do a leetcode hard problem in 60 minutes. In fact, if I get a leetcode hard problem I suspect the interviewer is mostly going to see me hemming and hawing for 60 minutes. If I wasn't stuck at a desk in front of a window containing a camera feed I'd be lying down, or pacing the room, or tossing a ball against a wall. At least in person interviews let me scribble on a whiteboard."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "I've had to deal with leetcode hard interviews before, but it was usually a surprise in the past, and those employers weeded themselves out of my consideration. I've never tried to "
                                    },
                                    {
                                        "type": "text",
                                        "text": "train",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " for this level. And it has given me greater empathy for others who haven't had my good luck, those who are penalized rather than advantaged by the current interview process. Like the people who need to toss a ball against a wall for leetcode medium problems. The problems themselves are fun, but they seem terrible in the context of an interview."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "It's all very well to say companies aren't doing interviews right. But what matters is the practice, not the ideal. Companies hire engineers, not \"qualified interviewers.\" As an industry we have no rigorous rubric for interviewers, for their knowledge, their discernment, their curiosity about a candidate, their motivation to tease apart fine detail. For the most part, doing interviews well is not a priority for companies, and it's not clear that it should be. It doesn't obviously increase their fitness to their environment. It's not clear to me that adding LLMs changes that equation. Though it's still early days and there are going to be tons of uses for LLMs that my puny brain can't even conceive of right now."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    }
                ]
            }
        ]
    }
]