[
    {
        "user": "U04TXPZ1W3S",
        "type": "message",
        "ts": "1680724848.632619",
        "edited": {
            "user": "U04TXPZ1W3S",
            "ts": "1680724902.000000"
        },
        "client_msg_id": "969a7d90-a02e-4e00-885d-128267b9b409",
        "text": "So is it the case that `langchain` and `agents` are specifically built prompt templates that are backed with some fun interprocess coms, passing the results to various piped tools like a python \/ JS script to get the next ‘prompt piece’, and then looping until something ‘correct’ comes up? I feel <https:\/\/github.com\/mpaepper\/llm_agents> simplified the abstractions a bit to help me understand what was going on.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "ba2110196f92",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-03-09\/4949815203584_ba2110196f92edcddbbb_72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Lugo",
            "display_name": "Ivan Lugo",
            "team": "T5TCAFTA9",
            "name": "lugo",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xVy=",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So is it the case that "
                            },
                            {
                                "type": "text",
                                "text": "langchain",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " and "
                            },
                            {
                                "type": "text",
                                "text": "agents",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " are specifically built prompt templates that are backed with some fun interprocess coms, passing the results to various piped tools like a python \/ JS script to get the next ‘prompt piece’, and then looping until something ‘correct’ comes up? I feel "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/mpaepper\/llm_agents"
                            },
                            {
                                "type": "text",
                                "text": " simplified the abstractions a bit to help me understand what was going on."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U04LK1R1VC1"
                ],
                "count": 1
            }
        ]
    }
]