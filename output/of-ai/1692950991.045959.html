<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #of-ai</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <img src="https://avatars.slack-edge.com/2021-03-12/1859691333940_e169f54bbaf8b9b36b12_72.png" style="float:left"/>
      <a href="../of-ai/1692950991.045959.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Konrad Hinsen</b>
<span style="margin:2em; color:#606060">2023-08-25 01:09</span><br/>
An interesting take on AI risk: <a href="https://metamoderna.org/what-can-stop-the-ai-apocalypse-grammar-yes-only-grammar/">https://metamoderna.org/what-can-stop-the-ai-apocalypse-gram&hellip;</a><br/><br/>The vision exposed in this article is that humans with their institutional superstructures (bureaucracies, markets, corporations, ...) and AIs (plural) will/should form an ecosystem in which all players coevolve, competing and collaborating at the same time. I don't think that any of the players are ready for this, but in the long run, this is where we could be heading.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1692988394.796729"></a>
      <img src="https://avatars.slack-edge.com/2023-10-13/6057269405632_8ea58fc41bd6baa7dda6_72.png" style="float:left"/>
      <a href="../of-ai/1692950991.045959.html#1692988394.796729" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jack Rusher</b>
<span style="margin:2em; color:#606060">2023-08-25 11:33</span><br/>
Weâ€™ll need some research that could plausibly generate AIs first, I suppose.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1693010103.232919"></a>
      <img src="https://avatars.slack-edge.com/2019-07-14/687915485201_6e649a383cf8f9e366e3_72.png" style="float:left"/>
      <a href="../of-ai/1692950991.045959.html#1693010103.232919" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Kartik Agaram</b>
<span style="margin:2em; color:#606060">2023-08-25 17:35</span><br/>
What did I just read!<br/><br/>Can someone post a summary that doesn't require understanding Lacan/Derrida/et al.?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1693073215.779249"></a>
      <img src="https://avatars.slack-edge.com/2021-03-12/1859691333940_e169f54bbaf8b9b36b12_72.png" style="float:left"/>
      <a href="../of-ai/1692950991.045959.html#1693073215.779249" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Konrad Hinsen</b>
<span style="margin:2em; color:#606060">2023-08-26 11:06</span><br/>
<span style="background-color:#ccf">@Jack Rusher</span> What's nice about this analysis is that it doesn't really rely on any specific notion of what AI is. "Large-scale information processing system" is all it takes.<br/><span style="background-color:#ccf">@Kartik Agaram</span> Well, the author is a sociologist, and that shows in some places. I just skip the references and try to make sense of what's left, which works pretty well for me.
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
