[
    {
        "user": "U04JY2BF24E",
        "type": "message",
        "ts": "1686770339.927269",
        "client_msg_id": "45017e9e-6374-4be3-81e4-4d267980071d",
        "text": "This might fall under \"thinking-together\", but I'm throwing this here as it specifically relates to AI. For context, I've been working to integrate an LLM into an existing application.  If \"prompt engineering\" is part of the future of coding, here are some challenges to expect:\n• **Non determinism:** I can repeat a prompt and get back drastically different results, in both content and format.\n• **Capabilities:** I feel like I'm constantly probing to discover the capabilities and limits of the model. Every interaction is similar to being presented with a blank canvas: What should I ask? What can I ask? Is there something that I could ask that I am forgetting about? Can I reword my prompt slightly and (potentially) get better results? This leads to a lot of experimentation.\n• **Expectations**: We are tricked into believing the LLM comprehends what we are saying, when it's really just a giant prediction table. Then we are disappointed when it gives less-than-satisfactory replies.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "154a9d12968c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-06-13\/5441522160256_154a9d12968ca5a13cf5_72.jpg",
            "first_name": "Greg",
            "real_name": "Greg Bylenok",
            "display_name": "Greg Bylenok",
            "team": "T5TCAFTA9",
            "name": "gregory.bylenok",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1686770339.927269",
        "reply_count": 13,
        "reply_users_count": 5,
        "latest_reply": "1687168091.120419",
        "reply_users": [
            "U0296ACR13M",
            "U04KZ8A9WCT",
            "U04JY2BF24E",
            "U02U0AS3J49",
            "UA14TGLTC"
        ],
        "replies": [
            {
                "user": "U0296ACR13M",
                "ts": "1686809890.747819"
            },
            {
                "user": "U04KZ8A9WCT",
                "ts": "1686810888.808929"
            },
            {
                "user": "U04KZ8A9WCT",
                "ts": "1686810926.193009"
            },
            {
                "user": "U04KZ8A9WCT",
                "ts": "1686810995.848789"
            },
            {
                "user": "U04KZ8A9WCT",
                "ts": "1686811021.697139"
            },
            {
                "user": "U04JY2BF24E",
                "ts": "1686836109.101449"
            },
            {
                "user": "U04KZ8A9WCT",
                "ts": "1686838763.504369"
            },
            {
                "user": "U04KZ8A9WCT",
                "ts": "1686838800.820169"
            },
            {
                "user": "U04KZ8A9WCT",
                "ts": "1686838849.039929"
            },
            {
                "user": "U04KZ8A9WCT",
                "ts": "1686838904.022879"
            },
            {
                "user": "U02U0AS3J49",
                "ts": "1686943601.369219"
            },
            {
                "user": "U02U0AS3J49",
                "ts": "1686943664.451089"
            },
            {
                "user": "UA14TGLTC",
                "ts": "1687168091.120419"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "LjFZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This might fall under \"thinking-together\", but I'm throwing this here as it specifically relates to AI. For context, I've been working to integrate an LLM into an existing application.  If \"prompt engineering\" is part of the future of coding, here are some challenges to expect:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "*"
                                    },
                                    {
                                        "type": "text",
                                        "text": "Non determinism:",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": "* I can repeat a prompt and get back drastically different results, in both content and format."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "*"
                                    },
                                    {
                                        "type": "text",
                                        "text": "Capabilities:",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": "* I feel like I'm constantly probing to discover the capabilities and limits of the model. Every interaction is similar to being presented with a blank canvas: What should I ask? What can I ask? Is there something that I could ask that I am forgetting about? Can I reword my prompt slightly and (potentially) get better results? This leads to a lot of experimentation."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "*"
                                    },
                                    {
                                        "type": "text",
                                        "text": "Expectations",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": "*: We are tricked into believing the LLM comprehends what we are saying, when it's really just a giant prediction table. Then we are disappointed when it gives less-than-satisfactory replies."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    }
                ]
            }
        ]
    },
    {
        "user": "U04JY2BF24E",
        "type": "message",
        "ts": "1686770353.667069",
        "client_msg_id": "8a43fc4f-db2c-4edf-82b9-454ea96e597d",
        "text": "Compare this to programming against a traditional API:\n• On in the input side, an API constrains the vocabulary. With an LLM, everything is fair game.\n• On the output side, I can guess (or learn) the effect of a given API call. With an LLM, it's all probabilistic.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "154a9d12968c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-06-13\/5441522160256_154a9d12968ca5a13cf5_72.jpg",
            "first_name": "Greg",
            "real_name": "Greg Bylenok",
            "display_name": "Greg Bylenok",
            "team": "T5TCAFTA9",
            "name": "gregory.bylenok",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "AFXk",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Compare this to programming against a traditional API:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "On in the input side, an API constrains the vocabulary. With an LLM, everything is fair game."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "On the output side, I can guess (or learn) the effect of a given API call. With an LLM, it's all probabilistic."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U04JY2BF24E",
        "type": "message",
        "ts": "1686770389.841669",
        "edited": {
            "user": "U04JY2BF24E",
            "ts": "1686770463.000000"
        },
        "client_msg_id": "4b9aeee8-f1a2-4bed-a7ca-317d046b2927",
        "text": "Curious about others experiences here, ways to reason about these models, techniques for overcoming, etc...",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "154a9d12968c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-06-13\/5441522160256_154a9d12968ca5a13cf5_72.jpg",
            "first_name": "Greg",
            "real_name": "Greg Bylenok",
            "display_name": "Greg Bylenok",
            "team": "T5TCAFTA9",
            "name": "gregory.bylenok",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "elwq2",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Curious about others experiences here, ways to reason about these models, techniques for overcoming, etc..."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0296ACR13M",
        "type": "message",
        "ts": "1686809890.747819",
        "edited": {
            "user": "U0296ACR13M",
            "ts": "1686810614.000000"
        },
        "client_msg_id": "79e75e2a-9bc0-4363-a700-a1dbeaf81060",
        "text": "I feel that one barrier to even starting to approach a coding task with LLM code generation is the uncertainty of how much effort it will be to end up with something satisfactory. If you're an experienced programmer you'll have a ballpark idea of the code you have to write and how much effort it will be beforehand. Also, you'll have a much better understanding of whether you're making progress or just heading towards a dead end. It's like choosing a familiar road you know gets you to your destination in an hour vs a road you have heard might take you there in 30 min, but just as likely you'll get lost and reach your destination in 2 hours.\n\nNow, this would be different for someone who has very little experience with coding. If you know none of the roads, you'd probably choose the one you've heard is the shortest. Also, there will be people who have more experience with LLM code generation than manual coding. It'll be interesting to see how they see this. Will people who start programming with heavy usage of LLM code generation stick to that or move towards manual coding as they gain experience.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "59de929720a2",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-09-08\/4075674207584_59de929720a2fe0a13d8_72.jpg",
            "first_name": "",
            "real_name": "Jarno Montonen",
            "display_name": "Jarno Montonen",
            "team": "T5TCAFTA9",
            "name": "jarno.montonen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1686770339.927269",
        "parent_user_id": "U04JY2BF24E",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Eda=",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I feel that one barrier to even starting to approach a coding task with LLM code generation is the uncertainty of how much effort it will be to end up with something satisfactory. If you're an experienced programmer you'll have a ballpark idea of the code you have to write and how much effort it will be beforehand. Also, you'll have a much better understanding of whether you're making progress or just heading towards a dead end. It's like choosing a familiar road you know gets you to your destination in an hour vs a road you have heard might take you there in 30 min, but just as likely you'll get lost and reach your destination in 2 hours.\n\nNow, this would be different for someone who has very little experience with coding. If you know none of the roads, you'd probably choose the one you've heard is the shortest. Also, there will be people who have more experience with LLM code generation than manual coding. It'll be interesting to see how they see this. Will people who start programming with heavy usage of LLM code generation stick to that or move towards manual coding as they gain experience."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04KZ8A9WCT",
        "type": "message",
        "ts": "1686810888.808929",
        "client_msg_id": "9BD14F1C-6756-4EB7-B98A-0B1F5F1F3276",
        "text": "&gt; Will people who start programming with heavy usage of LLM code generation stick to that or move towards manual coding as they gain experience.\nIf LLM assisted coding is like training wheels, I wonder if they'd end up in a situation like \"tutorial hell\" (where beginners never break the loop of doing yet another tutorial) and never break the cycle of needed the training wheels.\n\nWith AI as a copilot the question is if you ever want to break that cycle or if you want to have it always by your side. Pretty much like assisted flying in commercial airplanes. Which, by the way, doesn't do all the flaying for the pilot, only the \"boilerplate-ish\" parts (for lacking a better word in my poor English)",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "91ea427ee5e7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-01-21\/4672801393430_91ea427ee5e7ff6cb9ae_72.png",
            "first_name": "Christian",
            "real_name": "Christian Gill",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "gillchristiang",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1686770339.927269",
        "parent_user_id": "U04JY2BF24E",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "G+5bG",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Will people who start programming with heavy usage of LLM code generation stick to that or move towards manual coding as they gain experience."
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If LLM assisted coding is like training wheels, I wonder if they'd end up in a situation like \"tutorial hell\" (where beginners never break the loop of doing yet another tutorial) and never break the cycle of needed the training wheels.\n\nWith AI as a copilot the question is if you ever want to break that cycle or if you want to have it always by your side. Pretty much like assisted flying in commercial airplanes. Which, by the way, doesn't do all the flaying for the pilot, only the \"boilerplate-ish\" parts (for lacking a better word in my poor English)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04KZ8A9WCT",
        "type": "message",
        "ts": "1686810926.193009",
        "client_msg_id": "8E0DC4A2-0C35-4686-A2B0-ECFA564B8D1B",
        "text": "I might be mistaken but, pilots do learn to fly without a assistance first ",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "91ea427ee5e7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-01-21\/4672801393430_91ea427ee5e7ff6cb9ae_72.png",
            "first_name": "Christian",
            "real_name": "Christian Gill",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "gillchristiang",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1686770339.927269",
        "parent_user_id": "U04JY2BF24E",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "wk3+G",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I might be mistaken but, pilots do learn to fly without a assistance first "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04KZ8A9WCT",
        "type": "message",
        "ts": "1686810995.848789",
        "client_msg_id": "1D08718E-5A11-4686-A50C-76C5B60A63FD",
        "text": "I think the danger is loosing the ability to think (<https:\/\/experiment-0003.vercel.app\/t\/Uxkxi6Nuy7|https:\/\/experiment-0003.vercel.app\/t\/Uxkxi6Nuy7>)",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "91ea427ee5e7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-01-21\/4672801393430_91ea427ee5e7ff6cb9ae_72.png",
            "first_name": "Christian",
            "real_name": "Christian Gill",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "gillchristiang",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1686770339.927269",
        "parent_user_id": "U04JY2BF24E",
        "attachments": [
            {
                "from_url": "https:\/\/experiment-0003.vercel.app\/t\/Uxkxi6Nuy7",
                "id": 1,
                "original_url": "https:\/\/experiment-0003.vercel.app\/t\/Uxkxi6Nuy7",
                "fallback": "Is AI going to take over the thinking department?",
                "text": "Some thoughts I had ...",
                "title": "Is AI going to take over the thinking department?",
                "title_link": "https:\/\/experiment-0003.vercel.app\/t\/Uxkxi6Nuy7",
                "service_name": "experiment-0003.vercel.app"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zfGm",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think the danger is loosing the ability to think ("
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/experiment-0003.vercel.app\/t\/Uxkxi6Nuy7",
                                "text": "https:\/\/experiment-0003.vercel.app\/t\/Uxkxi6Nuy7"
                            },
                            {
                                "type": "text",
                                "text": ")"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04KZ8A9WCT",
        "type": "message",
        "ts": "1686811021.697139",
        "client_msg_id": "4854E341-2C91-4AFC-B4CE-2DB2DAE3D8DD",
        "text": "Which might happen to anybody, not only beginners",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "91ea427ee5e7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-01-21\/4672801393430_91ea427ee5e7ff6cb9ae_72.png",
            "first_name": "Christian",
            "real_name": "Christian Gill",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "gillchristiang",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1686770339.927269",
        "parent_user_id": "U04JY2BF24E",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "m5mN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Which might happen to anybody, not only beginners"
                            }
                        ]
                    }
                ]
            }
        ]
    }
]