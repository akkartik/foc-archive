[
    {
        "user": "U02U0AS3J49",
        "type": "message",
        "ts": "1725497398.193419",
        "client_msg_id": "d6f0f582-e9ec-475e-920d-5f5d2fdb1843",
        "text": "Can someone ELIF this for me? Is the memory available at training time or inference time? How is it connected to the network? And what does it mean that it is analogous to a Turing machine on von Neuman whatchamacallit?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g5247a9c6cbb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/5247a9c6cbb943683c9e2e2cef6eba79.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-72.png",
            "first_name": "Jason",
            "real_name": "Jason Morris",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "jason",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1725336081.046579",
        "parent_user_id": "U018S42NMMM",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Ny70S",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Can someone ELIF this for me? Is the memory available at training time or inference time? How is it connected to the network? And what does it mean that it is analogous to a Turing machine on von Neuman whatchamacallit?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "text": "<@U02U0AS3J49> These constructs define a \"memory\" to be used by the network at inference time.\nI'm still going through the NTM and DNC papers. But basically, Siegelmann and Sontag showed in 1992 that Recurrent Neural Networks (RNNs) are Turing-complete.",
        "files": [
            {
                "id": "F07L0E4EY6P",
                "mode": "hidden_by_limit"
            }
        ],
        "upload": false,
        "user": "U018S42NMMM",
        "display_as_bot": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4jVfi",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U02U0AS3J49"
                            },
                            {
                                "type": "text",
                                "text": " These constructs define a \"memory\" to be used by the network at inference time.\nI'm still going through the NTM and DNC papers. But basically, Siegelmann and Sontag showed in 1992 that Recurrent Neural Networks (RNNs) are Turing-complete."
                            }
                        ]
                    }
                ]
            }
        ],
        "type": "message",
        "ts": "1725511919.234029",
        "edited": {
            "user": "U018S42NMMM",
            "ts": "1725512853.000000"
        },
        "client_msg_id": "528bd90f-cd60-430b-a9d8-88476bf85bb8",
        "thread_ts": "1725336081.046579",
        "parent_user_id": "U018S42NMMM"
    },
    {
        "text": "",
        "files": [
            {
                "id": "F07KXNQN2ER",
                "mode": "hidden_by_limit"
            }
        ],
        "upload": false,
        "user": "U018S42NMMM",
        "display_as_bot": false,
        "type": "message",
        "ts": "1725512871.267849",
        "client_msg_id": "6b7788ce-4c1c-4f93-9e5f-f7ee5ca4500a",
        "thread_ts": "1725336081.046579",
        "parent_user_id": "U018S42NMMM"
    }
]