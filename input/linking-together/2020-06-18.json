[
    {
        "user": "UAL7940NM",
        "type": "message",
        "ts": "1592466064.375600",
        "client_msg_id": "c004e4bd-ce40-427a-8047-0ac5381d8191",
        "text": "&gt; Text can convey _ideas_ with a precisely controlled level of ambiguity and precision, implied context and elaborated content, unmatched by anything else.\nFor programming, it's important to distinguish between presentation and storage. In the presentation, you want a personalized experience, taking into account the user's context (e.g. which syntax sugar, libraries or PL features a user knows). For storage, you want an unambiguous representation including all relevant context.\nPLs typically use the exact same representation for presentation and storage, which requires compromises. It's neither personalized (e.g. displaying `HashMap` instead of `std::collections::HashMap` in my editor) nor unambiguous (e.g. a python script that doesn't specify compatible versions of the interpreter or any of its imports).\nText is a great communication medium in a lot of cases. In others, pictures, formulas, etc. are better suited. Providing different presentations is probably better than any single presentation (which is projectional editing, after all).\nDue to their conflicting requirements, it's necessary to separate presentation from storage! I don't care whether the storage presentation is textual, binary, or png-pics as long as it's well-defined, complete and easy to work with.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "43873346f949",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-07-13\/399377633206_43873346f949174e340e_72.jpg",
            "first_name": "Felix",
            "real_name": "Felix Kohlgrüber",
            "display_name": "Felix Kohlgrüber",
            "team": "T5TCAFTA9",
            "name": "felix.kohlgrueber",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Ca1",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Text can convey "
                            },
                            {
                                "type": "text",
                                "text": "ideas",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " with a precisely controlled level of ambiguity and precision, implied context and elaborated content, unmatched by anything else."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "For programming, it's important to distinguish between presentation and storage. In the presentation, you want a personalized experience, taking into account the user's context (e.g. which syntax sugar, libraries or PL features a user knows). For storage, you want an unambiguous representation including all relevant context.\nPLs typically use the exact same representation for presentation and storage, which requires compromises. It's neither personalized (e.g. displaying "
                            },
                            {
                                "type": "text",
                                "text": "HashMap",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " instead of "
                            },
                            {
                                "type": "text",
                                "text": "std::collections::HashMap",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " in my editor) nor unambiguous (e.g. a python script that doesn't specify compatible versions of the interpreter or any of its imports).\nText is a great communication medium in a lot of cases. In others, pictures, formulas, etc. are better suited. Providing different presentations is probably better than any single presentation (which is projectional editing, after all).\nDue to their conflicting requirements, it's necessary to separate presentation from storage! I don't care whether the storage presentation is textual, binary, or png-pics as long as it's well-defined, complete and easy to work with."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U6FKVSVCK",
                    "UJ6LDMMN0"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "UDQBTJ211",
        "type": "message",
        "ts": "1592472126.375800",
        "client_msg_id": "7892c263-c853-42db-b58c-9be09df8e478",
        "text": "&gt; I think the thesis behind a lot of graphical \/ visual programming languages is: there are things we want to be able to do in programming that we simply can't do with text.\n&gt; \nThere's also the fact that blog posts, documentation, lectures, personal notes etc, all optimised purely around understanding programming as easily as possible, tend to be packed with diagrams",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "2624b1e78c0a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-14\/551655871797_2624b1e78c0a9eaed529_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Knott",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "chrisknott",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "wrFHz",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think the thesis behind a lot of graphical \/ visual programming languages is: there are things we want to be able to do in programming that we simply can't do with text.\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nThere's also the fact that blog posts, documentation, lectures, personal notes etc, all optimised purely around understanding programming as easily as possible, tend to be packed with diagrams"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592492917.376500",
        "client_msg_id": "8c14b0e0-e19a-4667-bf65-4327f303c2db",
        "text": "<@U8A5MS6R1> — Your bridge example is interesting. What does the image convey to you? Because to me, I see no structural definitions, no measurements, no equations, hard-to-see use-case (i.e. I’m assuming it’s a bridge for cars?). I think the image says a lot, but perhaps more emotional and art than logic and mathematics.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6QkS",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U8A5MS6R1"
                            },
                            {
                                "type": "text",
                                "text": " — Your bridge example is interesting. What does the image convey to you? Because to me, I see no structural definitions, no measurements, no equations, hard-to-see use-case (i.e. I’m assuming it’s a bridge for cars?). I think the image says a lot, but perhaps more emotional and art than logic and mathematics."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UKP3B2J5D"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592493342.376700",
        "edited": {
            "user": "UJKKBAMLL",
            "ts": "1592493348.000000"
        },
        "client_msg_id": "7e2e30f3-fbb0-493f-bf81-7bbe76ed328e",
        "text": "Generally speaking, I’m in high agreement with the Graydon Hoare’s post, specifically around the use of text in logical and mathematical representations of complexity. I did a study on this ~7 years ago and the results confirmed that text was most optimal for expressing, sharing, understanding, writing, and reading complex logic. I did this study outside of academia during my own younger years as a professional so the records of this are all but lost on some hard-drive in a landfill, but the memory is still very much alive. I do want to run this study again…",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tE2xd",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Generally speaking, I’m in high agreement with the Graydon Hoare’s post, specifically around the use of text in logical and mathematical representations of complexity. I did a study on this ~7 years ago and the results confirmed that text was most optimal for expressing, sharing, understanding, writing, and reading complex logic. I did this study outside of academia during my own younger years as a professional so the records of this are all but lost on some hard-drive in a landfill, but the memory is still very much alive. I do want to run this study again…"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592493465.377000",
        "client_msg_id": "010f4cfa-b07b-46d4-b85a-fb1892735944",
        "text": "However, it’s really all about perspective of application here — UX. Nodes, images and other forms of HCI are powerful, text may be best, but that does not make it exclusive. I would however argue that text is best for many domains, but not all.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "raYA",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "However, it’s really all about perspective of application here — UX. Nodes, images and other forms of HCI are powerful, text may be best, but that does not make it exclusive. I would however argue that text is best for many domains, but not all."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UKP3B2J5D",
                    "UJRDRMWQN"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "UE0ETTCG7",
        "type": "message",
        "ts": "1592494638.377800",
        "client_msg_id": "674b4b94-62a9-411e-bf37-1158c115f859",
        "text": "This is probably obvious at this point, but it's worth re-iterating that visual programming languages are extremely popular anytime \"programming\" is used outside of traditional software development. Here's a quick list of a few examples that I personally use: Max\/MSP, Reaktor, Blender, Houdini, and VCV Rack. I would even go as far as to say visual programming languages are actually the default approach outside of traditional software development. This leads me to believe that visual programming languages, in a vacuum, are actually better, outside of one absolutely gigantic feature: Collaboration. Version control is the canonical example of a powerful collaboration feature powered by plain text, but even Stackoverflow, Slack, and any other place you cut and paste code are examples of leveraging plain text for collaboration. Using visual programming languages so much in various non-software development pursuits has convinced me that outside of these collaboration features, they're probably better. But if you are building complex systems that need collaboration between many different individuals, they're much worse.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "8d5fa305f272",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-09-24\/1392332871012_8d5fa305f272f9d0c9e3_72.jpg",
            "first_name": "Roben",
            "real_name": "Roben Kleene",
            "display_name": "robenkleene",
            "team": "T5TCAFTA9",
            "name": "services",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "\/I4",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This is probably obvious at this point, but it's worth re-iterating that visual programming languages are extremely popular anytime \"programming\" is used outside of traditional software development. Here's a quick list of a few examples that I personally use: Max\/MSP, Reaktor, Blender, Houdini, and VCV Rack. I would even go as far as to say visual programming languages are actually the default approach outside of traditional software development. This leads me to believe that visual programming languages, in a vacuum, are actually better, outside of one absolutely gigantic feature: Collaboration. Version control is the canonical example of a powerful collaboration feature powered by plain text, but even Stackoverflow, Slack, and any other place you cut and paste code are examples of leveraging plain text for collaboration. Using visual programming languages so much in various non-software development pursuits has convinced me that outside of these collaboration features, they're probably better. But if you are building complex systems that need collaboration between many different individuals, they're much worse."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UHWC9PXBL",
        "type": "message",
        "ts": "1592497725.381600",
        "client_msg_id": "D1DB7A81-D926-42C0-BC7C-A20A7C72B8D5",
        "text": "i can’t get over the fact that text-adherents deny all the visual affordances in everyday programming: if all we need is ascii, why indent? why syntax color? why use symbols to represent operators instead of words? what about things like decorators in javascript or python, which are positional? why do we use arrow notation for functions in a lot of cases? what’s the textual semantics of separating keys and values with a colon? what do we think parentheses are? ",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g0d754210ed4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/10d754210ed4e4706eba3d063cdf99f0.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "Garth",
            "real_name": "Garth Goldwater",
            "display_name": "garth",
            "team": "T5TCAFTA9",
            "name": "garth",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Lnb+R",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "i can’t get over the fact that text-adherents deny all the visual affordances in everyday programming: if all we need is ascii, why indent? why syntax color? why use symbols to represent operators instead of words? what about things like decorators in javascript or python, which are positional? why do we use arrow notation for functions in a lot of cases? what’s the textual semantics of separating keys and values with a colon? what do we think parentheses are? "
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "point_up",
                "users": [
                    "U8A5MS6R1"
                ],
                "count": 1
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0",
                    "UBSMEUXAA"
                ],
                "count": 2
            },
            {
                "name": "+1",
                "users": [
                    "UML4ZEKDK"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592498253.381800",
        "client_msg_id": "86f90dca-4438-415c-8f5d-80d921640eed",
        "text": "<@UHWC9PXBL> Indeed I agree some overlook or discount the topics you present — however, they are topics not universal required in textual representation of logic. For example: “when the door bell rings, text me” this statement does not need any syntax sugar to have meaning yet it conveys a respectable depth of complexity, would you agree?\n\nThe reason indent, color, etc. is applied to increase depth of meaning. If we apply colors, indentation and symbols to our door bell workflow than it (at least I hope) is only added to improve reading\/writing\/understanding of the logic, but by no means is it required at this depth of complexity.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tCgT",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UHWC9PXBL"
                            },
                            {
                                "type": "text",
                                "text": " Indeed I agree some overlook or discount the topics you present — however, they are topics not universal required in textual representation of logic. For example: “when the door bell rings, text me” this statement does not need any syntax sugar to have meaning yet it conveys a respectable depth of complexity, would you agree?\n\nThe reason indent, color, etc. is applied to increase depth of meaning. If we apply colors, indentation and symbols to our door bell workflow than it (at least I hope) is only added to improve reading\/writing\/understanding of the logic, but by no means is it required at this depth of complexity."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UKP3B2J5D"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592498391.382900",
        "client_msg_id": "db3acb1b-a6c6-4b10-800c-6630f8508091",
        "text": "In this particular example (and I have thousands more), text is best. Drawing a picture of the doorbell ringing and a text message sending is less effective at conveying the required complexities of our intended behavior — in fact it would include a terrible amount of unnecessary complexity if represented in a drawing that may include unnecessary emotion or a diagram which includes unnecessary shapes\/lines\/structures\/visual-space.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "fcx1U",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In this particular example (and I have thousands more), text is best. Drawing a picture of the doorbell ringing and a text message sending is less effective at conveying the required complexities of our intended behavior — in fact it would include a terrible amount of unnecessary complexity if represented in a drawing that may include unnecessary emotion or a diagram which includes unnecessary shapes\/lines\/structures\/visual-space."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592498437.383100",
        "client_msg_id": "9af008ed-5e08-4ab5-812f-44b95923f145",
        "text": "<@U015H1K64G1> this conversation and topic is very relevant to our recent conversation.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zoQAy",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U015H1K64G1"
                            },
                            {
                                "type": "text",
                                "text": " this conversation and topic is very relevant to our recent conversation."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592498512.383300",
        "client_msg_id": "50d1a952-1a62-4e9f-b90d-569dbc68338e",
        "text": "If I may continue: though text may be best in places, it does not need to be exclusively text. Why choose one? Why not choose text when appropriate and visual when appropriate? I would argue the latter here is most optimal for UX.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RNe",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If I may continue: though text may be best in places, it does not need to be exclusively text. Why choose one? Why not choose text when appropriate and visual when appropriate? I would argue the latter here is most optimal for UX."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UKP3B2J5D"
                ],
                "count": 1
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UHWC9PXBL",
        "type": "message",
        "ts": "1592500557.387100",
        "client_msg_id": "4DC99551-E7F9-45E9-A8BC-DF5166817402",
        "text": "<@UBZ91GWJW> you’re working at a different level of text, so i’m not sure the argument applies here. storyscript (as i understand it) aims to have the user communicate in natural language, then conversationally hone in on a mapping of that language to the formal, underlying system, right? i wouldn’t describe that as fundamentally textual (at least for the purpose of this discussion) since “displayed code” gets evolved over the course of the interaction—does that make sense?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g0d754210ed4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/10d754210ed4e4706eba3d063cdf99f0.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "Garth",
            "real_name": "Garth Goldwater",
            "display_name": "garth",
            "team": "T5TCAFTA9",
            "name": "garth",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Pqi",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UBZ91GWJW"
                            },
                            {
                                "type": "text",
                                "text": " you’re working at a different level of text, so i’m not sure the argument applies here. storyscript (as i understand it) aims to have the user communicate in natural language, then conversationally hone in on a mapping of that language to the formal, underlying system, right? i wouldn’t describe that as fundamentally textual (at least for the purpose of this discussion) since “displayed code” gets evolved over the course of the interaction—does that make sense?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592500845.389400",
        "client_msg_id": "913355b0-4681-4c7b-a7a0-3b04e1ad5f88",
        "text": "<@UHWC9PXBL> I intentionally left Storyscript of out my argument :wink:  but yes, it has influenced my argument, no question about that. But my intention and argument was more about generalized logic which has vastly different weights of complexity ranging from simple Alexa commands to something much closer to what traditional programming supports. I rather not bring Storyscript into this conversation an focus on different levels of necessary complexity. Generally speaking, I’m arguing that text is best for the majority of complex domains, but not exclusively.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "SiU",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UHWC9PXBL"
                            },
                            {
                                "type": "text",
                                "text": " I intentionally left Storyscript of out my argument "
                            },
                            {
                                "type": "emoji",
                                "name": "wink",
                                "unicode": "1f609"
                            },
                            {
                                "type": "text",
                                "text": "  but yes, it has influenced my argument, no question about that. But my intention and argument was more about generalized logic which has vastly different weights of complexity ranging from simple Alexa commands to something much closer to what traditional programming supports. I rather not bring Storyscript into this conversation an focus on different levels of necessary complexity. Generally speaking, I’m arguing that text is best for the majority of complex domains, but not exclusively."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UDQBTJ211",
        "type": "message",
        "ts": "1592500984.390500",
        "client_msg_id": "5f7b5733-c550-4931-bdad-178ff8811205",
        "text": "One example where I don't think that text is better is in logic gate circuits. The way text is laid out it's not obvious what the inputs and what the overall output is.\n\ne.g. A or B and C or D and E\n\nThis is very simple example but it would already need brackets and even then isn't clear. When you see highly structured text (like law) they tend to essentially lay it out diagrammatically (with indents) and it's still not very clear",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "2624b1e78c0a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-14\/551655871797_2624b1e78c0a9eaed529_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Knott",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "chrisknott",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "yE6",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "One example where I don't think that text is better is in logic gate circuits. The way text is laid out it's not obvious what the inputs and what the overall output is.\n\ne.g. A or B and C or D and E\n\nThis is very simple example but it would already need brackets and even then isn't clear. When you see highly structured text (like law) they tend to essentially lay it out diagrammatically (with indents) and it's still not very clear"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UFPPABQ7P"
                ],
                "count": 1
            },
            {
                "name": "mag",
                "users": [
                    "UFPPABQ7P"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UDQBTJ211",
        "type": "message",
        "ts": "1592501062.390700",
        "client_msg_id": "10f5be97-4443-4b55-bfd3-ab4576bf8b09",
        "text": "Text shines when you have a large vocabulary",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "2624b1e78c0a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-14\/551655871797_2624b1e78c0a9eaed529_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Knott",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "chrisknott",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2QV",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Text shines when you have a large vocabulary"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            },
            {
                "name": "+1",
                "users": [
                    "UAHHWT22U"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U8A5MS6R1",
        "type": "message",
        "ts": "1592501977.391300",
        "client_msg_id": "8deb6517-b0cc-4011-a381-0da15d48be99",
        "text": "&gt; <@U8A5MS6R1> — Your bridge example is interesting. What does the image convey to you?\n<@UJKKBAMLL> - it's about the arrangement of beams and trusses - how do you convey that in text? \"There are two large trusses. The left truss has N beams. The first beam starts at coordinates (0,0) at an angle of 15%.. this is connected to two other beams\". Then how do you describe _all_ the connections? You could even make a table with the list of beams with coordinates and connections, but a reader wouln't get it until they reconstruct the diagram from the table and look at it.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "DR=f6",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U8A5MS6R1"
                            },
                            {
                                "type": "text",
                                "text": " — Your bridge example is interesting. What does the image convey to you?"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UJKKBAMLL"
                            },
                            {
                                "type": "text",
                                "text": " - it's about the arrangement of beams and trusses - how do you convey that in text? \"There are two large trusses. The left truss has N beams. The first beam starts at coordinates (0,0) at an angle of 15%.. this is connected to two other beams\". Then how do you describe "
                            },
                            {
                                "type": "text",
                                "text": "all",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " the connections? You could even make a table with the list of beams with coordinates and connections, but a reader wouln't get it until they reconstruct the diagram from the table and look at it."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT",
                    "UMWF81HTP"
                ],
                "count": 2
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UHWC9PXBL",
        "type": "message",
        "ts": "1592502188.391500",
        "edited": {
            "user": "UHWC9PXBL",
            "ts": "1592502249.000000"
        },
        "client_msg_id": "92748344-19b8-4941-910a-7b173633c6ba",
        "text": "Ok—I think I might have a better way of putting this. Articles about the primacy of “text” as a medium frustrate me because they move the goalposts on what they mean by text, and often are used to justify a world where we continue to edit programs character-by-character in order to produce a single array of characters that pass lexing, parsing, and compilation or interpretation checks.\n\nThis is frustrating. Here’s one of the example quotes from the article:\n\n&gt; _“Human rights are moral principles or norms that describe certain standards of human behaviour, and are regularly protected as legal rights in national and international law.”_\nI’m not sure how to convey that graphically, but I’m also not sure how to define even _a process to find an appropriate semantic model_ for that sentence. Some quick bullet points:\n• The social context for this sentence matters. You could be reading it at a filibuster, an open mic night, or during a debate around a constitutional amendment. All of those wildly change the intention that the audience (or the “compiler”) should intuit from the text\n• The vast majority of the meaning of this sentence is buried in definitions, assumptions, behaviors, cultures, etc—there are a million “why?” questions a naive alien could ask about this sentence—to say nothing of the non-precise definition of every single word used in it—reminding me of a long-lost old tweet: “Words are a scam. If you look them up, they just mean other words. That’s how they get you”\n• Even *humans*, who designed the damn language thing, can’t agree on definitions or reasonable inference. That’s why lawyers and judges and polticians write and argue about what laws mean all the time.\nAll this is to say that the _advantages_ that authors of these types of articles often cite as belonging to text tend to actually belong to _human language_, not arrays of ascii or unicode. Sorry—I’m bringing up storyscript again because it’s cool and a good example: I find the most appealing part of being able to write the sentence “text me when the doorbell rings” and have it work is the idea that there is a tool or process set up that\n1. knows who i am\n2. understands that “text me” means “text me `the doorbell has rung`”\n3. knows which doorbell I mean when I say `the doorbell`",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g0d754210ed4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/10d754210ed4e4706eba3d063cdf99f0.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "Garth",
            "real_name": "Garth Goldwater",
            "display_name": "garth",
            "team": "T5TCAFTA9",
            "name": "garth",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "O\/hvs",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Ok—I think I might have a better way of putting this. Articles about the primacy of “text” as a medium frustrate me because they move the goalposts on what they mean by text, and often are used to justify a world where we continue to edit programs character-by-character in order to produce a single array of characters that pass lexing, parsing, and compilation or interpretation checks.\n\nThis is frustrating. Here’s one of the example quotes from the article:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "“Human rights are moral principles or norms that describe certain standards of human behaviour, and are regularly protected as legal rights in national and international law.”",
                                "style": {
                                    "italic": true
                                }
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nI’m not sure how to convey that graphically, but I’m also not sure how to define even "
                            },
                            {
                                "type": "text",
                                "text": "a process to find an appropriate semantic model",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " for that sentence. Some quick bullet points:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "The social context for this sentence matters. You could be reading it at a filibuster, an open mic night, or during a debate around a constitutional amendment. All of those wildly change the intention that the audience (or the “compiler”) should intuit from the text"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "The vast majority of the meaning of this sentence is buried in definitions, assumptions, behaviors, cultures, etc—there are a million “why?” questions a naive alien could ask about this sentence—to say nothing of the non-precise definition of every single word used in it—reminding me of a long-lost old tweet: “Words are a scam. If you look them up, they just mean other words. That’s how they get you”"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Even "
                                    },
                                    {
                                        "type": "text",
                                        "text": "humans",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": ", who designed the damn language thing, can’t agree on definitions or reasonable inference. That’s why lawyers and judges and polticians write and argue about what laws mean all the time."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "All this is to say that the "
                            },
                            {
                                "type": "text",
                                "text": "advantages",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " that authors of these types of articles often cite as belonging to text tend to actually belong to "
                            },
                            {
                                "type": "text",
                                "text": "human language",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", not arrays of ascii or unicode. Sorry—I’m bringing up storyscript again because it’s cool and a good example: I find the most appealing part of being able to write the sentence “text me when the doorbell rings” and have it work is the idea that there is a tool or process set up that\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "knows who i am"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "understands that “text me” means “text me "
                                    },
                                    {
                                        "type": "text",
                                        "text": "the doorbell has rung",
                                        "style": {
                                            "code": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": "”"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "knows which doorbell I mean when I say "
                                    },
                                    {
                                        "type": "text",
                                        "text": "the doorbell",
                                        "style": {
                                            "code": true
                                        }
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT",
                    "UMWF81HTP",
                    "U010328JA1E",
                    "UCGAK10LS"
                ],
                "count": 4
            }
        ]
    },
    {
        "user": "UHWC9PXBL",
        "type": "message",
        "ts": "1592502208.391700",
        "client_msg_id": "91d382fd-41f0-49be-8a5a-7221ebd8216c",
        "text": "this is the second time ive accidentally sent the message before finishing it so I’m just plowing ahead",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g0d754210ed4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/10d754210ed4e4706eba3d063cdf99f0.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "Garth",
            "real_name": "Garth Goldwater",
            "display_name": "garth",
            "team": "T5TCAFTA9",
            "name": "garth",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xAg+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "this is the second time ive accidentally sent the message before finishing it so I’m just plowing ahead"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592502741.392000",
        "client_msg_id": "3fe97dd5-f48c-4fcd-8a98-c92431b655aa",
        "text": "<@U8A5MS6R1> <https:\/\/blokdots.com\/> blends this very well IMO",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "attachments": [
            {
                "title": "blokdots",
                "title_link": "https:\/\/blokdots.com\/",
                "text": "blokdots is a simple to use software to build interactive hardware prototypes without a line of code.",
                "fallback": "blokdots",
                "image_url": "https:\/\/blokdots.com\/richPreview.jpg",
                "image_width": 476,
                "image_height": 250,
                "from_url": "https:\/\/blokdots.com\/",
                "image_bytes": 162566,
                "service_icon": "https:\/\/blokdots.com\/touch-icon.png",
                "service_name": "blokdots.com",
                "id": 1,
                "original_url": "https:\/\/blokdots.com\/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Fh0O",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U8A5MS6R1"
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/blokdots.com\/"
                            },
                            {
                                "type": "text",
                                "text": " blends this very well IMO"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UHWC9PXBL",
                    "U8A5MS6R1",
                    "UML4ZEKDK"
                ],
                "count": 3
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592502801.392300",
        "client_msg_id": "da458d75-fd6e-4406-b22c-281c746b3a73",
        "text": "Beautiful blend of visual and textual representation of complexity.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "91ptj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Beautiful blend of visual and textual representation of complexity."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592502982.392500",
        "client_msg_id": "c7329257-35f9-4db0-9b9d-72b9a380efcf",
        "text": "<@UHWC9PXBL> I will return to comment soon, have meetings for a while now :smile: — Also DM so we can schedule time to chat and show demos.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "b2S",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UHWC9PXBL"
                            },
                            {
                                "type": "text",
                                "text": " I will return to comment soon, have meetings for a while now "
                            },
                            {
                                "type": "emoji",
                                "name": "smile",
                                "unicode": "1f604"
                            },
                            {
                                "type": "text",
                                "text": " — Also DM so we can schedule time to chat and show demos."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UHWC9PXBL"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UHWC9PXBL",
        "type": "message",
        "ts": "1592504752.392700",
        "client_msg_id": "22cacb15-c340-4edc-a5b5-7ee9ed147f9e",
        "text": "Those three numbered points are all examples of embedding context in the environment interpreting a set of commands. I think the more useful way of looking at the bare reality of how computers get used is that we send them instructions. The tradition is to batch them up in code files and pass them somewhere, then run them by clicking or invoking them on the command line.\n\nOne major frustration I have is that the input for these commands tends to be constrained to appending, concatenating, inserting, and deleting either characters or regular expressions over characters on arrays (really ropes if you want to nerd out about probable data structures—but the user is experience is indistinguishable from arrays) of text that will eventually get parsed. That sucks:\n• There’s clearly a level of direct inefficiency here: we edit text files, so that they can be parsed to data structures (ASTs)—and then attempt to edit those data structures by editing our text files—and we maintain a relationship between those two pieces of state by maintaining a model in our brains, and spot-checking it repeatedly against a parser, typechecker, and manual and automated tests. I’d argue that storyscript *is actually* a conversational interface over a structural editor, that uses a lot of NLP and some clever UX to make the experience very pleasant. Plus all the stuff about connections to services and everything else it’s doing.\n• there are demonstrably more efficient or ergonomic ways of entering many types of data (interactively or not): dropping pins on a map, using a color picker or eyedropper, drawing a box for a screencap or crop, clicking an element on the screen rather than specifying its exact position or some sort of structural selector, etc. \n• In fact, some of these may be more useful for data types that have direct analogues in code and ASTs: do you think there are more tables or maps in all the excel documents in the world or all the code in the world? How many cars are there whose speed is controlled by the user typing in a percentage delineating the openness of a throttle?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g0d754210ed4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/10d754210ed4e4706eba3d063cdf99f0.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "Garth",
            "real_name": "Garth Goldwater",
            "display_name": "garth",
            "team": "T5TCAFTA9",
            "name": "garth",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Q7yo",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Those three numbered points are all examples of embedding context in the environment interpreting a set of commands. I think the more useful way of looking at the bare reality of how computers get used is that we send them instructions. The tradition is to batch them up in code files and pass them somewhere, then run them by clicking or invoking them on the command line.\n\nOne major frustration I have is that the input for these commands tends to be constrained to appending, concatenating, inserting, and deleting either characters or regular expressions over characters on arrays (really ropes if you want to nerd out about probable data structures—but the user is experience is indistinguishable from arrays) of text that will eventually get parsed. That sucks:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "There’s clearly a level of direct inefficiency here: we edit text files, so that they can be parsed to data structures (ASTs)—and then attempt to edit those data structures by editing our text files—and we maintain a relationship between those two pieces of state by maintaining a model in our brains, and spot-checking it repeatedly against a parser, typechecker, and manual and automated tests. I’d argue that storyscript "
                                    },
                                    {
                                        "type": "text",
                                        "text": "is actually",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " a conversational interface over a structural editor, that uses a lot of NLP and some clever UX to make the experience very pleasant. Plus all the stuff about connections to services and everything else it’s doing."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "there are demonstrably more efficient or ergonomic ways of entering many types of data (interactively or not): dropping pins on a map, using a color picker or eyedropper, drawing a box for a screencap or crop, clicking an element on the screen rather than specifying its exact position or some sort of structural selector, etc. "
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "In fact, some of these may be more useful for data types that have direct analogues in code and ASTs: do you think there are more tables or maps in all the excel documents in the world or all the code in the world? How many cars are there whose speed is controlled by the user typing in a percentage delineating the openness of a throttle?"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0
                    }
                ]
            }
        ]
    },
    {
        "user": "UHWC9PXBL",
        "type": "message",
        "ts": "1592504752.392900",
        "edited": {
            "user": "UHWC9PXBL",
            "ts": "1592504820.000000"
        },
        "client_msg_id": "22cacb15-c340-4edc-a5b5-7ee9ed147f9e",
        "text": "What do all these specialized tools for data entry actually give you? Context, live feedback, and constrained input. And most of them _don’t feel like using a language_—the thing about flow states is that they deal with feeling _embodied_. So a fencer considers their sword an extension of _their arm_, a driver considers a car the extension of _their body_, and a musician often considers their instruments an extension of _their hands, voice, or speech_. There’s a reason we put frets on guitars, even though a rational being with an infinite time horizon would be perfectly fine with labeled fretless guitars, or simply perfect pitch.\n\nThe thing about all these affordances is that they quickly move from conscious to subconscious attention as people become more familiar with them through use. That’s (part of) what generates flow states. So most of what *good* visual or gestural interfaces provide quickly become invisible. The use of carets for editing, highlighting for selection, clicking for activating or selecting, etc, eliminate reams and reams of parameters we’d have to add to functions if we were doing everything with text-based languages—but we don’t talk about this when we talk about text and programming languages. That’s the power I see in phrases like `the doorbell`. It’s an implicit selection or context that doesn’t require you to hop out of your subconscious way of thinking “*that* doorbell, which is close at hand, or in my mind” and into machine language “what’s the UUID of that doorbell? what’s the order at the call site of the function? did I import the right module? is it objectName.data or objectName.value?” and pointing—whether with your eyes, explicit context from associating things with your username, using a mouse, or using the history of a conversation—makes this much, much more ergonomic. And none of those options have to do with the array of characters that you hope defines a parseable program. They all have to do with directions to the interpreter or whatever about *how to look up and interpret symbols.*",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g0d754210ed4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/10d754210ed4e4706eba3d063cdf99f0.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "Garth",
            "real_name": "Garth Goldwater",
            "display_name": "garth",
            "team": "T5TCAFTA9",
            "name": "garth",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3lTK",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "What do all these specialized tools for data entry actually give you? Context, live feedback, and constrained input. And most of them "
                            },
                            {
                                "type": "text",
                                "text": "don’t feel like using a language",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "—the thing about flow states is that they deal with feeling "
                            },
                            {
                                "type": "text",
                                "text": "embodied",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". So a fencer considers their sword an extension of "
                            },
                            {
                                "type": "text",
                                "text": "their arm",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", a driver considers a car the extension of "
                            },
                            {
                                "type": "text",
                                "text": "their body",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", and a musician often considers their instruments an extension of "
                            },
                            {
                                "type": "text",
                                "text": "their hands, voice, or speech",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". There’s a reason we put frets on guitars, even though a rational being with an infinite time horizon would be perfectly fine with labeled fretless guitars, or simply perfect pitch.\n\nThe thing about all these affordances is that they quickly move from conscious to subconscious attention as people become more familiar with them through use. That’s (part of) what generates flow states. So most of what "
                            },
                            {
                                "type": "text",
                                "text": "good",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " visual or gestural interfaces provide quickly become invisible. The use of carets for editing, highlighting for selection, clicking for activating or selecting, etc, eliminate reams and reams of parameters we’d have to add to functions if we were doing everything with text-based languages—but we don’t talk about this when we talk about text and programming languages. That’s the power I see in phrases like "
                            },
                            {
                                "type": "text",
                                "text": "the doorbell",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". It’s an implicit selection or context that doesn’t require you to hop out of your subconscious way of thinking “"
                            },
                            {
                                "type": "text",
                                "text": "that",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " doorbell, which is close at hand, or in my mind” and into machine language “what’s the UUID of that doorbell? what’s the order at the call site of the function? did I import the right module? is it objectName.data or objectName.value?” and pointing—whether with your eyes, explicit context from associating things with your username, using a mouse, or using the history of a conversation—makes this much, much more ergonomic. And none of those options have to do with the array of characters that you hope defines a parseable program. They all have to do with directions to the interpreter or whatever about "
                            },
                            {
                                "type": "text",
                                "text": "how to look up and interpret symbols.",
                                "style": {
                                    "bold": true
                                }
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UHWC9PXBL",
        "type": "message",
        "ts": "1592504785.393200",
        "client_msg_id": "16f0a530-259d-4f23-be7f-d25d6c87f4fe",
        "text": "Sorry, COVID isolation + unemployment = my high pressure programming rant chamber required venting",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g0d754210ed4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/10d754210ed4e4706eba3d063cdf99f0.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "Garth",
            "real_name": "Garth Goldwater",
            "display_name": "garth",
            "team": "T5TCAFTA9",
            "name": "garth",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hvQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Sorry, COVID isolation + unemployment = my high pressure programming rant chamber required venting"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "beers",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UKDM3GLAJ",
        "type": "message",
        "ts": "1592507517.393500",
        "client_msg_id": "37e43714-a9cd-44ca-ac36-8c37ef85a705",
        "text": "That’s an interesting point about how most good interfaces fade into the background. I find text does not do that to the same extent. Perhaps part of what is interesting about being a programmer is the novelty of how much can be accomplished by learning to edit text files. Maybe text isn’t good; it’s just conspicuous. Even if you’re doing more, better, you don’t feel like you’re programming when you’re using a spreadsheet (or I don’t).",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "34e7a55348e8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-01-04\/893378739792_34e7a55348e8c86c1901_72.jpg",
            "first_name": "",
            "real_name": "Jared Windover",
            "display_name": "Jared Windover",
            "team": "T5TCAFTA9",
            "name": "jaredwindover",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Hey",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "That’s an interesting point about how most good interfaces fade into the background. I find text does not do that to the same extent. Perhaps part of what is interesting about being a programmer is the novelty of how much can be accomplished by learning to edit text files. Maybe text isn’t good; it’s just conspicuous. Even if you’re doing more, better, you don’t feel like you’re programming when you’re using a spreadsheet (or I don’t)."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "ok_hand",
                "users": [
                    "UHWC9PXBL",
                    "UFLN9JFRT"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "UKDM3GLAJ",
        "type": "message",
        "ts": "1592507536.393700",
        "client_msg_id": "38519018-778e-49ef-851b-611d49413975",
        "text": "Programming is just conspicuous computing.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "34e7a55348e8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-01-04\/893378739792_34e7a55348e8c86c1901_72.jpg",
            "first_name": "",
            "real_name": "Jared Windover",
            "display_name": "Jared Windover",
            "team": "T5TCAFTA9",
            "name": "jaredwindover",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xUL",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Programming is just conspicuous computing."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJKKBAMLL",
        "type": "message",
        "ts": "1592510495.395100",
        "edited": {
            "user": "UJKKBAMLL",
            "ts": "1592510507.000000"
        },
        "client_msg_id": "1e95e993-aa62-404f-bb82-586da1138167",
        "text": "<@UHWC9PXBL> There is a lot to digest in your statements, I’m honestly not sure where to start…",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6b9db1f76eed",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-06-12\/662675221668_6b9db1f76eed746965ca_72.jpg",
            "first_name": "Steve",
            "real_name": "Steve Peak",
            "display_name": "Steve",
            "team": "T5TCAFTA9",
            "name": "steve727",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "w4m",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UHWC9PXBL"
                            },
                            {
                                "type": "text",
                                "text": " There is a lot to digest in your statements, I’m honestly not sure where to start…"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UHWC9PXBL",
        "type": "message",
        "ts": "1592511040.395400",
        "client_msg_id": "860f6e5e-3e7b-4c1e-82c6-5fda4eb3947d",
        "text": "<@UJKKBAMLL> no worries! I apologized because I realized it had evolved into more of a blog post haha",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g0d754210ed4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/10d754210ed4e4706eba3d063cdf99f0.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "Garth",
            "real_name": "Garth Goldwater",
            "display_name": "garth",
            "team": "T5TCAFTA9",
            "name": "garth",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WcHYZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UJKKBAMLL"
                            },
                            {
                                "type": "text",
                                "text": " no worries! I apologized because I realized it had evolved into more of a blog post haha"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "rolling_on_the_floor_laughing",
                "users": [
                    "UJKKBAMLL"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U8A5MS6R1",
        "type": "message",
        "ts": "1592516663.396400",
        "client_msg_id": "9d92b486-e5d6-46e7-9be6-703a01266062",
        "text": "&gt; If I may continue: though text may be best in places, it does not need to be exclusively text. Why choose one? Why not choose text when appropriate and visual when appropriate? I would argue the latter here is most optimal for UX.\nI agree with this.\n\nIf we think of 'information' as an artifact, text is a UI. The same information can have other UIs too, other text or visual representations, or mixtures of course. I think storing the text as the essential representation of information is where the trouble starts (which is what I think Garth is referring to). First, you have an incredibly denormalized representation where you have to normalize the links every time you load it (e.g. repetitive use of the same word\/variable name). Second, you've embedded display and style information (80 columns?) into your information. Third, you often embed text delimiters to represent structure, and now parsing is a whole giant subject. This can go on..\n\nReally I think we should be moving off this pattern to a more hybrid and layered approach: the innermost representation only stores the essential elements of the information (kinda closer to a graph with nodes having ids?). The the outer layers map this into various forms, adding text, graphics, style etc. This is what I mean by 'universal hypermedia'. Imagine a view that shows \"when the doorbell rings, ...\", what does 'doorbell' refer to? What does 'ring' refer to? If I hover over the words, I should see highlights on all currently visible UI represensations of the same _entity_, e.g. an icon in a different pane. If I click I should be able to navigate to other entities connected to the 'doorbell' - provenance, other rules, etc. The entities are part of the information model here, which is more unified than fragmented, and we have these kinds of 'lenses' to look at the information. Yes, various expressions in the UI may use text, but I think 'always bet on text' misses the potential power of an information\/hypermedia system. You should be able to switch to other views of the _same_ information, even multiple text views in fact.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tlek3",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If I may continue: though text may be best in places, it does not need to be exclusively text. Why choose one? Why not choose text when appropriate and visual when appropriate? I would argue the latter here is most optimal for UX."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I agree with this.\n\nIf we think of 'information' as an artifact, text is a UI. The same information can have other UIs too, other text or visual representations, or mixtures of course. I think storing the text as the essential representation of information is where the trouble starts (which is what I think Garth is referring to). First, you have an incredibly denormalized representation where you have to normalize the links every time you load it (e.g. repetitive use of the same word\/variable name). Second, you've embedded display and style information (80 columns?) into your information. Third, you often embed text delimiters to represent structure, and now parsing is a whole giant subject. This can go on..\n\nReally I think we should be moving off this pattern to a more hybrid and layered approach: the innermost representation only stores the essential elements of the information (kinda closer to a graph with nodes having ids?). The the outer layers map this into various forms, adding text, graphics, style etc. This is what I mean by 'universal hypermedia'. Imagine a view that shows \"when the doorbell rings, ...\", what does 'doorbell' refer to? What does 'ring' refer to? If I hover over the words, I should see highlights on all currently visible UI represensations of the same "
                            },
                            {
                                "type": "text",
                                "text": "entity",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", e.g. an icon in a different pane. If I click I should be able to navigate to other entities connected to the 'doorbell' - provenance, other rules, etc. The entities are part of the information model here, which is more unified than fragmented, and we have these kinds of 'lenses' to look at the information. Yes, various expressions in the UI may use text, but I think 'always bet on text' misses the potential power of an information\/hypermedia system. You should be able to switch to other views of the "
                            },
                            {
                                "type": "text",
                                "text": "same",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " information, even multiple text views in fact."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT",
                    "UHWC9PXBL",
                    "UAL7940NM",
                    "UMWF81HTP",
                    "UJBAJNFLK"
                ],
                "count": 5
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0"
                ],
                "count": 1
            },
            {
                "name": "white_check_mark",
                "users": [
                    "UFPPABQ7P"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1592518457.396600",
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1592519231.000000"
        },
        "client_msg_id": "ba73da58-83b6-4d78-80fd-e9c966b35728",
        "text": "&gt; the innermost representation only stores the essential elements of the information\nI've never seen a case — including formal mathematics — where this can be taken to a perfect, full realization. You always have to draw a \"good enough\" line somewhere.\n\nEg: 2+2 is not a minimal encoding of that operation. There is no one true minimal encoding. Things get even worse when you start looking at (eg) Clifford algebras. Or you could just draw a \"good enough\" line at the cross product, since that (comparatively) minimizes the number of CPU operations you need to burn in order to do your workaday 3d vector algebra.\n\nSo if leaking some aspect or another of inessential complexity is inescapable, I argue that you (the designer of some innermost representation) should choose a healthy number of inessential elements you want to have handy and insist that all viewers understand, and not feel the pressure to scrub away as much as possible. For textual source code, we've chosen that indentation is worth storing, but highlighting is not. I think most of us can agree that these are bad choices — but that doesn't mean that the best choice is as little choice as possible.\n\n(Solidly agree with everything else you say, though!)",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "Ivan Reese",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uNsj",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "the innermost representation only stores the essential elements of the information"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I've never seen a case — including formal mathematics — where this can be taken to a perfect, full realization. You always have to draw a \"good enough\" line somewhere.\n\nEg: 2+2 is not a minimal encoding of that operation. There is no one true minimal encoding. Things get even worse when you start looking at (eg) Clifford algebras. Or you could just draw a \"good enough\" line at the cross product, since that (comparatively) minimizes the number of CPU operations you need to burn in order to do your workaday 3d vector algebra.\n\nSo if leaking some aspect or another of inessential complexity is inescapable, I argue that you (the designer of some innermost representation) should choose a healthy number of inessential elements you want to have handy and insist that all viewers understand, and not feel the pressure to scrub away as much as possible. For textual source code, we've chosen that indentation is worth storing, but highlighting is not. I think most of us can agree that these are bad choices — but that doesn't mean that the best choice is as little choice as possible.\n\n(Solidly agree with everything else you say, though!)"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U8A5MS6R1",
                    "UJBAJNFLK"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "U8A5MS6R1",
        "type": "message",
        "ts": "1592520791.398600",
        "client_msg_id": "fd50cca9-ddaa-4676-94b7-ed0a42480406",
        "text": "Yeah I've struggled in rabbit holes looking for minimal schemas models :smile:. It's kind of like finding the minimal repr of the rectangle - is it center and half-widths, or four corners, or ..?\n\nIt appears we can never really share information, we can only share _views_ of information. So whatever the _medium of the view_ is - it will introduce artifacts into our representations (~indentation). The thrust of my argument kinda missed what I really wanted to emphasize, which is that with computers we now have the ability to store deeply interlinked views of the same things, and we should engage more in this direction. Rather than trying to think in terms of the non-computer ideas (dead text), we should think more in terms of computer-ish ideas (many views of the same intertwingled things). I'll see if I can phrase this better at some point.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zu\/sx",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah I've struggled in rabbit holes looking for minimal schemas models "
                            },
                            {
                                "type": "emoji",
                                "name": "smile",
                                "unicode": "1f604"
                            },
                            {
                                "type": "text",
                                "text": ". It's kind of like finding the minimal repr of the rectangle - is it center and half-widths, or four corners, or ..?\n\nIt appears we can never really share information, we can only share "
                            },
                            {
                                "type": "text",
                                "text": "views",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " of information. So whatever the "
                            },
                            {
                                "type": "text",
                                "text": "medium of the view",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " is - it will introduce artifacts into our representations (~indentation). The thrust of my argument kinda missed what I really wanted to emphasize, which is that with computers we now have the ability to store deeply interlinked views of the same things, and we should engage more in this direction. Rather than trying to think in terms of the non-computer ideas (dead text), we should think more in terms of computer-ish ideas (many views of the same intertwingled things). I'll see if I can phrase this better at some point."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UHWC9PXBL",
                    "UMWF81HTP",
                    "UJBAJNFLK",
                    "U5STGTB3J"
                ],
                "count": 4
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UEBG0NPDK",
        "type": "message",
        "ts": "1592522794.398900",
        "client_msg_id": "b980f925-0fa7-4abd-8c70-ae765bbbdb7f",
        "text": "One of the open problems down the road of hyperlink-it-all is how you make all the views computable. I have that drawing of the bridge - how does that turn into useful information for me to work with without losing the semantics the drawing is actually providing me? There are lots of deep holes to fall into along the path: notions of identity, the dream of semantically preserving transforms, conceptual implicitness with execution stability, and so on.\n\nIn the end I think you run up against the curse of dimensionality no matter what you do and at some point you have to accept there will always be representations that you can't preserve. Our best efforts remain lossy (computers aside, we still have no idea how to convey information losslessly across formats between people). But that's _ok_. I'm firmly in the camp that when it comes to basically anything related to thought, the answer is always somewhere in the intersection of an effectively uncountable number of axes. To suggest that any one way is superior is to forget the simple question \"in what context?\" And trying to answer that question is an exercise in attempting, and failing, to capture all the external forces that apply. As Ivan said, at some point we have to stop claiming X is better and instead start saying \"this is useful in some context that we potentially share.\" If a system captures enough of those useful cases, it eventually overcomes all the ways in which it is inadequate and we get the thing we complain about but we use anyway because it's \"good enough.\"\n\nI've always found looking at the extremes useful - what if everything was text? what if nothing was text? what if everything was the most domain-relevant representation for itself? There's a lot to learn from each of them and they're all awful in their own ways - even the last. But I think there's something great waiting for us in the middle ground :slightly_smiling_face:",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "9e85c7bdd45b",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-11-25\/487455880658_9e85c7bdd45b1d2d4721_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Granger",
            "display_name": "ibdknox",
            "team": "T5TCAFTA9",
            "name": "ibdknox",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Oi5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "One of the open problems down the road of hyperlink-it-all is how you make all the views computable. I have that drawing of the bridge - how does that turn into useful information for me to work with without losing the semantics the drawing is actually providing me? There are lots of deep holes to fall into along the path: notions of identity, the dream of semantically preserving transforms, conceptual implicitness with execution stability, and so on.\n\nIn the end I think you run up against the curse of dimensionality no matter what you do and at some point you have to accept there will always be representations that you can't preserve. Our best efforts remain lossy (computers aside, we still have no idea how to convey information losslessly across formats between people). But that's "
                            },
                            {
                                "type": "text",
                                "text": "ok",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". I'm firmly in the camp that when it comes to basically anything related to thought, the answer is always somewhere in the intersection of an effectively uncountable number of axes. To suggest that any one way is superior is to forget the simple question \"in what context?\" And trying to answer that question is an exercise in attempting, and failing, to capture all the external forces that apply. As Ivan said, at some point we have to stop claiming X is better and instead start saying \"this is useful in some context that we potentially share.\" If a system captures enough of those useful cases, it eventually overcomes all the ways in which it is inadequate and we get the thing we complain about but we use anyway because it's \"good enough.\"\n\nI've always found looking at the extremes useful - what if everything was text? what if nothing was text? what if everything was the most domain-relevant representation for itself? There's a lot to learn from each of them and they're all awful in their own ways - even the last. But I think there's something great waiting for us in the middle ground "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "point_up",
                "users": [
                    "UHWC9PXBL",
                    "UFLN9JFRT"
                ],
                "count": 2
            },
            {
                "name": "heart",
                "users": [
                    "UMWF81HTP",
                    "U8A5MS6R1",
                    "UKP3B2J5D"
                ],
                "count": 3
            },
            {
                "name": "+1",
                "users": [
                    "UAVCC2X70",
                    "UJBAJNFLK",
                    "UFLN9JFRT",
                    "UE6EFEPTQ",
                    "UJ6LDMMN0",
                    "UAHHWT22U",
                    "UML4ZEKDK"
                ],
                "count": 7
            },
            {
                "name": "white_check_mark",
                "users": [
                    "UFPPABQ7P"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U8A5MS6R1",
        "type": "message",
        "ts": "1592529048.399300",
        "edited": {
            "user": "U8A5MS6R1",
            "ts": "1592529287.000000"
        },
        "client_msg_id": "aab3b6a3-3777-4ec2-b2e7-a333c0d3c0c4",
        "text": "My reply went super off tangent :smile: so I'll tldr it but leave the text below. TL;DR it's not about total correspondence, but creating a virtual world where 'views' are a reified notion and so are partial correspondence between various views.\n\nLong tangent:\nThose are kind of the holes I'm stumbling around in. What we do presently is computation _within_ various views. These views are related but the links are not reliably or uniformly maintained. E.g. we compute the intersection of two lines within a 'data structure view' and map the result back to the 'canvas view'. This is a partial mapping: some structures in the first view may map onto points on the canvas but other structures wont. Computation may not even exist in the 'canvas view world' - all views don't have to be computable. When we run a program and step through the debugger, we again map objects in the one view (compiled running code) onto objects in another view (source). Most of these connections across views are severed by default. Only if the debug symbols were injected _and_ you have a program that can interpret those _and_ have the right version of the source around, you'll be able to follow the correspondence between objects. The 'filesystem' is yet another view that we map a lot of objects into and later try to extract by reversing the process.\n\nMy search here is not to find some kind of total correspondence meta model that can be used to drive all other models. I don't think that is fruitful, because we want to have many new models and new views that may not fit completely within old ideas. What I think is missing is the very notion of 'views' with 'objects', where there is a partial correspondence between objects across different views. This model should be the fundamental nature of the virtual world. We've made the virtual world much like the physical world (~objects with severed links, the idea of 'just data'). So instead of the traditional idea of \"lets create a program that operates on data (e.g. database, paint app)\" we only ever create \"views with expose objects\" and the system lets us connect these objects to others outside.\n\nTo take the example of the drawing of the bridge. Say I receive this drawing, I should be able to pick up various view objects I have laying about, and apply them one at a time to the drawing. Much like picking up various lenses to look at a butterfly. Say I find a suitable view that shows a list of all corner points in the drawing. Now I can leave this view attached and on top apply other functions\/programs I have laying about that can work with the 'point view'. Now I've modified the 'point view' and my change gets mapped back onto the drawing via the view. This creates a new drawing (attached to the original one for provenance, and attached also to other paraphernalia I have used) which I can then share. One idea here is we haven't sent around a 'dead drawing' but something more like a live object. Another is that we have stable references to versions of objects, and perhaps even subobjects.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "340ZQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "My reply went super off tangent "
                            },
                            {
                                "type": "emoji",
                                "name": "smile",
                                "unicode": "1f604"
                            },
                            {
                                "type": "text",
                                "text": " so I'll tldr it but leave the text below. TL;DR it's not about total correspondence, but creating a virtual world where 'views' are a reified notion and so are partial correspondence between various views.\n\nLong tangent:\nThose are kind of the holes I'm stumbling around in. What we do presently is computation "
                            },
                            {
                                "type": "text",
                                "text": "within",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " various views. These views are related but the links are not reliably or uniformly maintained. E.g. we compute the intersection of two lines within a 'data structure view' and map the result back to the 'canvas view'. This is a partial mapping: some structures in the first view may map onto points on the canvas but other structures wont. Computation may not even exist in the 'canvas view world' - all views don't have to be computable. When we run a program and step through the debugger, we again map objects in the one view (compiled running code) onto objects in another view (source). Most of these connections across views are severed by default. Only if the debug symbols were injected "
                            },
                            {
                                "type": "text",
                                "text": "and",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " you have a program that can interpret those "
                            },
                            {
                                "type": "text",
                                "text": "and",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " have the right version of the source around, you'll be able to follow the correspondence between objects. The 'filesystem' is yet another view that we map a lot of objects into and later try to extract by reversing the process.\n\nMy search here is not to find some kind of total correspondence meta model that can be used to drive all other models. I don't think that is fruitful, because we want to have many new models and new views that may not fit completely within old ideas. What I think is missing is the very notion of 'views' with 'objects', where there is a partial correspondence between objects across different views. This model should be the fundamental nature of the virtual world. We've made the virtual world much like the physical world (~objects with severed links, the idea of 'just data'). So instead of the traditional idea of \"lets create a program that operates on data (e.g. database, paint app)\" we only ever create \"views with expose objects\" and the system lets us connect these objects to others outside.\n\nTo take the example of the drawing of the bridge. Say I receive this drawing, I should be able to pick up various view objects I have laying about, and apply them one at a time to the drawing. Much like picking up various lenses to look at a butterfly. Say I find a suitable view that shows a list of all corner points in the drawing. Now I can leave this view attached and on top apply other functions\/programs I have laying about that can work with the 'point view'. Now I've modified the 'point view' and my change gets mapped back onto the drawing via the view. This creates a new drawing (attached to the original one for provenance, and attached also to other paraphernalia I have used) which I can then share. One idea here is we haven't sent around a 'dead drawing' but something more like a live object. Another is that we have stable references to versions of objects, and perhaps even subobjects."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UEBG0NPDK",
                    "U5STGTB3J",
                    "UHWC9PXBL"
                ],
                "count": 3
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0"
                ],
                "count": 1
            },
            {
                "name": "+1",
                "users": [
                    "UML4ZEKDK"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1592541332.401200",
        "client_msg_id": "0a16dde8-a9f1-405d-a882-fefb3c3bca4a",
        "text": "I guess this kind of discussion has been going on for a long time (for a 90-year-old contribution, see <https:\/\/en.wikipedia.org\/wiki\/The_Treachery_of_Images>), and is not going to stop. Any analysis, by whatever means, depends on the choice of a point of view, and there are always other points of view that require a different analysis. Computing doesn't change this, it merely makes it more obvious by multiplying the number of points of views enormously. And by driving wedges between similar but not quite identical points of view - which I think is the problem we are really discussing in this thread.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "attachments": [
            {
                "image_url": "https:\/\/upload.wikimedia.org\/wikipedia\/en\/b\/b9\/MagrittePipe.jpg",
                "image_width": 378,
                "image_height": 264,
                "image_bytes": 34329,
                "title": "The Treachery of Images",
                "title_link": "https:\/\/en.wikipedia.org\/wiki\/The_Treachery_of_Images",
                "from_url": "https:\/\/en.wikipedia.org\/wiki\/The_Treachery_of_Images",
                "author_name": "Wikipedia",
                "author_link": "https:\/\/en.wikipedia.org\/",
                "text": "The Treachery of Images (French: La Trahison des images) is a 1929 painting by surrealist painter René Magritte. It is also known as This is Not a Pipe and The Wind and the Song. Magritte painted it when he was 30 years old. It is on display at the Los Angeles County Museum of Art.The painting shows a pipe. Below it, Magritte painted, \"Ceci n'est pas une pipe\", French for \"This is not a pipe\".\n\nThe famous pipe. How people reproached me for it!  And yet, could you stuff my pipe?  No, it's just a representation, is it not? So if I had written on my picture \"This is a pipe\", I'd have been lying!\nThe theme of pipes with the text \"Ceci n'est pas une pipe\" is extended in Les Mots et Les Images, La Clé des Songes, Ceci n'est pas une pipe (L'air et la chanson), The Tune and Also the Words, Ceci n’est pas une pomme, and Les Deux Mystères.The painting is sometimes given as an example of meta message conveyed by paralanguage, like Alfred Korzybski's \"The word is not the thing\" and \"The map is not the territory\", as well as Denis Diderot's This is not a story. One interpretation is that the pipe in the painting is not a pipe, but rather a drawing of a pipe.\nOn December 15, 1929, Paul Éluard and André Breton published an essay about poetry in La Révolution surréaliste (The Surrealist Revolution) as a reaction to the publication by poet Paul Valéry \"Notes sur la poésie\" in Les Nouvelles littéraires of September 28, 1929. When Valéry wrote \"Poetry is a survival\", Breton and Éluard made fun of it and wrote \"Poetry is a pipe\", as a reference to Magritte's <http:\/\/painting.In|painting.In> the same edition of La Révolution surréaliste, Magritte published \"Les mots et les images\" (his founding text which illustrated where words play with images), his answer to the survey on love, and Je ne vois pas la [femme] cachée dans la forêt, a painting tableau surrounded by photos of sixteen surrealists with their eyes closed, including Magritte himself.",
                "fallback": "wikipedia: The Treachery of Images",
                "service_icon": "https:\/\/a.slack-edge.com\/80588\/img\/unfurl_icons\/wikipedia.png",
                "id": 1,
                "original_url": "https:\/\/en.wikipedia.org\/wiki\/The_Treachery_of_Images"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tPS",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I guess this kind of discussion has been going on for a long time (for a 90-year-old contribution, see "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/en.wikipedia.org\/wiki\/The_Treachery_of_Images"
                            },
                            {
                                "type": "text",
                                "text": "), and is not going to stop. Any analysis, by whatever means, depends on the choice of a point of view, and there are always other points of view that require a different analysis. Computing doesn't change this, it merely makes it more obvious by multiplying the number of points of views enormously. And by driving wedges between similar but not quite identical points of view - which I think is the problem we are really discussing in this thread."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "U8A5MS6R1",
                    "UFLN9JFRT"
                ],
                "count": 2
            },
            {
                "name": "exploding_head",
                "users": [
                    "UFPPABQ7P"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U8A5MS6R1",
        "type": "message",
        "ts": "1592542886.401600",
        "client_msg_id": "49901bb9-3c50-4b67-ae8a-62c18d8a95ad",
        "text": "Wow Konrad got right to the point :point_up:\n&gt; Computing doesn't change this, it merely makes it more obvious by multiplying the number of points of views enormously. And by driving wedges between similar but not quite identical points of view\nYes exactly! 'Views' are points of view, and we have a bajillion of them in computing - each showing only a slice of what is, in its own language.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "b7c63cc07373",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-03-21\/584465935395_b7c63cc07373326ec6ea_72.jpg",
            "first_name": "Shalabh",
            "real_name": "Shalabh",
            "display_name": "shalabh",
            "team": "T5TCAFTA9",
            "name": "shalabh.chaturvedi",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1592430013.363800",
        "parent_user_id": "UJKKBAMLL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "N0M=",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Wow Konrad got right to the point "
                            },
                            {
                                "type": "emoji",
                                "name": "point_up",
                                "unicode": "261d-fe0f"
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Computing doesn't change this, it merely makes it more obvious by multiplying the number of points of views enormously. And by driving wedges between similar but not quite identical points of view"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yes exactly! 'Views' are points of view, and we have a bajillion of them in computing - each showing only a slice of what is, in its own language."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]