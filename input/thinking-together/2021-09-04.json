[
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1630741349.056400",
        "client_msg_id": "bcddc709-71dd-4982-9348-7001f6e2497f",
        "text": "<@U027P92A0N5> Common Lisp and Smalltalk make no distinction between \"language\" and \"development environment\", being live systems. Put differently, they are more integrated than anything called IDE today.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630621354.050800",
        "parent_user_id": "U01AD80KMLK",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "R4b",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U027P92A0N5"
                            },
                            {
                                "type": "text",
                                "text": " Common Lisp and Smalltalk make no distinction between \"language\" and \"development environment\", being live systems. Put differently, they are more integrated than anything called IDE today."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "U013ZLJARC7",
                    "UA14TGLTC"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "UCGAK10LS",
        "type": "message",
        "ts": "1630745854.074100",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1630745903.000000"
        },
        "client_msg_id": "3694edf0-7cff-48c1-b14d-cf5d4f5a2892",
        "text": "*Huge idea:* what if tensors are the next-generation replacement for RAM? Classic RAM (I'm talking about the software abstraction, not the physical hardware) is just a vector with 2^64 cells, most of which are zero and not backed by physical memory. This is commonly known as a _sparse_ vector. The current AI boom has made it obvious that higher-dimensional memory chunks, known as _tensors_, are an important idea, especially sparse ones. Other than being higher-dimensional, key differences between tensors and RAM include:\n• An AI app will typically work with multiple tensors, but a classical app will only work with one RAM. (Though Wasm can have multiple RAMs, known as \"linear memories\", and of course, you can pretend to have multiple memories using abstractions like _malloc_).\n• Tensors can be subjected to *unary operations* such as slicing, permuting, and aggregation (min, max, sum, product), that generalize the boring read and write operations on RAM.\n• Tensors can be subjected to *binary operations* such as multiplication\/contraction (generalizing matrix multiplication), convolution, and element-wise addition.\nThe data of everyday programs is often very heterogeneous, which corresponds to having lots of *sparse* tensors. Sparse tensors need good support in software and _ideally_ in hardware. Thankfully, there is AI hardware being developed that is designed to operate on sparse tensors, by way of dedicated circuits that can compress and decompress them. <https:\/\/tenstorrent.com\/|Tenstorrent> is probably the leader here.\n\nHere's a fun fact: multiplication of sparse Boolean tensors is equivalent to a database equi-join. So if you think databases are important, then maybe you should give tensors some thought.\n\nAnd relatedly: operations on tensors are typically massively-parallelizable, thus could be a good foundation for a high-performance programming language that compiles to AI hardware.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6402e9775ed7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-13\/5095853045814_6402e9775ed73b75334f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630745854.074100",
        "reply_count": 29,
        "reply_users_count": 8,
        "latest_reply": "1631025210.120600",
        "reply_users": [
            "UPVBV34EL",
            "UJZS8UUJV",
            "UCGAK10LS",
            "U01AD80KMLK",
            "UJBAJNFLK",
            "U027P92A0N5",
            "U01JNTE35QS",
            "UCUSW7WVD"
        ],
        "replies": [
            {
                "user": "UPVBV34EL",
                "ts": "1630750683.074300"
            },
            {
                "user": "UJZS8UUJV",
                "ts": "1630778381.075000"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630795361.078700"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630795536.081700"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630795876.084800"
            },
            {
                "user": "U01AD80KMLK",
                "ts": "1630806483.085100"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630806818.088800"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630807242.093300"
            },
            {
                "user": "UJBAJNFLK",
                "ts": "1630829040.093600"
            },
            {
                "user": "UJBAJNFLK",
                "ts": "1630829126.093800"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630831671.094000"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630831833.094200"
            },
            {
                "user": "UJBAJNFLK",
                "ts": "1630867715.095800"
            },
            {
                "user": "U027P92A0N5",
                "ts": "1630919270.102200"
            },
            {
                "user": "U027P92A0N5",
                "ts": "1630919399.102400"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630919603.106300"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630919660.107900"
            },
            {
                "user": "U027P92A0N5",
                "ts": "1630923308.108900"
            },
            {
                "user": "U027P92A0N5",
                "ts": "1630923435.109100"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630923655.112000"
            },
            {
                "user": "U027P92A0N5",
                "ts": "1630926920.112200"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630930637.115400"
            },
            {
                "user": "U027P92A0N5",
                "ts": "1630931054.115600"
            },
            {
                "user": "U01JNTE35QS",
                "ts": "1630940171.116400"
            },
            {
                "user": "UJBAJNFLK",
                "ts": "1630943903.116700"
            },
            {
                "user": "U027P92A0N5",
                "ts": "1630944775.117000"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630968182.118100"
            },
            {
                "user": "UCGAK10LS",
                "ts": "1630968344.118300"
            },
            {
                "user": "UCUSW7WVD",
                "ts": "1631025210.120600"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3dvvc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Huge idea:",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " what if tensors are the next-generation replacement for RAM? Classic RAM (I'm talking about the software abstraction, not the physical hardware) is just a vector with 2^64 cells, most of which are zero and not backed by physical memory. This is commonly known as a "
                            },
                            {
                                "type": "text",
                                "text": "sparse",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " vector. The current AI boom has made it obvious that higher-dimensional memory chunks, known as "
                            },
                            {
                                "type": "text",
                                "text": "tensors",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", are an important idea, especially sparse ones. Other than being higher-dimensional, key differences between tensors and RAM include:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "An AI app will typically work with multiple tensors, but a classical app will only work with one RAM. (Though Wasm can have multiple RAMs, known as \"linear memories\", and of course, you can pretend to have multiple memories using abstractions like "
                                    },
                                    {
                                        "type": "text",
                                        "text": "malloc",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": ")."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Tensors can be subjected to "
                                    },
                                    {
                                        "type": "text",
                                        "text": "unary operations",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " such as slicing, permuting, and aggregation (min, max, sum, product), that generalize the boring read and write operations on RAM."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Tensors can be subjected to "
                                    },
                                    {
                                        "type": "text",
                                        "text": "binary operations",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " such as multiplication\/contraction (generalizing matrix multiplication), convolution, and element-wise addition."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nThe data of everyday programs is often very heterogeneous, which corresponds to having lots of "
                            },
                            {
                                "type": "text",
                                "text": "sparse",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " tensors. Sparse tensors need good support in software and "
                            },
                            {
                                "type": "text",
                                "text": "ideally",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " in hardware. Thankfully, there is AI hardware being developed that is designed to operate on sparse tensors, by way of dedicated circuits that can compress and decompress them. "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/tenstorrent.com\/",
                                "text": "Tenstorrent"
                            },
                            {
                                "type": "text",
                                "text": " is probably the leader here.\n\nHere's a fun fact: multiplication of sparse Boolean tensors is equivalent to a database equi-join. So if you think databases are important, then maybe you should give tensors some thought.\n\nAnd relatedly: operations on tensors are typically massively-parallelizable, thus could be a good foundation for a high-performance programming language that compiles to AI hardware."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UPVBV34EL",
        "type": "message",
        "ts": "1630750683.074300",
        "client_msg_id": "36393e0b-fc8c-4a00-8f53-323f4e929253",
        "text": "&gt; And relatedly: operations on tensors are typically massively-parallelizable, thus could be a good foundation for a high-performance programming language that compiles to AI hardware. \nYou hooked me there",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "259a1e56ad2e",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-10-28\/811814014976_259a1e56ad2e11fe3d56_72.jpg",
            "first_name": "",
            "real_name": "Shubhadeep Roychowdhury",
            "display_name": "Shubhadeep Roychowdhury",
            "team": "T5TCAFTA9",
            "name": "shubhadeeproychowdhur",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630745854.074100",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "57nD",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "And relatedly: operations on tensors are typically massively-parallelizable, thus could be a good foundation for a high-performance programming language that compiles to AI hardware. "
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nYou hooked me there"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UA14TGLTC",
        "type": "message",
        "ts": "1630756988.074700",
        "client_msg_id": "3b39dd0d-0990-448e-b03e-22464c9721f8",
        "text": "Came here to echo <@U027P92A0N5> about Common Lisp conditions.  Practical Common Lisp has a good introduction <https:\/\/gigamonkeys.com\/book\/beyond-exception-handling-conditions-and-restarts.html>.\n\n<@U013ZLJARC7> had a good tl;dr.\n\nMore generally, I feel we underutilize the stack as a way to abstract.  Instead of explicit passing, build context through selective use of dynamically scoped variables.\n\nAlternatively, I guess there's the aspect oriented notion of CFlow <https:\/\/schuchert.github.io\/wikispaces\/pages\/aop\/AspectJ_CFlowExplained>.\n\nAnd I guess better functional programmers than me could say something about comonads, but in as much as option, collection, either, and exception monads are all about returning things, there should be a sort of opposite construction.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gae6d55db9d1",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "William Taysom",
            "display_name": "wtaysom",
            "team": "T5TCAFTA9",
            "name": "wtaysom",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630621354.050800",
        "parent_user_id": "U01AD80KMLK",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4DNc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Came here to echo "
                            },
                            {
                                "type": "user",
                                "user_id": "U027P92A0N5"
                            },
                            {
                                "type": "text",
                                "text": " about Common Lisp conditions.  Practical Common Lisp has a good introduction "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/gigamonkeys.com\/book\/beyond-exception-handling-conditions-and-restarts.html"
                            },
                            {
                                "type": "text",
                                "text": ".\n\n"
                            },
                            {
                                "type": "user",
                                "user_id": "U013ZLJARC7"
                            },
                            {
                                "type": "text",
                                "text": " had a good tl;dr.\n\nMore generally, I feel we underutilize the stack as a way to abstract.  Instead of explicit passing, build context through selective use of dynamically scoped variables.\n\nAlternatively, I guess there's the aspect oriented notion of CFlow "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/schuchert.github.io\/wikispaces\/pages\/aop\/AspectJ_CFlowExplained"
                            },
                            {
                                "type": "text",
                                "text": ".\n\nAnd I guess better functional programmers than me could say something about comonads, but in as much as option, collection, either, and exception monads are all about returning things, there should be a sort of opposite construction."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJZS8UUJV",
        "type": "message",
        "ts": "1630778381.075000",
        "client_msg_id": "24ecf77d-8b1a-424a-9909-7d9668338a70",
        "text": "So we already store tensors in RAM and perform various operations on them. You said software not hardware, so is the difference here that the abstraction between the 1D (flattened) data and its higher dimensional form is provided at a lower level in the software?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g62b260c347a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/962b260c347a11e19b0fdce4a97a5d49.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "Luke",
            "real_name": "Luke Persola",
            "display_name": "Luke Persola",
            "team": "T5TCAFTA9",
            "name": "lukepersola",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630745854.074100",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Aay",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So we already store tensors in RAM and perform various operations on them. You said software not hardware, so is the difference here that the abstraction between the 1D (flattened) data and its higher dimensional form is provided at a lower level in the software?"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U027P92A0N5"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UCGAK10LS",
        "type": "message",
        "ts": "1630795361.078700",
        "client_msg_id": "6EC69FC1-3F5F-42A3-B9A5-4D22C5C4E787",
        "text": "I mean the _assembly language_ of the hardware should be phrased in terms of operations on tensors. :slightly_smiling_face: The programmer should not be concerned with whether the tensor is ultimately flattened into a linear array of SRAM or DRAM cells. (In AI hardware, they definitely won’t be.)",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6402e9775ed7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-13\/5095853045814_6402e9775ed73b75334f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630745854.074100",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Fn+Q",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I mean the "
                            },
                            {
                                "type": "text",
                                "text": "assembly language",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " of the hardware should be phrased in terms of operations on tensors. "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            },
                            {
                                "type": "text",
                                "text": " The programmer should not be concerned with whether the tensor is ultimately flattened into a linear array of SRAM or DRAM cells. (In AI hardware, they definitely won’t be.)"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UJZS8UUJV"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UCGAK10LS",
        "type": "message",
        "ts": "1630795536.081700",
        "client_msg_id": "CD966572-30CB-4B62-A574-B7DCB55748A0",
        "text": "My goal with this post is just to get people thinking a little differently about the memory model upon which a programming language is built. Tensor-based memory models are about to become mainstream (next 5 years) thanks to the AI boom. Could lead to some exciting new paradigms of programming.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6402e9775ed7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-13\/5095853045814_6402e9775ed73b75334f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630745854.074100",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "8yc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "My goal with this post is just to get people thinking a little differently about the memory model upon which a programming language is built. Tensor-based memory models are about to become mainstream (next 5 years) thanks to the AI boom. Could lead to some exciting new paradigms of programming."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UCGAK10LS",
        "type": "message",
        "ts": "1630795876.084800",
        "client_msg_id": "59167AAE-88EA-402C-8F60-79E2A09253BB",
        "text": "Here’s a challenge for everyone: when you visualise the act of “allocating memory”, what do you see? If you see a big linear chunk that you can address with a pointer, then maybe you’re trapped in 1-dimensional thinking. I certainly was\/am.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6402e9775ed7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-13\/5095853045814_6402e9775ed73b75334f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630745854.074100",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ErQrW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Here’s a challenge for everyone: when you visualise the act of “allocating memory”, what do you see? If you see a big linear chunk that you can address with a pointer, then maybe you’re trapped in 1-dimensional thinking. I certainly was\/am."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01AD80KMLK",
        "type": "message",
        "ts": "1630806483.085100",
        "client_msg_id": "4bb1cabf-3823-4c83-bc87-e990f8fbce4c",
        "text": "How's your memory mostly zeros? If it is, you should use smaller machines. I think the idea that RAM is similar to a sparse vector is often not right. At least not if you use Chrome for browsing.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "a07cdcb6d037",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-09-09\/1376906509376_a07cdcb6d037bf7b6a5e_72.jpg",
            "first_name": "",
            "real_name": "Denny Vrandečić",
            "display_name": "Denny Vrandečić",
            "team": "T5TCAFTA9",
            "name": "dvrandecic",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630745854.074100",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "\/vz7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "How's your memory mostly zeros? If it is, you should use smaller machines. I think the idea that RAM is similar to a sparse vector is often not right. At least not if you use Chrome for browsing."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UCGAK10LS",
        "type": "message",
        "ts": "1630806818.088800",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1630806862.000000"
        },
        "client_msg_id": "ABAF8820-147D-406E-9F72-DD64C3342F32",
        "text": "I’m referring to virtual memory (i.e. what apps see). I guarantee you that your 64-bits of virtual memory are mostly zeroes! And with a paging system, you can write across vast swathes of the memory whilst only consuming physical resources for the pages you actually touch. That’s what I mean when I describe linear memory as a sparse vector.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6402e9775ed7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-13\/5095853045814_6402e9775ed73b75334f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630745854.074100",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7He+A",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I’m referring to virtual memory (i.e. what apps see). I guarantee you that your 64-bits of virtual memory are mostly zeroes! And with a paging system, you can write across vast swathes of the memory whilst only consuming physical resources for the pages you actually touch. That’s what I mean when I describe linear memory as a sparse vector."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UCGAK10LS",
        "type": "message",
        "ts": "1630807242.093300",
        "client_msg_id": "118D103C-8CAD-40EA-9E74-FF2BE32E3373",
        "text": "Now imagine what it would be like to have a memory model where your memory is sparse at the _byte_-level, and is multidimensional, and you can have multiple memories and perform massively-parallel operations (such as aggregations) over them. This is what sparse tensors are.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6402e9775ed7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-04-13\/5095853045814_6402e9775ed73b75334f_72.jpg",
            "first_name": "",
            "real_name": "Nick Smith",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "nmsmith65",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1630745854.074100",
        "parent_user_id": "UCGAK10LS",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "aHN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Now imagine what it would be like to have a memory model where your memory is sparse at the "
                            },
                            {
                                "type": "text",
                                "text": "byte",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "-level, and is multidimensional, and you can have multiple memories and perform massively-parallel operations (such as aggregations) over them. This is what sparse tensors are."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]