[
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1679471411.976119",
        "client_msg_id": "d8d65683-87bf-434c-9f5d-83fe5ddc8538",
        "text": "The \"generation over explanation\" aspect mentioned by <@UMQ6LR9NZ> is something I worry about as well. I am a research scientist, my job is to create and improve explanations. Code in my universe should support explaining things, and should itself be understandable. If we end up with bloated codebases in which layer upon layer is AI-generated, we cannot do science with them.\n\nOn the other hand, quick generation at the top level is great. Glue code? Let an AI do it. As long as the code is shallow and small, it remains understandable.\n\nQuite often, today's glue code ends up in tomorrow's libraries. At that point, we need to clean up the mess. Today we don't. Will we see AI support for this job? Maybe. It sounds doable. But does anyone care AND have the means to work on this? I think this depends on how Open Source AI will develop in the near future.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1678975525.942829",
        "parent_user_id": "U04TXPZ1W3S",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ISZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The \"generation over explanation\" aspect mentioned by "
                            },
                            {
                                "type": "user",
                                "user_id": "UMQ6LR9NZ"
                            },
                            {
                                "type": "text",
                                "text": " is something I worry about as well. I am a research scientist, my job is to create and improve explanations. Code in my universe should support explaining things, and should itself be understandable. If we end up with bloated codebases in which layer upon layer is AI-generated, we cannot do science with them.\n\nOn the other hand, quick generation at the top level is great. Glue code? Let an AI do it. As long as the code is shallow and small, it remains understandable.\n\nQuite often, today's glue code ends up in tomorrow's libraries. At that point, we need to clean up the mess. Today we don't. Will we see AI support for this job? Maybe. It sounds doable. But does anyone care AND have the means to work on this? I think this depends on how Open Source AI will develop in the near future."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "U016VUZGUUQ"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U02U0AS3J49",
        "type": "message",
        "ts": "1679513456.154469",
        "client_msg_id": "bfca994f-e608-4a6b-b018-47a3b5abeb1c",
        "text": "I use symbolic knowledge representation to generate models of laws that are capable of being validated by subject matter experts, and use those models to generate answers and explanations from fact scenarios. The explanations are typically extremely verbose, and as I add features to the representation language, they tend to get longer. I am currently exploring using GPT3\/4 to summarize those explanations in ways that are easier to digest, with some success. So I use it ON explanations, but not FOR them. I anticipate also using it in a Codex-like way to help users generate the symbolic models of legal text. I will likely try that myself as part of my own coding workflow inside the tool, first. But it remains to be seen if even GPT4 makes that feasible, and there are some technical hurdles, because the language currently doesn't have a plain-text representation that is isomorphic with the visual one.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g5247a9c6cbb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/5247a9c6cbb943683c9e2e2cef6eba79.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-72.png",
            "first_name": "Jason",
            "real_name": "Jason Morris",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "jason",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1678975525.942829",
        "parent_user_id": "U04TXPZ1W3S",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "lVse",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I use symbolic knowledge representation to generate models of laws that are capable of being validated by subject matter experts, and use those models to generate answers and explanations from fact scenarios. The explanations are typically extremely verbose, and as I add features to the representation language, they tend to get longer. I am currently exploring using GPT3\/4 to summarize those explanations in ways that are easier to digest, with some success. So I use it ON explanations, but not FOR them. I anticipate also using it in a Codex-like way to help users generate the symbolic models of legal text. I will likely try that myself as part of my own coding workflow inside the tool, first. But it remains to be seen if even GPT4 makes that feasible, and there are some technical hurdles, because the language currently doesn't have a plain-text representation that is isomorphic with the visual one."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]