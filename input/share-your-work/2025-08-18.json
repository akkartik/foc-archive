[
    {
        "user": "U06BZTE8Q3B",
        "type": "message",
        "ts": "1755501591.234379",
        "edited": {
            "user": "U06BZTE8Q3B",
            "ts": "1755501848.000000"
        },
        "client_msg_id": "d9d1c2e0-042d-4420-ae3c-f0aaf617596a",
        "text": ">  Sometimes metaprogramming is dismissed as just being used for the sake of being clever, but this is exactly the kind of runtime flexibility that makes self-modifying systems possible. The kind that would let an AI agent literally write its own capabilities while it's running.\nBut does an LLM-powered agent actually have to facilitate symbolic rule-making in order to coordinate with other parts of the system?\n\nI understand an agent might set parameters for other agents, but LLMs seem capable of developing their own non-human, non-deterministic languages to reason internally.\n\nOr would meta-programming facilitate a human in the loop?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g4c272d7a0e4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/4c272d7a0e4b25c5126a93372d8403b6.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0004-72.png",
            "first_name": "D.",
            "real_name": "D. Schmudde",
            "display_name": "D. Schmudde",
            "team": "T5TCAFTA9",
            "name": "d",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1755436500.789159",
        "parent_user_id": "U05GSC0B4A0",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "C9r+J",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": " Sometimes metaprogramming is dismissed as just being used for the sake of being clever, but this is exactly the kind of runtime flexibility that makes self-modifying systems possible. The kind that would let an AI agent literally write its own capabilities while it's running."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nBut does an LLM-powered agent actually have to facilitate symbolic rule-making in order to coordinate with other parts of the system?\n\nI understand an agent might set parameters for other agents, but LLMs seem capable of developing their own non-human, non-deterministic languages to reason internally.\n\nOr would meta-programming facilitate a human in the loop?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05GSC0B4A0",
        "type": "message",
        "ts": "1755523469.944389",
        "client_msg_id": "b43edcbd-a8ca-47a0-bedd-d5eefe235ade",
        "text": "Hm yeah, I don't think this is an either\/or, it's more about providing a shared, modifiable structure that an LLM do whatever it likes inside and then ways to incorporate it. It needs to do symbolic rule-making at some level to interact with the rest of the system, right?\n\nThe other thing is that LLMs do really well when you provide examples for them to work off of and constrain what they can do, so once you have a structure you can feed into an LLM with something like:\nHere's the interface and 5 working examples of {THING} -&gt; generate me a new {THING} that does {new behavior}\nYou have a really high likelihood of getting exactly what you want and being able to use it right away, but there's still a chance it needs some modifications before you can use it.\n\nBut thinking more about your question at the end, maybe this is all about human in the loop...I was originally just thinking about it at the first level: just being able to approve\/reject an action an agent wants to take and providing an interface for that.\n\nBut there's a second aspect: being able to ask questions to see and inspect the structure the LLM has built and having the language to do it...\n\nAnd maybe even a third: having a common language to modify the system with the human being able to say \"add a new governance rule to this sub-system\" or an agent being able to say something like \"I need a new sub-system for xyz capability\" and they're communicating in the same structural language.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g6366d8630c4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6366d8630c4e2394142efb0a9358fcc6.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "Scott",
            "real_name": "Scott",
            "display_name": "Scott",
            "team": "T5TCAFTA9",
            "name": "scott099",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1755436500.789159",
        "parent_user_id": "U05GSC0B4A0",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "USJO4",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Hm yeah, I don't think this is an either\/or, it's more about providing a shared, modifiable structure that an LLM do whatever it likes inside and then ways to incorporate it. It needs to do symbolic rule-making at some level to interact with the rest of the system, right?\n\nThe other thing is that LLMs do really well when you provide examples for them to work off of and constrain what they can do, so once you have a structure you can feed into an LLM with something like:\nHere's the interface and 5 working examples of {THING} -> generate me a new {THING} that does {new behavior}\nYou have a really high likelihood of getting exactly what you want and being able to use it right away, but there's still a chance it needs some modifications before you can use it.\n\nBut thinking more about your question at the end, maybe this is all about human in the loop...I was originally just thinking about it at the first level: just being able to approve\/reject an action an agent wants to take and providing an interface for that.\n\nBut there's a second aspect: being able to ask questions to see and inspect the structure the LLM has built and having the language to do it...\n\nAnd maybe even a third: having a common language to modify the system with the human being able to say \"add a new governance rule to this sub-system\" or an agent being able to say something like \"I need a new sub-system for xyz capability\" and they're communicating in the same structural language."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05GSC0B4A0",
        "type": "message",
        "ts": "1755523601.801999",
        "client_msg_id": "6a1e8fe9-6ced-4f2c-bf63-684f9b9538ca",
        "text": "And now I'm thinking I wonder if an even more interesting feature of this framework is about creating the language between human and AI, to put a structure around the \"their own non-human, non-deterministic languages to reason internally\"",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g6366d8630c4",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6366d8630c4e2394142efb0a9358fcc6.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "Scott",
            "real_name": "Scott",
            "display_name": "Scott",
            "team": "T5TCAFTA9",
            "name": "scott099",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1755436500.789159",
        "parent_user_id": "U05GSC0B4A0",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4bEZ8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "And now I'm thinking I wonder if an even more interesting feature of this framework is about creating the language between human and AI, to put a structure around the \"their own non-human, non-deterministic languages to reason internally\""
                            }
                        ]
                    }
                ]
            }
        ]
    }
]