<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #thinking-together</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <img src="https://avatars.slack-edge.com/2019-09-09/753296041488_3447742b735b104a7ff2_72.png" style="float:left"/>
      <a href="../thinking-together/1568642855.169000.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Don Abrams</b>
<span style="margin:2em; color:#606060">2019-09-16 07:07</span><br/>
Hi everyone, I'm poking around at the state of the art in session types &lt;-&gt; linear types (lambda calculus) and wondering if anyone has seen it applied to multi-threaded programming (particularly GPU/CPU). In particular, I'm curious if anyone's seen languages that are biased towards pass by reference or have generation-less GC (which seems like it'd have to be rust-like).
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
