[
    {
        "subtype": "thread_broadcast",
        "user": "UAV037WKC",
        "thread_ts": "1677925287.583739",
        "root": {
            "user": "UDQBTJ211",
            "type": "message",
            "ts": "1677925287.583739",
            "client_msg_id": "7acba099-0ebf-4ab2-8d06-ffc1827ce303",
            "text": "<https:\/\/twitter.com\/garybernhardt\/status\/1631866199515738113>",
            "team": "T5TCAFTA9",
            "thread_ts": "1677925287.583739",
            "reply_count": 19,
            "reply_users_count": 11,
            "latest_reply": "1678404020.541969",
            "reply_users": [
                "UDQBTJ211",
                "U03R0B9U1GD",
                "UAJKEBGP8",
                "U016VUZGUUQ",
                "UJBAJNFLK",
                "U035QJ14NN9",
                "UBSMEUXAA",
                "U04MTMF6Y4W",
                "UAV037WKC",
                "U03E4LY27FS",
                "U02NU8FTL5N"
            ],
            "replies": [
                {
                    "user": "UDQBTJ211",
                    "ts": "1677925399.783249"
                },
                {
                    "user": "UDQBTJ211",
                    "ts": "1677925440.574299"
                },
                {
                    "user": "UDQBTJ211",
                    "ts": "1677925651.195299"
                },
                {
                    "user": "U03R0B9U1GD",
                    "ts": "1677927178.376199"
                },
                {
                    "user": "UAJKEBGP8",
                    "ts": "1677970809.181689"
                },
                {
                    "user": "U016VUZGUUQ",
                    "ts": "1677978724.464979"
                },
                {
                    "user": "UJBAJNFLK",
                    "ts": "1678007002.433749"
                },
                {
                    "user": "U03R0B9U1GD",
                    "ts": "1678009478.321519"
                },
                {
                    "user": "U035QJ14NN9",
                    "ts": "1678050644.058159"
                },
                {
                    "user": "UBSMEUXAA",
                    "ts": "1678063143.913699"
                },
                {
                    "user": "U04MTMF6Y4W",
                    "ts": "1678106498.478819"
                },
                {
                    "user": "UDQBTJ211",
                    "ts": "1678174324.104469"
                },
                {
                    "user": "UAV037WKC",
                    "ts": "1678372217.896749"
                },
                {
                    "user": "U03E4LY27FS",
                    "ts": "1678388850.811809"
                },
                {
                    "user": "U016VUZGUUQ",
                    "ts": "1678389317.722429"
                },
                {
                    "user": "U03E4LY27FS",
                    "ts": "1678389925.452699"
                },
                {
                    "user": "U02NU8FTL5N",
                    "ts": "1678395225.898019"
                },
                {
                    "user": "U016VUZGUUQ",
                    "ts": "1678402600.972029"
                },
                {
                    "user": "UAV037WKC",
                    "ts": "1678404020.541969"
                }
            ],
            "is_locked": false,
            "subscribed": false,
            "attachments": [
                {
                    "from_url": "https:\/\/twitter.com\/garybernhardt\/status\/1631866199515738113",
                    "ts": 1677902195,
                    "id": 1,
                    "original_url": "https:\/\/twitter.com\/garybernhardt\/status\/1631866199515738113",
                    "fallback": "<https:\/\/twitter.com\/garybernhardt|@garybernhardt>: 1960s: \"COBOL will let non-programmers make the software!\"\n\n1980s: \"4GLs will let non-programmers make the software!\"\n\n2000s: \"UML will let non-programmers make the software!\"\n\n2020s: \"AI will let non-programmers make the software!\"",
                    "text": "1960s: \"COBOL will let non-programmers make the software!\"\n\n1980s: \"4GLs will let non-programmers make the software!\"\n\n2000s: \"UML will let non-programmers make the software!\"\n\n2020s: \"AI will let non-programmers make the software!\"",
                    "author_name": "Gary Bernhardt",
                    "author_link": "https:\/\/twitter.com\/garybernhardt\/status\/1631866199515738113",
                    "author_icon": "https:\/\/pbs.twimg.com\/profile_images\/1328504683095199745\/YXr3Xioa_normal.jpg",
                    "author_subname": "@garybernhardt",
                    "service_name": "twitter",
                    "service_url": "https:\/\/twitter.com\/",
                    "footer": "Twitter",
                    "footer_icon": "https:\/\/a.slack-edge.com\/80588\/img\/services\/twitter_pixel_snapped_32.png"
                }
            ],
            "blocks": [
                {
                    "type": "rich_text",
                    "block_id": "H+n1f",
                    "elements": [
                        {
                            "type": "rich_text_section",
                            "elements": [
                                {
                                    "type": "link",
                                    "url": "https:\/\/twitter.com\/garybernhardt\/status\/1631866199515738113"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        "type": "message",
        "ts": "1678372217.896749",
        "client_msg_id": "24126059-e85a-4a32-8ed1-118cbe7d0d84",
        "text": "I am beginning to believe that with AI, it might be possible to let non-programmers make software. Until now, most software was imperative and needed to be managed by knowledgable human. With what I am seeing with LLM such as chatGPT, we might be entering declarative software building and not worry about the internals. In fact, I am going to experiment if I can create few ideas I have in my mind using declarative approach.  Would love if anyone can share examples of such attempts already.\n\nDeclarative approach with AI to me is significantly different than no-coding platform, because no-coding platforms have pre-built lego pieces and will have limited configuration potential. But with AI based system what if we can build the lego pieces to our description on demand?",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "JaiCw",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I am beginning to believe that with AI, it might be possible to let non-programmers make software. Until now, most software was imperative and needed to be managed by knowledgable human. With what I am seeing with LLM such as chatGPT, we might be entering declarative software building and not worry about the internals. In fact, I am going to experiment if I can create few ideas I have in my mind using declarative approach.  Would love if anyone can share examples of such attempts already.\n\nDeclarative approach with AI to me is significantly different than no-coding platform, because no-coding platforms have pre-built lego pieces and will have limited configuration potential. But with AI based system what if we can build the lego pieces to our description on demand?"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "U035QJ14NN9",
                    "U03E4LY27FS",
                    "U02NU8FTL5N",
                    "UA14TGLTC"
                ],
                "count": 4
            }
        ]
    },
    {
        "user": "U04MAEU6VHN",
        "type": "message",
        "ts": "1678378273.595259",
        "client_msg_id": "3ce6c725-a792-4c95-b9d4-4c7d921d3b2a",
        "text": "(ftr I don't think bret worked on eve, that was chris granger <https:\/\/chris-granger.com\/resume\/>)",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "43e7ef32ef6c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-01-25\/4713451001249_43e7ef32ef6c84455dbd_72.jpg",
            "first_name": "Jared",
            "real_name": "Jared Forsyth",
            "display_name": "Jared Forsyth",
            "team": "T5TCAFTA9",
            "name": "jabapyth",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1678321880.602369",
        "parent_user_id": "UHWC9PXBL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "eB42Z",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "(ftr I don't think bret worked on eve, that was chris granger "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/chris-granger.com\/resume\/"
                            },
                            {
                                "type": "text",
                                "text": ")"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT",
                    "U0296ACR13M"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "U0296ACR13M",
        "type": "message",
        "ts": "1678378851.460029",
        "client_msg_id": "351ae352-7594-4d96-88bd-744f47e6f657",
        "text": "Well no wonder I was having so difficult time googling the project :sweat_smile:",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "59de929720a2",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-09-08\/4075674207584_59de929720a2fe0a13d8_72.jpg",
            "first_name": "",
            "real_name": "Jarno Montonen",
            "display_name": "Jarno Montonen",
            "team": "T5TCAFTA9",
            "name": "jarno.montonen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1678321880.602369",
        "parent_user_id": "UHWC9PXBL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7o9",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Well no wonder I was having so difficult time googling the project "
                            },
                            {
                                "type": "emoji",
                                "name": "sweat_smile",
                                "unicode": "1f605"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03E4LY27FS",
        "type": "message",
        "ts": "1678388850.811809",
        "edited": {
            "user": "U03E4LY27FS",
            "ts": "1678388904.000000"
        },
        "client_msg_id": "0E793BCA-821D-419C-AC6C-2AD2959919A6",
        "text": "Elsewhere has been mentioned (please credit whoever said this!) that this LLM stuff is a “universal coupler”. You can ask for an amalgamation of any set of arbitrary things, and _something_ will come back, which can be iterated on more.\n\nThis means that, just like people got used to refining their search terms, they can learn to refine their requests to get what they want, and like you said, _without needing to learn the syntax for the computer-language to get it done_. That’s huge.\n\nI give it maybe a year or two, at the most, until prompting for code becomes some on-premise, logged, reproducible, and shareable just like any other media asset. Generating code and sharing the prompt + output will be the new wave of the .gist, and there will be a major shift to those who can accurately describe a need over those who can accurately _translate_ that need into a _specific_ language. \n\nWe current devs will still be relevant: we are trained and disciplined on specifying requirements and understanding what things to ask for in a program or algorithm. Id be a very happy person if my skills gradually transition to helping others understand why their requests aren’t getting what they want, and writing those prompt-requests for others just like writing a software package.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "98f0011b77c6",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-04-28\/3450316621254_98f0011b77c61bbc241b_72.jpg",
            "first_name": "Ivan",
            "real_name": "Ivan Lugo",
            "display_name": "Ivan Lugo",
            "team": "T5TCAFTA9",
            "name": "iheartlappy486",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1677925287.583739",
        "parent_user_id": "UDQBTJ211",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uPJ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Elsewhere has been mentioned (please credit whoever said this!) that this LLM stuff is a “universal coupler”. You can ask for an amalgamation of any set of arbitrary things, and "
                            },
                            {
                                "type": "text",
                                "text": "something ",
                                "style": {
                                    "bold": false,
                                    "italic": true,
                                    "strike": false
                                }
                            },
                            {
                                "type": "text",
                                "text": "will come back, which can be iterated on more.\n\nThis means that, just like people got used to refining their search terms, they can learn to refine their requests to get what they want, and like you said, "
                            },
                            {
                                "type": "text",
                                "text": "without needing to learn the syntax for the computer-language to get it done",
                                "style": {
                                    "bold": false,
                                    "italic": true,
                                    "strike": false
                                }
                            },
                            {
                                "type": "text",
                                "text": ". That’s huge.\n\nI give it maybe a year or two, at the most, until prompting for code becomes some on-premise, logged, reproducible, and shareable just like any other media asset. Generating code and sharing the prompt + output will be the new wave of the .gist, and there will be a major shift to those who can accurately describe a need over those who can accurately "
                            },
                            {
                                "type": "text",
                                "text": "translate",
                                "style": {
                                    "bold": false,
                                    "italic": true,
                                    "strike": false
                                }
                            },
                            {
                                "type": "text",
                                "text": " that need into a "
                            },
                            {
                                "type": "text",
                                "text": "specific",
                                "style": {
                                    "bold": false,
                                    "italic": true,
                                    "strike": false
                                }
                            },
                            {
                                "type": "text",
                                "text": " language. \n\nWe current devs will still be relevant: we are trained and disciplined on specifying requirements and understanding what things to ask for in a program or algorithm. Id be a very happy person if my skills gradually transition to helping others understand why their requests aren’t getting what they want, and writing those prompt-requests for others just like writing a software package."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UAV037WKC",
                    "UA14TGLTC"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "U016VUZGUUQ",
        "type": "message",
        "ts": "1678389317.722429",
        "client_msg_id": "0561058c-d548-4315-b17f-b55bbe6ae5c0",
        "text": "This property:\n\n&gt;  You can ask for an amalgamation of any set of arbitrary things, and _something_ will come back, which can be iterated on more.\n&gt; \n... does not imply what you think it does, IMO. It's arguably the biggest weakness of the current generation of LLMs.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gaee3c99144d",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/aee3c99144dfc6644c6c1f1303683140.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "Andrew F",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "andrewflnr",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1677925287.583739",
        "parent_user_id": "UDQBTJ211",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "r8Y",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This property:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": " You can ask for an amalgamation of any set of arbitrary things, and "
                            },
                            {
                                "type": "text",
                                "text": "something",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " will come back, which can be iterated on more.\n"
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n... does not imply what you think it does, IMO. It's arguably the biggest weakness of the current generation of LLMs."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03E4LY27FS",
        "type": "message",
        "ts": "1678389925.452699",
        "edited": {
            "user": "U03E4LY27FS",
            "ts": "1678389951.000000"
        },
        "client_msg_id": "69ED2DFB-A875-418E-B269-9A2812EE6237",
        "text": "Well, let me be a bit more descriptive to see if we’re on the same page.\n\nWhen I talk to you, your brain is interpreting all the words I’m writing, filtering them through your personal perception, and then you respond. Sometimes directly with more written language, sometimes through another medium - body language, another form of media, etc.\n\nEven though I can ask an LLM for code that renders a purple elephant with a funny hat, it doesn’t mean I’m going to get it. But, whatever comes back as a result (unless it’s a complete failure to recognize a sentence at all), is a close interpretation of the desire. Just by the sake of the words in that particular order produces a set of related vectors. After that though, it’s up to the person to do something with it.\n\nSo, it’s certainly not an Oracle, but it’s a great listener and is quite patient. And pragmatic, too.\n\nFor us, we can do stuff like code completion, fuzzy searching that may or may not be accurate (oops ;)), even writing whole articles about a topic. I gave the prompt box to a family member, and they immediately started using it like a search engine to understand the meaning and context of things (ham radio stuff in this case - very simple definition type of stuff). That same algorithm can take my, “here’s a code snippet, please make it draw a snippet” and then do something with it.\n\nI kinda consider that a universal coupler. And you’re right, though, insofar as all of this only works because everything is translated to a word weight and relationship edges. It’s up to the strength of the algorithms that define the relationships to deliver meaningful responses. Which kinda goes back to how people prompt it, and whether or not their style of speech approximates the global averages constructed by the model.\n\nThis is all top of my head here because I’m really in lust with this stuff, and I’m procrastinating diving into the implementations. These are my surface thoughts that likely are curtailed with more understanding, but I’ll tell ya.. even as a n00b, you can make these things say and so some crazy stuff.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "98f0011b77c6",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-04-28\/3450316621254_98f0011b77c61bbc241b_72.jpg",
            "first_name": "Ivan",
            "real_name": "Ivan Lugo",
            "display_name": "Ivan Lugo",
            "team": "T5TCAFTA9",
            "name": "iheartlappy486",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1677925287.583739",
        "parent_user_id": "UDQBTJ211",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "f1GZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Well, let me be a bit more descriptive to see if we’re on the same page.\n\nWhen I talk to you, your brain is interpreting all the words I’m writing, filtering them through your personal perception, and then you respond. Sometimes directly with more written language, sometimes through another medium - body language, another form of media, etc.\n\nEven though I can ask an LLM for code that renders a purple elephant with a funny hat, it doesn’t mean I’m going to get it. But, whatever comes back as a result (unless it’s a complete failure to recognize a sentence at all), is a close interpretation of the desire. Just by the sake of the words in that particular order produces a set of related vectors. After that though, it’s up to the person to do something with it.\n\nSo, it’s certainly not an Oracle, but it’s a great listener and is quite patient. And pragmatic, too.\n\nFor us, we can do stuff like code completion, fuzzy searching that may or may not be accurate (oops ;)), even writing whole articles about a topic. I gave the prompt box to a family member, and they immediately started using it like a search engine to understand the meaning and context of things (ham radio stuff in this case - very simple definition type of stuff). That same algorithm can take my, “here’s a code snippet, please make it draw a snippet” and then do something with it.\n\nI kinda consider that a universal coupler. And you’re right, though, insofar as all of this only works because everything is translated to a word weight and relationship edges. It’s up to the strength of the algorithms that define the relationships to deliver meaningful responses. Which kinda goes back to how people prompt it, and whether or not their style of speech approximates the global averages constructed by the model.\n\nThis is all top of my head here because I’m really in lust with this stuff, and I’m procrastinating diving into the implementations. These are my surface thoughts that likely are curtailed with more understanding, but I’ll tell ya.. even as a n00b, you can make these things say and so some crazy stuff."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U02NU8FTL5N",
        "type": "message",
        "ts": "1678395225.898019",
        "client_msg_id": "746721cd-3747-47d9-b824-6d149b8fc02f",
        "text": "<@UAV037WKC> I'm planning to add something like that to Flyde (<https:\/\/www.flyde.dev>) soon\nI believe the mix of visual flow-based programming, with the ability of creating new nodes from textual prompts can a perfect fit!\nLet's chat if you find this interesting :slightly_smiling_face:",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "99e8e5773319",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-11-21\/2737933101591_99e8e5773319ebc4666a_72.jpg",
            "first_name": "Gabriel",
            "real_name": "Gabriel Grinberg",
            "display_name": "Gabriel Grinberg",
            "team": "T5TCAFTA9",
            "name": "gabi.grinberg",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1677925287.583739",
        "parent_user_id": "UDQBTJ211",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "5xKx2",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UAV037WKC"
                            },
                            {
                                "type": "text",
                                "text": " I'm planning to add something like that to Flyde ("
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/www.flyde.dev"
                            },
                            {
                                "type": "text",
                                "text": ") soon\nI believe the mix of visual flow-based programming, with the ability of creating new nodes from textual prompts can a perfect fit!\nLet's chat if you find this interesting "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UAV037WKC"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U04GFG356MV",
        "type": "message",
        "ts": "1678397795.068949",
        "client_msg_id": "2e184c0d-8468-4a63-8f4b-0075de62407b",
        "text": "Data Particles looks :fire: . Really interested in language-oriented authoring tools.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "4794fc315d8e",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-27\/4878514783233_4794fc315d8e2985738a_72.png",
            "first_name": "Mike",
            "real_name": "Mike",
            "display_name": "miike",
            "team": "T5TCAFTA9",
            "name": "mike",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1678321880.602369",
        "parent_user_id": "UHWC9PXBL",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "g=MZV",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Data Particles looks "
                            },
                            {
                                "type": "emoji",
                                "name": "fire",
                                "unicode": "1f525"
                            },
                            {
                                "type": "text",
                                "text": " . Really interested in language-oriented authoring tools."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016VUZGUUQ",
        "type": "message",
        "ts": "1678402600.972029",
        "client_msg_id": "fa9310f2-d17c-4705-88ab-265af3322ee3",
        "text": "The difference I'm getting at is that when given a question, I as a human can say \"I don't know\" or \"that sounds like nonsense to me\" if the connection between the things you're trying to \"couple\" is too tenuous. There are many cases where that's the only appropriate answer. An LLM is more or less incapable of giving it. And while you can say that people need to look critically at the output, this will absolutely not happen at scale, given an AI that works well enough most of the time to lull people into complacency. The problem will get really wicked if LLMs make another couple jumps in ability without solving this basic problem; the BS that sneaks through will be subtler, take longer to detect in practice, and (partly for that reason) bite harder when it does.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gaee3c99144d",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/aee3c99144dfc6644c6c1f1303683140.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "Andrew F",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "andrewflnr",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1677925287.583739",
        "parent_user_id": "UDQBTJ211",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "sjc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The difference I'm getting at is that when given a question, I as a human can say \"I don't know\" or \"that sounds like nonsense to me\" if the connection between the things you're trying to \"couple\" is too tenuous. There are many cases where that's the only appropriate answer. An LLM is more or less incapable of giving it. And while you can say that people need to look critically at the output, this will absolutely not happen at scale, given an AI that works well enough most of the time to lull people into complacency. The problem will get really wicked if LLMs make another couple jumps in ability without solving this basic problem; the BS that sneaks through will be subtler, take longer to detect in practice, and (partly for that reason) bite harder when it does."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "U02NU8FTL5N"
                ],
                "count": 1
            },
            {
                "name": "amiga-tick",
                "users": [
                    "U02NU8FTL5N",
                    "UAV037WKC"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "UAV037WKC",
        "type": "message",
        "ts": "1678404020.541969",
        "edited": {
            "user": "UAV037WKC",
            "ts": "1678404060.000000"
        },
        "client_msg_id": "831C0B51-C3D4-463B-81D0-F8E23964FC12",
        "text": "Yes, <@U02NU8FTL5N> would be interested to chat ",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf88a0173379",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/4f88a017337947bdc4ac0cc05e025d83.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png",
            "first_name": "",
            "real_name": "Dawa Sherpa",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "dawalama",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1677925287.583739",
        "parent_user_id": "UDQBTJ211",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "oPz",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yes, "
                            },
                            {
                                "type": "user",
                                "user_id": "U02NU8FTL5N"
                            },
                            {
                                "type": "text",
                                "text": " would be interested to chat "
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "raised_hands",
                "users": [
                    "U02NU8FTL5N"
                ],
                "count": 1
            }
        ]
    }
]