[
    {
        "user": "UEQ7QL15F",
        "type": "message",
        "ts": "1696845341.002639",
        "edited": {
            "user": "UEQ7QL15F",
            "ts": "1696848497.000000"
        },
        "client_msg_id": "b413ebb6-74b8-420f-bb80-67aa6ff9343e",
        "text": "Has anyone thought about or written about malleable software + LLM:s? I feel that it is an area that could be quite interesting, but I haven't got yet a clear understanding on what this will lead to.\n\nI think that pretty soon most of end-user code will be generated with the help of LLM:s. Some thoughts\/questions I've been thinking about:\n1. How to generate programming languages, libraries and abstractions that LLM:s can use well? Is that different from generating libraries etc for humans?\n    a. LLM:s are faster than humans in processing data, so API:s can be really wide and probably more complex than what would be practical for devs. \n    b. LLM:s can probably handle more condensed\/optimized representation better, too. \n    c. And be able to infer system affordances directly from code.\n2. How to support creating good and maintainable code from LLM:s? And will that matter? Or will actual code become irrelevant?\n3. How to modularize apps so that they can be easily composed by LLM:s?\n    a. My hunch: making apps modular and composable would work really well with LLM:s already now and even better in the future. Doesn't matter if functional or OOP, as long as the LLM can understand the logic.\n4. What kinds of new apps and malleable software will LLM:s enable?\n5. Also: LLM:s could finally enable removing some boundaries between different programming tools, library ecosystems, etc, by enabling translations\/bridges automatically.\nAny thoughts?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g52d221ae708",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/a52d221ae708f36674644a348005633a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png",
            "first_name": "Janne",
            "real_name": "Janne Aukia",
            "display_name": "jaukia",
            "team": "T5TCAFTA9",
            "name": "janne.aukia",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "reply_count": 17,
        "reply_users_count": 7,
        "latest_reply": "1699314470.904839",
        "reply_users": [
            "UAZT04VT4",
            "UJBAJNFLK",
            "UEQ7QL15F",
            "UNS7QDKFV",
            "UCUSW7WVD",
            "UFEQUBNNT",
            "U04JY2BF24E"
        ],
        "replies": [
            {
                "user": "UAZT04VT4",
                "ts": "1696856872.883759"
            },
            {
                "user": "UJBAJNFLK",
                "ts": "1696865948.141189"
            },
            {
                "user": "UEQ7QL15F",
                "ts": "1696866838.238209"
            },
            {
                "user": "UEQ7QL15F",
                "ts": "1696867174.255229"
            },
            {
                "user": "UNS7QDKFV",
                "ts": "1696871268.775599"
            },
            {
                "user": "UEQ7QL15F",
                "ts": "1696872816.032239"
            },
            {
                "user": "UCUSW7WVD",
                "ts": "1696872877.922299"
            },
            {
                "user": "UEQ7QL15F",
                "ts": "1696873043.779909"
            },
            {
                "user": "UFEQUBNNT",
                "ts": "1696873468.339889"
            },
            {
                "user": "U04JY2BF24E",
                "ts": "1696883025.497729"
            },
            {
                "user": "UEQ7QL15F",
                "ts": "1696884151.992949"
            },
            {
                "user": "UJBAJNFLK",
                "ts": "1696929453.580749"
            },
            {
                "user": "UEQ7QL15F",
                "ts": "1696933279.121379"
            },
            {
                "user": "U04JY2BF24E",
                "ts": "1696937107.877229"
            },
            {
                "user": "UJBAJNFLK",
                "ts": "1696937952.202249"
            },
            {
                "user": "UFEQUBNNT",
                "ts": "1696949882.249399"
            },
            {
                "user": "U04JY2BF24E",
                "ts": "1699314470.904839"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "FTlY+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Has anyone thought about or written about malleable software + LLM:s? I feel that it is an area that could be quite interesting, but I haven't got yet a clear understanding on what this will lead to.\n\nI think that pretty soon most of end-user code will be generated with the help of LLM:s. Some thoughts\/questions I've been thinking about:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "How to generate programming languages, libraries and abstractions that LLM:s can use well? Is that different from generating libraries etc for humans?"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "LLM:s are faster than humans in processing data, so API:s can be really wide and probably more complex than what would be practical for devs. "
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "LLM:s can probably handle more condensed\/optimized representation better, too. "
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "And be able to infer system affordances directly from code."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "How to support creating good and maintainable code from LLM:s? And will that matter? Or will actual code become irrelevant?"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "How to modularize apps so that they can be easily composed by LLM:s?"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "offset": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "My hunch: making apps modular and composable would work really well with LLM:s already now and even better in the future. Doesn't matter if functional or OOP, as long as the LLM can understand the logic."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "What kinds of new apps and malleable software will LLM:s enable?"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Also: LLM:s could finally enable removing some boundaries between different programming tools, library ecosystems, etc, by enabling translations\/bridges automatically."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "offset": 3,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nAny thoughts?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UAZT04VT4",
        "type": "message",
        "ts": "1696856872.883759",
        "client_msg_id": "fb0e9c02-0061-4bea-b198-1405d41149d8",
        "text": "<https:\/\/www.geoffreylitt.com\/2023\/03\/25\/llm-end-user-programming>",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "f3d63cdd3157",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-12-16\/2861597891505_f3d63cdd315711ff17a4_72.jpg",
            "first_name": "Paul",
            "real_name": "Paul Sonnentag",
            "display_name": "Paul Sonnentag",
            "team": "T5TCAFTA9",
            "name": "paul.sonnentag",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "attachments": [
            {
                "from_url": "https:\/\/www.geoffreylitt.com\/2023\/03\/25\/llm-end-user-programming",
                "id": 1,
                "original_url": "https:\/\/www.geoffreylitt.com\/2023\/03\/25\/llm-end-user-programming",
                "fallback": "Malleable software in the age of LLMs",
                "text": "All computer users may soon have the ability to author small bits of code. What structural changes does this imply for the production and distribution of software?",
                "title": "Malleable software in the age of LLMs",
                "title_link": "https:\/\/www.geoffreylitt.com\/2023\/03\/25\/llm-end-user-programming",
                "service_name": "geoffreylitt.com"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2AuoQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https:\/\/www.geoffreylitt.com\/2023\/03\/25\/llm-end-user-programming"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT",
                    "UCUSW7WVD"
                ],
                "count": 2
            },
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            },
            {
                "name": "the_horns::skin-tone-3",
                "users": [
                    "UFEQUBNNT"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1696865948.141189",
        "client_msg_id": "af18c8db-c3bb-489c-9504-9753e2cdd0c0",
        "text": "One big question I see is: will anyone actually make an LLM that will do this job well? Are there economic incentives?\n\nToday's LLMs are not up to the task. Whatever they produce, code or prose, needs to be checked by a human if precision matters (which is almost always does in code).\n\nAlso, today's LLMs are not up to the taks of maintaining anything, because they themselves evolve too quickly. It's very much \"move quickly and break things\". If you write end-user code in a natural language and count on an LLM to turn it into precise instructions, at the very least you want those precise instructions to be reproducible over time.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zyMTP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "One big question I see is: will anyone actually make an LLM that will do this job well? Are there economic incentives?\n\nToday's LLMs are not up to the task. Whatever they produce, code or prose, needs to be checked by a human if precision matters (which is almost always does in code).\n\nAlso, today's LLMs are not up to the taks of maintaining anything, because they themselves evolve too quickly. It's very much \"move quickly and break things\". If you write end-user code in a natural language and count on an LLM to turn it into precise instructions, at the very least you want those precise instructions to be reproducible over time."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UEQ7QL15F",
        "type": "message",
        "ts": "1696866838.238209",
        "client_msg_id": "471fa00e-b5ab-4dcc-8616-5c2f69dce962",
        "text": "Thanks <@UAZT04VT4>, this is pretty much exactly the kind of thing I was looking for and thinking about!",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g52d221ae708",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/a52d221ae708f36674644a348005633a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png",
            "first_name": "Janne",
            "real_name": "Janne Aukia",
            "display_name": "jaukia",
            "team": "T5TCAFTA9",
            "name": "janne.aukia",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "OOKrF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "UAZT04VT4"
                            },
                            {
                                "type": "text",
                                "text": ", this is pretty much exactly the kind of thing I was looking for and thinking about!"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEQ7QL15F",
        "type": "message",
        "ts": "1696867174.255229",
        "edited": {
            "user": "UEQ7QL15F",
            "ts": "1696867765.000000"
        },
        "client_msg_id": "bd453298-5194-4467-841f-1c4dd019b1f5",
        "text": "<@UJBAJNFLK>, good points! My hunch is that LLM:s will still improve a lot. Also model versioning, open-source models and fine-tuning will help at overcoming some of the other current bottle-necks. But we'll see. :man-shrugging:",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g52d221ae708",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/a52d221ae708f36674644a348005633a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png",
            "first_name": "Janne",
            "real_name": "Janne Aukia",
            "display_name": "jaukia",
            "team": "T5TCAFTA9",
            "name": "janne.aukia",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MhPmN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UJBAJNFLK"
                            },
                            {
                                "type": "text",
                                "text": ", good points! My hunch is that LLM:s will still improve a lot. Also model versioning, open-source models and fine-tuning will help at overcoming some of the other current bottle-necks. But we'll see. "
                            },
                            {
                                "type": "emoji",
                                "name": "man-shrugging",
                                "unicode": "1f937-200d-2642-fe0f"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UNS7QDKFV",
        "type": "message",
        "ts": "1696871268.775599",
        "client_msg_id": "4f77b61a-26af-4552-bbf3-0cc39851db69",
        "text": "LLMs are good a producing a first draft, since they do require a lot of human oversight of the output.  I'm partial to modifying programs by describing the transformation of the code.  LLMs might be useful for writing the first draft of those transformations.  That helps with the reproducibility issue because the LLM is describing the changes to the code in more structured way, not the code itself.  Unfortunately, as far as I know, there is no widely recognized syntax or system for describing program transformations.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gbc993d98fe7",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/bc993d98fe7bf26c048ac0818a598d4d.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "Mark Dewing",
            "display_name": "Mark Dewing",
            "team": "T5TCAFTA9",
            "name": "markdewing",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "oqjKN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "LLMs are good a producing a first draft, since they do require a lot of human oversight of the output.  I'm partial to modifying programs by describing the transformation of the code.  LLMs might be useful for writing the first draft of those transformations.  That helps with the reproducibility issue because the LLM is describing the changes to the code in more structured way, not the code itself.  Unfortunately, as far as I know, there is no widely recognized syntax or system for describing program transformations."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UCUSW7WVD",
        "type": "message",
        "ts": "1696872118.554279",
        "edited": {
            "user": "UCUSW7WVD",
            "ts": "1696872291.000000"
        },
        "client_msg_id": "7ef81d15-a84d-487c-bdc0-c3c0175c7d4a",
        "text": "<@UJBAJNFLK> Funny you should mention it, the Preamble to the US constitution was on my mind when I wrote my draft. I'd love to see a new batch of Federalist papers for the current epoch :smile: Because the questions you raise seem to me to quickly end up in the weeds of thorny philosophical questions I've never seen satisfactorily answered, and it would be good to have someone distill the current philosophical thinking for the rest of us. With my limited knowledge so far, it seems to me that we have no demonstrated way to avoid harm, or to compare arbitrary actions by their total harm caused. We cause harm everyday just by existing, and that's not going to change.\n\nSo you're absolutely right about the fork between the way that might not scale up and the way that nobody knows how to achieve and will cause evils in its name. I prefer the first fork. I prefer to respond to questions I don't know the answer to with avoidance rather than soaring rhetoric. I'd like the scope of my intervention to be small. The goal is not a perfect intervention but a \"more perfect\" intervention. That way I avoid unnecessarily perturbing the existing patterns of harms caused, so that people who study them have to spend less of their time playing catch-up. (They still have to play catch-up to some extent just by new wars declared and so on.) But I'd certainly love to learn from proposals that update the \"vague, global goals\" side of things.\n\n(I'm very influenced by the emergent properties of a local or bottom-up intervention like setting the price of an object, and how they help societies plan. I think indirect bottom-up interventions have a better track record than attempting to attack thorny problems head on in a top-down way. Top-down still has a role to play. I imagine society as a system of bottom-up rules. As they emergently cause problems, we apply band-aids of top-down regulation using laws. One dream I have is to see the bottom-up rules get gradually replaced with better ones, obviating some number of top-down regulations.)\n\nThe one thing I'd encourage in a thread like this one is more of a \"yes, and\" mindset from improv (<https:\/\/en.wikipedia.org\/wiki\/Yes,_and><https:\/\/en.wikipedia.org\/wiki\/Yes,_and...|...>) It seems to me you're both accusing me of being small-scale on one hand and lecturing me against the dangers of scaling up on the other :smile: I'm very cognizant of both dangers. I'm nowhere near the point of trying to tell anyone else what to do. This thread is very much in the brainstorming stage of things. Long lists of what it doesn't do don't seem very actionable. Tell us surprising new applications for what you see, or suggest changes\/alternative formulations that would improve things. If you think it would benefit from a dose of soaring rhetoric in favor of harm reduction, suggest it and show me an example of a situation where it can't be rationalized away.\n\nOr try to do what I do, and try to apply this pledge in a background thread as you go about your life. Do you run into situations where the pledge obviously leads in the wrong direction? Or places where the pledge made you uncomfortable about your choices, but seems to lead in the ethical direction? I'd love to hear anecdata like this.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6e649a383cf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_72.png",
            "first_name": "Kartik",
            "real_name": "Kartik Agaram",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ak",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696628791.117649",
        "parent_user_id": "UCUSW7WVD",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xQ2Qx",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UJBAJNFLK"
                            },
                            {
                                "type": "text",
                                "text": " Funny you should mention it, the Preamble to the US constitution was on my mind when I wrote my draft. I'd love to see a new batch of Federalist papers for the current epoch "
                            },
                            {
                                "type": "emoji",
                                "name": "smile",
                                "unicode": "1f604"
                            },
                            {
                                "type": "text",
                                "text": " Because the questions you raise seem to me to quickly end up in the weeds of thorny philosophical questions I've never seen satisfactorily answered, and it would be good to have someone distill the current philosophical thinking for the rest of us. With my limited knowledge so far, it seems to me that we have no demonstrated way to avoid harm, or to compare arbitrary actions by their total harm caused. We cause harm everyday just by existing, and that's not going to change.\n\nSo you're absolutely right about the fork between the way that might not scale up and the way that nobody knows how to achieve and will cause evils in its name. I prefer the first fork. I prefer to respond to questions I don't know the answer to with avoidance rather than soaring rhetoric. I'd like the scope of my intervention to be small. The goal is not a perfect intervention but a \"more perfect\" intervention. That way I avoid unnecessarily perturbing the existing patterns of harms caused, so that people who study them have to spend less of their time playing catch-up. (They still have to play catch-up to some extent just by new wars declared and so on.) But I'd certainly love to learn from proposals that update the \"vague, global goals\" side of things.\n\n(I'm very influenced by the emergent properties of a local or bottom-up intervention like setting the price of an object, and how they help societies plan. I think indirect bottom-up interventions have a better track record than attempting to attack thorny problems head on in a top-down way. Top-down still has a role to play. I imagine society as a system of bottom-up rules. As they emergently cause problems, we apply band-aids of top-down regulation using laws. One dream I have is to see the bottom-up rules get gradually replaced with better ones, obviating some number of top-down regulations.)\n\nThe one thing I'd encourage in a thread like this one is more of a \"yes, and\" mindset from improv ("
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/en.wikipedia.org\/wiki\/Yes,_and"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/en.wikipedia.org\/wiki\/Yes,_and...",
                                "text": "..."
                            },
                            {
                                "type": "text",
                                "text": ") It seems to me you're both accusing me of being small-scale on one hand and lecturing me against the dangers of scaling up on the other "
                            },
                            {
                                "type": "emoji",
                                "name": "smile",
                                "unicode": "1f604"
                            },
                            {
                                "type": "text",
                                "text": " I'm very cognizant of both dangers. I'm nowhere near the point of trying to tell anyone else what to do. This thread is very much in the brainstorming stage of things. Long lists of what it doesn't do don't seem very actionable. Tell us surprising new applications for what you see, or suggest changes\/alternative formulations that would improve things. If you think it would benefit from a dose of soaring rhetoric in favor of harm reduction, suggest it and show me an example of a situation where it can't be rationalized away.\n\nOr try to do what I do, and try to apply this pledge in a background thread as you go about your life. Do you run into situations where the pledge obviously leads in the wrong direction? Or places where the pledge made you uncomfortable about your choices, but seems to lead in the ethical direction? I'd love to hear anecdata like this."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U023V63MF6V",
                    "UJBAJNFLK",
                    "U05SU27S1M2"
                ],
                "count": 3
            }
        ]
    },
    {
        "user": "UEQ7QL15F",
        "type": "message",
        "ts": "1696872816.032239",
        "client_msg_id": "a799facb-ecc0-458c-95a8-f7a1406a3641",
        "text": "Right. Instead or in addition to editing raw low-level imperative code, I think LLM:s could be useful in altering module-level code\/structure, such as which objects\/panels are visible where, how they are interconnected, etc. And then create minimal required glue to bind them together. I think this kind of use-case could be interesting to explore and perhaps even more interesting than just creating for loops, if-statements, etc.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g52d221ae708",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/a52d221ae708f36674644a348005633a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png",
            "first_name": "Janne",
            "real_name": "Janne Aukia",
            "display_name": "jaukia",
            "team": "T5TCAFTA9",
            "name": "janne.aukia",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "e5RRZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Right. Instead or in addition to editing raw low-level imperative code, I think LLM:s could be useful in altering module-level code\/structure, such as which objects\/panels are visible where, how they are interconnected, etc. And then create minimal required glue to bind them together. I think this kind of use-case could be interesting to explore and perhaps even more interesting than just creating for loops, if-statements, etc."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UCUSW7WVD",
        "type": "message",
        "ts": "1696872877.922299",
        "client_msg_id": "5a6d7180-c0f1-4dff-b1de-0d2c9b830b9a",
        "text": "At least in my filter bubble, I'm seeing a lot of ferment in the area of local-only models. I think they go a long way towards addressing concerns of incentives as well as LLM evolution.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6e649a383cf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_72.png",
            "first_name": "Kartik",
            "real_name": "Kartik Agaram",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ak",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ccKgc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "At least in my filter bubble, I'm seeing a lot of ferment in the area of local-only models. I think they go a long way towards addressing concerns of incentives as well as LLM evolution."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UEQ7QL15F",
        "type": "message",
        "ts": "1696873043.779909",
        "client_msg_id": "02e3442b-bcc2-4884-bb88-c3ed99a65b91",
        "text": "Interesting idea of having LLM:s describe transformations of code <@UNS7QDKFV>, btw. Using an LLM to create a transpiler from one language to another would be something like this. Perhaps also LLM creating glue code between API layers. Or are you thinking of something different. :thinking_face:",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g52d221ae708",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/a52d221ae708f36674644a348005633a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png",
            "first_name": "Janne",
            "real_name": "Janne Aukia",
            "display_name": "jaukia",
            "team": "T5TCAFTA9",
            "name": "janne.aukia",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WYZQF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Interesting idea of having LLM:s describe transformations of code "
                            },
                            {
                                "type": "user",
                                "user_id": "UNS7QDKFV"
                            },
                            {
                                "type": "text",
                                "text": ", btw. Using an LLM to create a transpiler from one language to another would be something like this. Perhaps also LLM creating glue code between API layers. Or are you thinking of something different. "
                            },
                            {
                                "type": "emoji",
                                "name": "thinking_face",
                                "unicode": "1f914"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UFEQUBNNT",
        "type": "message",
        "ts": "1696873468.339889",
        "client_msg_id": "6D3E3FDF-7CD6-4F30-A33E-553DFC6B44EA",
        "text": "OpenAI had a first-class “edit” API where you’d send it (for example) code and a description of a change, and it would return the modified version. They deprecated it this summer because it was just as reliable to use the chat API. Even without a transformation language, I find it easy to work with because I can examine the diff just like if another human made the change.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "565c54a4fa91",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-09-13\/2508698086192_565c54a4fa91a0c8c75a_72.png",
            "first_name": "Tom",
            "real_name": "Tom Lieber",
            "display_name": "alltom",
            "team": "T5TCAFTA9",
            "name": "tom",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Fyi6S",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "OpenAI had a first-class “edit” API where you’d send it (for example) code and a description of a change, and it would return the modified version"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": " They deprecated it this summer because it was just as reliable to use the chat API. Even without a transformation language, I find it easy to work with because I can examine the diff just like if another human made the change."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            },
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F",
                    "UNS7QDKFV"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "UCUSW7WVD",
        "type": "message",
        "ts": "1696878937.437939",
        "client_msg_id": "c9679c38-3936-4cf1-bb42-5d7afc871e54",
        "text": "Oh, <@UMQ6LR9NZ> I meant to respond to you to say, I'd love to see your direct statement or acknowledgement of how a programmer should relate to power, and when they should support\/complicate\/concentrate power.\n\nThat is sort of the hope in starting this thread. The internet's strength is if you want a question answered, a wrong answer can trigger lots of better answers. No pressure or hurry, but I look forward to seeing what others come up with over weeks and months.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "6e649a383cf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-07-14\/687915485201_6e649a383cf8f9e366e3_72.png",
            "first_name": "Kartik",
            "real_name": "Kartik Agaram",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "ak",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696628791.117649",
        "parent_user_id": "UCUSW7WVD",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "rgOb2",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Oh, "
                            },
                            {
                                "type": "user",
                                "user_id": "UMQ6LR9NZ"
                            },
                            {
                                "type": "text",
                                "text": " I meant to respond to you to say, I'd love to see your direct statement or acknowledgement of how a programmer should relate to power, and when they should support\/complicate\/concentrate power.\n\nThat is sort of the hope in starting this thread. The internet's strength is if you want a question answered, a wrong answer can trigger lots of better answers. No pressure or hurry, but I look forward to seeing what others come up with over weeks and months."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05SU27S1M2",
        "type": "message",
        "ts": "1696881286.971039",
        "edited": {
            "user": "U05SU27S1M2",
            "ts": "1696881383.000000"
        },
        "client_msg_id": "27e2702a-3b8b-45a4-905b-1c960955e20e",
        "text": "<@UJBAJNFLK> Why can't local things scale up? If you do something small and local, and document and share it in a way that it affords copying, then if it's good, it should spread with little effort from yourself. This has worked well for the tech-oriented cultural movements I've been involved with.. making it possible for others to copy what you're doing and take it further as a model of 'growth'.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "60e6ebbc4a9a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-09-18\/5922641047217_60e6ebbc4a9a68a57656_72.png",
            "first_name": "Alex",
            "real_name": "Alex McLean",
            "display_name": "Alex McLean",
            "team": "T5TCAFTA9",
            "name": "alex952",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696628791.117649",
        "parent_user_id": "UCUSW7WVD",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7Nz9\/",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UJBAJNFLK"
                            },
                            {
                                "type": "text",
                                "text": " Why can't local things scale up? If you do something small and local, and document and share it in a way that it affords copying, then if it's good, it should spread with little effort from yourself. This has worked well for the tech-oriented cultural movements I've been involved with.. making it possible for others to copy what you're doing and take it further as a model of 'growth'."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05SU27S1M2",
        "type": "message",
        "ts": "1696882769.295459",
        "client_msg_id": "711cb838-8df8-49d0-9782-774b07ade516",
        "text": "<@UCUSW7WVD>'s draft programmer's pledge reminded me of Ursula Franklin's checklist for technology projects, which is a bit hidden in one of her really excellent 1986 lectures on the \"real world of technology\"\n&gt; “… whether it:\n&gt;  (1) promotes justice;\n&gt;  (2) restores reciprocity;\n&gt;  (3) confers divisible or indivisible benefits;\n&gt;  (4) favours people over machines;\n&gt;  (5) whether its strategy maximizes gain or minimizes disaster;\n&gt;  (6) whether conservation is favoured over waste; and\n&gt;  (7), whether the reversible is favoured over the irreversible?”\nI tried to <https:\/\/slab.org\/2022\/02\/11\/ursula-franklins-tech-project-checklist\/|summarise these points in a blog post here> or you can <https:\/\/archive.org\/details\/the-real-world-of-technology|listen to the lectures> directly, or <https:\/\/archive.org\/details\/realworldoftechn0000fran_u9w8\/page\/n9\/mode\/2up|read it in book form>.\n\nI'll pull out a couple of quotes, first on 3) divisible\/indivisible benefits:\n&gt; “If you have a garden and your friends help you to grow a tremendous tomato crop, you can share it out among those who helped. What you have obtained is a divisible benefit and the right to distribute it. Whoever didn’t help you, may not get anything. On the other hand, if you work hard to fight pollution and you and your friends succeed in changing the practices of the battery-recycling plant down the street, those who helped you get the benefits, but those who didn’t get them too. What you and your friends have obtained are indivisible benefits.”\nand on 7) reversible vs irreversible:\n&gt; “The last item is obviously important. Considering that most projects do not work out as planned, it would be helpful if they proceeded in a way that allowed revision and learning, that is, in small reversible steps.”\n5) on maximising gain vs minimising disaster is also a really interesting point, where she argues against planning, and for finding the right conditions for something to grow, at its own rate.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "60e6ebbc4a9a",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-09-18\/5922641047217_60e6ebbc4a9a68a57656_72.png",
            "first_name": "Alex",
            "real_name": "Alex McLean",
            "display_name": "Alex McLean",
            "team": "T5TCAFTA9",
            "name": "alex952",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696882769.295459",
        "reply_count": 3,
        "reply_users_count": 3,
        "latest_reply": "1696952282.069179",
        "reply_users": [
            "UCUSW7WVD",
            "U05SU27S1M2",
            "U05597GCDDK"
        ],
        "replies": [
            {
                "user": "UCUSW7WVD",
                "ts": "1696950280.588299"
            },
            {
                "user": "U05SU27S1M2",
                "ts": "1696950590.284029"
            },
            {
                "user": "U05597GCDDK",
                "ts": "1696952282.069179"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+y4JL",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UCUSW7WVD"
                            },
                            {
                                "type": "text",
                                "text": "'s draft programmer's pledge reminded me of Ursula Franklin's checklist for technology projects, which is a bit hidden in one of her really excellent 1986 lectures on the \"real world of technology\"\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "“… whether it:\n (1) promotes justice;\n (2) restores reciprocity;\n (3) confers divisible or indivisible benefits;\n (4) favours people over machines;\n (5) whether its strategy maximizes gain or minimizes disaster;\n (6) whether conservation is favoured over waste; and\n (7), whether the reversible is favoured over the irreversible?”"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nI tried to "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/slab.org\/2022\/02\/11\/ursula-franklins-tech-project-checklist\/",
                                "text": "summarise these points in a blog post here"
                            },
                            {
                                "type": "text",
                                "text": " or you can "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/archive.org\/details\/the-real-world-of-technology",
                                "text": "listen to the lectures"
                            },
                            {
                                "type": "text",
                                "text": " directly, or "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/archive.org\/details\/realworldoftechn0000fran_u9w8\/page\/n9\/mode\/2up",
                                "text": "read it in book form"
                            },
                            {
                                "type": "text",
                                "text": ".\n\nI'll pull out a couple of quotes, first on 3) divisible\/indivisible benefits:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "“If you have a garden and your friends help you to grow a tremendous tomato crop, you can share it out among those who helped. What you have obtained is a divisible benefit and the right to distribute it. Whoever didn’t help you, may not get anything. On the other hand, if you work hard to fight pollution and you and your friends succeed in changing the practices of the battery-recycling plant down the street, those who helped you get the benefits, but those who didn’t get them too. What you and your friends have obtained are indivisible benefits.”"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nand on 7) reversible vs irreversible:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "“The last item is obviously important. Considering that most projects do not work out as planned, it would be helpful if they proceeded in a way that allowed revision and learning, that is, in small reversible steps.”"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n5) on maximising gain vs minimising disaster is also a really interesting point, where she argues against planning, and for finding the right conditions for something to grow, at its own rate."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UCUSW7WVD",
                    "U023V63MF6V",
                    "U05G29UQHKK",
                    "UML4ZEKDK",
                    "UJBAJNFLK",
                    "URKQXRCAC",
                    "U05UK5T7LPP"
                ],
                "count": 7
            },
            {
                "name": "boom",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            },
            {
                "name": "eyes",
                "users": [
                    "U023V63MF6V"
                ],
                "count": 1
            },
            {
                "name": "+1",
                "users": [
                    "UEQ7QL15F",
                    "U052S2NHZFU"
                ],
                "count": 2
            },
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT",
                    "U05597GCDDK"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "U04JY2BF24E",
        "type": "message",
        "ts": "1696883025.497729",
        "client_msg_id": "f76df641-3d1f-420f-bd44-6a71370a0dfe",
        "text": "You may enjoy this: nothing concrete yet but a vision for the future: \"LLM As Compiler\": <https:\/\/medium.com\/redsquirrel-tech\/llm-as-compiler-2a2f79d30f0b>",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "154a9d12968c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-06-13\/5441522160256_154a9d12968ca5a13cf5_72.jpg",
            "first_name": "Greg",
            "real_name": "Greg Bylenok",
            "display_name": "Greg Bylenok",
            "team": "T5TCAFTA9",
            "name": "gregory.bylenok",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "c9gOG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "You may enjoy this: nothing concrete yet but a vision for the future: \"LLM As Compiler\": "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/medium.com\/redsquirrel-tech\/llm-as-compiler-2a2f79d30f0b"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEQ7QL15F",
        "type": "message",
        "ts": "1696884151.992949",
        "client_msg_id": "1d78bab6-fe53-4442-a8e4-aec3dda29211",
        "text": "Interesting, thanks <@U04JY2BF24E>! So if I get this correctly, the idea is that users will do coding in high-level pseudo-language, compile it to the actual target language and then verify that it works as intended.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g52d221ae708",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/a52d221ae708f36674644a348005633a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png",
            "first_name": "Janne",
            "real_name": "Janne Aukia",
            "display_name": "jaukia",
            "team": "T5TCAFTA9",
            "name": "janne.aukia",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1696845341.002639",
        "parent_user_id": "UEQ7QL15F",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zcw7s",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Interesting, thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "U04JY2BF24E"
                            },
                            {
                                "type": "text",
                                "text": "! So if I get this correctly, the idea is that users will do coding in high-level pseudo-language, compile it to the actual target language and then verify that it works as intended."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]