<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #two-minute-week</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <a href="../two-minute-week/1742398334.625809.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Marek Rogalski</b>
<span style="margin:2em; color:#606060">2025-03-19 08:32</span><br/>
I'm getting feedback about the state of the game using basic OCR now. Unfortunately the OCR that I'm using is optimized towards "natural" text - so it doesn't handle game UIs too well.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1742400687.619789"></a>
      <img src="https://avatars.slack-edge.com/2021-09-13/2483463922595_27dffd0e73bd6f709927_72.gif" style="float:left"/>
      <a href="../two-minute-week/1742398334.625809.html#1742400687.619789" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Tom Larkworthy</b>
<span style="margin:2em; color:#606060">2025-03-19 09:11</span><br/>
the deep learning models are now state of the art for OCR imho. they can do natural scenes as well
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1742400831.410039"></a>
      <img src="https://avatars.slack-edge.com/2024-04-04/6922823105585_287ba5559ee1cedd6b98_72.png" style="float:left"/>
      <a href="../two-minute-week/1742398334.625809.html#1742400831.410039" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Marek Rogalski</b>
<span style="margin:2em; color:#606060">2025-03-19 09:13</span><br/>
I've spent some time digging through huggingface but the OCR models I've found tended to be 1GB+<br/><br/>The also have a ton of "image-to-text" models but unfortunately it's not the same as "OCR".<br/><br/>I kind of wish there was a "ocr.cpp" repo somewhere - just like "llama.cpp" or "whisper.cpp"...
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1742401087.519379"></a>
      <img src="https://avatars.slack-edge.com/2021-09-13/2483463922595_27dffd0e73bd6f709927_72.gif" style="float:left"/>
      <a href="../two-minute-week/1742398334.625809.html#1742401087.519379" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Tom Larkworthy</b>
<span style="margin:2em; color:#606060">2025-03-19 09:18</span><br/>
yeah I would be looking for multi-modal LLM, but definitely they are gonna be massive for local use so that would be a good reason to use classical OCR.<br/>That said, Skyrim 5.6 GB so gamers are quite tolerant of large downloads.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1742401204.388589"></a>
      <img src="https://avatars.slack-edge.com/2021-09-13/2483463922595_27dffd0e73bd6f709927_72.gif" style="float:left"/>
      <a href="../two-minute-week/1742398334.625809.html#1742401204.388589" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Tom Larkworthy</b>
<span style="margin:2em; color:#606060">2025-03-19 09:20</span><br/>
"Here's an example of how to run llama.cpp's built-in HTTP server. This example uses LLaVA v1.5-7B, a <b>multimodal</b> LLM that works with llama.cpp's recently-added support for image inputs." so its seems like multi modal is supported by llama.cpp now (says <a href="https://github.com/Mozilla-Ocho/llamafile">llamafile's</a> README)
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1742401376.956429"></a>
      <img src="https://avatars.slack-edge.com/2024-04-04/6922823105585_287ba5559ee1cedd6b98_72.png" style="float:left"/>
      <a href="../two-minute-week/1742398334.625809.html#1742401376.956429" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Marek Rogalski</b>
<span style="margin:2em; color:#606060">2025-03-19 09:22</span><br/>
Desktop capture + Multimodal LLMs + Fake input sounds like a match made in heaven
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1742401537.891599"></a>
      <img src="https://avatars.slack-edge.com/2021-09-13/2483463922595_27dffd0e73bd6f709927_72.gif" style="float:left"/>
      <a href="../two-minute-week/1742398334.625809.html#1742401537.891599" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Tom Larkworthy</b>
<span style="margin:2em; color:#606060">2025-03-19 09:25</span><br/>
I know one local doing something in this area  <a href="https://github.com/e2b-dev/desktop">https://github.com/e2b-dev/desktop</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1742401546.813869"></a>
      <img src="https://avatars.slack-edge.com/2024-04-04/6922823105585_287ba5559ee1cedd6b98_72.png" style="float:left"/>
      <a href="../two-minute-week/1742398334.625809.html#1742401546.813869" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Marek Rogalski</b>
<span style="margin:2em; color:#606060">2025-03-19 09:25</span><br/>
BTW Tesseract OCR that I'm using clearly hasn't been updated in quite a long time. It's docs praise the new LSTM-based engine. I wonder how a modern convnet hierarchy + attention architecture would work...
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1742401788.646259"></a>
      <img src="https://avatars.slack-edge.com/2021-09-13/2483463922595_27dffd0e73bd6f709927_72.gif" style="float:left"/>
      <a href="../two-minute-week/1742398334.625809.html#1742401788.646259" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Tom Larkworthy</b>
<span style="margin:2em; color:#606060">2025-03-19 09:29</span><br/>
At work we switched out document OCR from classical to LLM and got better results. docs are literally the ideal use case for classical OCR but still LLMs seem to outperform coz they "get" the task and the words. For your use case the OCR is not on docs so I imagine the delta is even better.
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
