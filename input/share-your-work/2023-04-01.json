[
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1680370755.360969",
        "client_msg_id": "7f01785c-b4e9-45b1-aabb-17a5564b52ea",
        "text": "Future of Coding â€¢ Episode 63\nBen Moseley &amp; Peter Marks â€¢ Out of the Tar Pit\nð’‚¶ <https:\/\/futureofcoding.org\/episodes\/063>\n\n<https:\/\/moss.cs.iit.edu\/cs100\/papers\/out-of-the-tar-pit.pdf|Out of the Tar Pit> is in the grand pantheon of great papers, beloved the world over, with just _so much influence_. The resurgence of Functional Programming over the past decade owes its very existence to the Tar Pitâ€™s snarling takedown of mutable state, championed by Hickey &amp; The Cloj-Co. Many a budding computational philosophizer â€” both of yours truly counted among them â€” have been led onward to the late great <https:\/\/futureofcoding.org\/episodes\/062|Bro86> by this paperâ€™s borrow of his _essence_ and _accident_. But is the paper _actually_ good? Like, really â€” is it _that_ good? Does it hold up to the blinding light of hindsight that 2023 offers? Is this episode actually an April Fools joke, or is it a serious episode that Ivan just delayed by a few weeks because of life circumstances and his own incoherent sense of humour? I canâ€™t tell.\n\nApologies in advance. Next time, weâ€™re going back to our usual format to discuss <https:\/\/en.wikipedia.org\/wiki\/INTERCAL|Intercal>.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "Ivan Reese",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1680370755.360969",
        "reply_count": 26,
        "reply_users_count": 8,
        "latest_reply": "1684527159.567249",
        "reply_users": [
            "U02U0AS3J49",
            "UC2A2ARPT",
            "U03R0B9U1GD",
            "U04MTMF6Y4W",
            "UA14TGLTC",
            "U03CEGR3HSL",
            "UK3LH8CF5",
            "U017TE5R09M"
        ],
        "replies": [
            {
                "user": "U02U0AS3J49",
                "ts": "1680387267.285919"
            },
            {
                "user": "U02U0AS3J49",
                "ts": "1680388464.340919"
            },
            {
                "user": "UC2A2ARPT",
                "ts": "1680402954.168419"
            },
            {
                "user": "U02U0AS3J49",
                "ts": "1680411839.411449"
            },
            {
                "user": "U03R0B9U1GD",
                "ts": "1680541272.439419"
            },
            {
                "user": "U02U0AS3J49",
                "ts": "1680541344.054009"
            },
            {
                "user": "U03R0B9U1GD",
                "ts": "1680541442.828519"
            },
            {
                "user": "UC2A2ARPT",
                "ts": "1680545134.812359"
            },
            {
                "user": "U03R0B9U1GD",
                "ts": "1680545179.866759"
            },
            {
                "user": "U04MTMF6Y4W",
                "ts": "1680597863.331019"
            },
            {
                "user": "UA14TGLTC",
                "ts": "1680598470.323629"
            },
            {
                "user": "U03CEGR3HSL",
                "ts": "1682712600.334319"
            },
            {
                "user": "UC2A2ARPT",
                "ts": "1682828183.924529"
            },
            {
                "user": "U03CEGR3HSL",
                "ts": "1682829524.999199"
            },
            {
                "user": "UK3LH8CF5",
                "ts": "1682866170.653509"
            },
            {
                "user": "U03CEGR3HSL",
                "ts": "1682870029.728789"
            },
            {
                "user": "UC2A2ARPT",
                "ts": "1682871400.660259"
            },
            {
                "user": "U017TE5R09M",
                "ts": "1684042987.877889"
            },
            {
                "user": "UK3LH8CF5",
                "ts": "1684072313.665109"
            },
            {
                "user": "U017TE5R09M",
                "ts": "1684132428.733029"
            },
            {
                "user": "U017TE5R09M",
                "ts": "1684490591.505269"
            },
            {
                "user": "UC2A2ARPT",
                "ts": "1684512931.782839"
            },
            {
                "user": "UC2A2ARPT",
                "ts": "1684513175.773629"
            },
            {
                "user": "UK3LH8CF5",
                "ts": "1684518238.478799"
            },
            {
                "user": "U03CEGR3HSL",
                "ts": "1684518543.826509"
            },
            {
                "user": "UC2A2ARPT",
                "ts": "1684527159.567249"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6Lo8p",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Future of Coding â€¢ Episode 63\nBen Moseley & Peter Marks â€¢ Out of the Tar Pit\nð’‚¶ "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/futureofcoding.org\/episodes\/063"
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/moss.cs.iit.edu\/cs100\/papers\/out-of-the-tar-pit.pdf",
                                "text": "Out of the Tar Pit"
                            },
                            {
                                "type": "text",
                                "text": " is in the grand pantheon of great papers, beloved the world over, with just "
                            },
                            {
                                "type": "text",
                                "text": "so much influence",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". The resurgence of Functional Programming over the past decade owes its very existence to the Tar Pitâ€™s snarling takedown of mutable state, championed by Hickey & The Cloj-Co. Many a budding computational philosophizer â€” both of yours truly counted among them â€” have been led onward to the late great "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/futureofcoding.org\/episodes\/062",
                                "text": "Bro86"
                            },
                            {
                                "type": "text",
                                "text": " by this paperâ€™s borrow of his "
                            },
                            {
                                "type": "text",
                                "text": "essence",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " and "
                            },
                            {
                                "type": "text",
                                "text": "accident",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". But is the paper "
                            },
                            {
                                "type": "text",
                                "text": "actually",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " good? Like, really â€” is it "
                            },
                            {
                                "type": "text",
                                "text": "that",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " good? Does it hold up to the blinding light of hindsight that 2023 offers? Is this episode actually an April Fools joke, or is it a serious episode that Ivan just delayed by a few weeks because of life circumstances and his own incoherent sense of humour? I canâ€™t tell.\n\nApologies in advance. Next time, weâ€™re going back to our usual format to discuss "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/en.wikipedia.org\/wiki\/INTERCAL",
                                "text": "Intercal"
                            },
                            {
                                "type": "text",
                                "text": "."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U03CEGR3HSL",
                    "UMQ6LR9NZ",
                    "U03R0B9U1GD",
                    "UA14TGLTC",
                    "U04MTMF6Y4W"
                ],
                "count": 5
            },
            {
                "name": "headphones",
                "users": [
                    "UMQ6LR9NZ",
                    "U02U0AS3J49",
                    "U0123H7JRDM"
                ],
                "count": 3
            },
            {
                "name": "cake",
                "users": [
                    "U03R0B9U1GD",
                    "UBN9AFS0N"
                ],
                "count": 2
            }
        ]
    },
    {
        "user": "U02U0AS3J49",
        "type": "message",
        "ts": "1680387267.285919",
        "client_msg_id": "65e38837-aad0-420f-8656-79b10e61a1e1",
        "text": "If you do programming by generating a LLM to do a task, you cannot use informal reasoning to understand the behaviour of your system. You can't even use formal reasoning. The run-state of the code is so far removed from what you wrote, you can't look at the source code and say \"oh, here's where I made it racist.\". That is a programming that informal reasoning doesn't work for. It requires that you are building systems that build systems, of course, and that it is the system two turtles down you are concerned with understanding. But still, I think it fits?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g5247a9c6cbb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/5247a9c6cbb943683c9e2e2cef6eba79.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-72.png",
            "first_name": "Jason",
            "real_name": "Jason Morris",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "jason",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1680370755.360969",
        "parent_user_id": "UC2A2ARPT",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "UqCj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If you do programming by generating a LLM to do a task, you cannot use informal reasoning to understand the behaviour of your system. You can't even use formal reasoning. The run-state of the code is so far removed from what you wrote, you can't look at the source code and say \"oh, here's where I made it racist.\". That is a programming that informal reasoning doesn't work for. It requires that you are building systems that build systems, of course, and that it is the system two turtles down you are concerned with understanding. But still, I think it fits?"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "amiga-tick",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U02U0AS3J49",
        "type": "message",
        "ts": "1680388464.340919",
        "client_msg_id": "313efc9e-1887-4f0c-aa6f-83023511b7db",
        "text": ":point_up::skin-tone-2:That is my answer the challenge #1. Now challenge #2. In Blawx, it would be trivial to take a test, and generalize the inputs of that test by making them abducible, and run the query again. The answer to that second query would be a set of models, with constraints on unground variables, in which the query holds. Essentially, a description of all inputs that would have made your test pass. But of course, there is no reason to have the extra step of starting with a grounded test. You can go straight to the most general query, and say \"give me all the inputs for which the following assertion holds.\" But technically, I think that's an example of #2. The system could answer \"that test passes, because it is an example of this model, anything in that model would work. Also, here are all the other models that work.\" It's also the reason I'm really excited about its potential as a tool for generating tests that can be used to validate the legal reasoning of other systems.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g5247a9c6cbb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/5247a9c6cbb943683c9e2e2cef6eba79.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-72.png",
            "first_name": "Jason",
            "real_name": "Jason Morris",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "jason",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1680370755.360969",
        "parent_user_id": "UC2A2ARPT",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "leVgt",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "emoji",
                                "name": "point_up",
                                "unicode": "261d-1f3fb",
                                "skin_tone": 2
                            },
                            {
                                "type": "text",
                                "text": "That is my answer the challenge #1. Now challenge #2. In Blawx, it would be trivial to take a test, and generalize the inputs of that test by making them abducible, and run the query again. The answer to that second query would be a set of models, with constraints on unground variables, in which the query holds. Essentially, a description of all inputs that would have made your test pass. But of course, there is no reason to have the extra step of starting with a grounded test. You can go straight to the most general query, and say \"give me all the inputs for which the following assertion holds.\" But technically, I think that's an example of #2. The system could answer \"that test passes, because it is an example of this model, anything in that model would work. Also, here are all the other models that work.\" It's also the reason I'm really excited about its potential as a tool for generating tests that can be used to validate the legal reasoning of other systems."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "amiga-tick",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1680402954.168419",
        "client_msg_id": "97F5E441-C9E6-40C4-8A99-FAC12F9D7027",
        "text": "Great answers!",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "Ivan Reese",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1680370755.360969",
        "parent_user_id": "UC2A2ARPT",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hk2H",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Great answers!"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U02U0AS3J49",
        "type": "message",
        "ts": "1680411839.411449",
        "client_msg_id": "da79c858-8bf0-4854-b24b-6bf3254d1089",
        "text": "Great episode! I wonder if being bad at reasoning over specific examples drives one toward philosophy, which attempts to find broader truths. A weakness that creates a corresponding superpower?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g5247a9c6cbb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/5247a9c6cbb943683c9e2e2cef6eba79.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-72.png",
            "first_name": "Jason",
            "real_name": "Jason Morris",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "jason",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1680370755.360969",
        "parent_user_id": "UC2A2ARPT",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "NF93",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Great episode! I wonder if being bad at reasoning over specific examples drives one toward philosophy, which attempts to find broader truths. A weakness that creates a corresponding superpower?"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "face_with_monocle",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    }
]