<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #linking-together</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <img src="https://avatars.slack-edge.com/2017-08-20/228447816352_649181907e06ec450c64_72.jpg" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Stefan Lesser</b>
<span style="margin:2em; color:#606060">2024-10-08 15:01</span><br/>
<a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1362658/full">Naturalizing relevance realization: why agency and cognition&hellip;</a><br/>This is a psychology paper, so perhaps not what you usually consume, but I want to encourage you to give this a go. I think it’s super useful to leave our bubble from time to time and learn about what other disciplines’ perspectives on computation are. I’ll quote the summary at the end, but there is so much more building up to that that you don’t want to miss, certainly not before commenting on it. :)<br/><br/>&gt; The view that intelligence equals some kind of computational optimization is no longer tenable. It does not help us make sense of a large world. Therefore, claims that the study of intelligence is converging onto computational rationality as its ultimate foundation are not only premature, but outright misguided. Quite the opposite: we have shown here that the basic foundation of natural agency and cognition, and therefore of anything we could reasonably call “intelligence,” cannot be computational at all because it cannot be completely formalized. The dream of generating purely algorithmic systems able to think and act like human beings is and remains a pipe dream, because purely symbolic machines exist in small worlds, in which there is no problem of relevance to be solved.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728461980.575889"></a>
      <img src="https://avatars.slack-edge.com/2023-10-13/6057269405632_8ea58fc41bd6baa7dda6_72.png" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728461980.575889" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jack Rusher</b>
<span style="margin:2em; color:#606060">2024-10-09 01:19</span><br/>
:-1::skin-tone-2: This is like the dual of AI people who want to reduce everything to oversimplified computational models because they don’t know enough biology to realize how stupid that is.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728471647.431599"></a>
      <img src="https://avatars.slack-edge.com/2017-08-20/228447816352_649181907e06ec450c64_72.jpg" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728471647.431599" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Stefan Lesser</b>
<span style="margin:2em; color:#606060">2024-10-09 04:00</span><br/>
<span style="background-color:#ccf">@Jack Rusher</span> If one was so misguided to be motivated enough wanting to teach those AI people just enough biology to realize their stupidity, what would one do?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728471688.338619"></a>
      <img src="https://avatars.slack-edge.com/2023-02-06/4754627914258_41a8bada781281751d07_72.jpg" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728471688.338619" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Paul Tarvydas</b>
<span style="margin:2em; color:#606060">2024-10-09 04:01</span><br/>
I believe that computational thinking is a corner that we've painted ourselves into and is causing a great deal of self-flagellation and accidental complexity. I haven't finished reading the paper, but, it seems that this paper, as far as I've read, supports my belief. Does the paper go too far in the opposite direction by proposing new corner-y solutions in lieu of computational thinking?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728472482.025449"></a>
      <img src="https://avatars.slack-edge.com/2017-08-20/228447816352_649181907e06ec450c64_72.jpg" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728472482.025449" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Stefan Lesser</b>
<span style="margin:2em; color:#606060">2024-10-09 04:14</span><br/>
<span style="background-color:#ccf">@Paul Tarvydas</span> Oh, I think you’ll be very interested in finishing reading it, because I guess you will quickly make a connection between the adaptive dynamic process they suggest lies behind relevance realization (which makes it non-computational or rather non-formalizable) and independent parallel processing, which you seem to be interested in judging from several other posts here. Although I’d be particularly careful about that mapping, as of course our understanding of parallelism and concurrency is heavily colored by computational models.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728473426.090779"></a>
      <img src="https://avatars.slack-edge.com/2023-10-13/6057269405632_8ea58fc41bd6baa7dda6_72.png" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728473426.090779" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jack Rusher</b>
<span style="margin:2em; color:#606060">2024-10-09 04:30</span><br/>
<span style="background-color:#ccf">@Stefan Lesser</span> if I knew a short path to that goal, I’d have already written that essay :laughing:<br/><br/>One the other side, “computational” does not mean deterministic/formalizable — i.e. the fact that something is stochastic or heuristic doesn’t prevent it from being modeled via computation. Church/Kleene/Turing stands, though it’s clear that working strictly from a function call perspective is not always the right practical approach (which <span style="background-color:#ccf">@Paul Tarvydas</span> has recently been trying to demonstrate).
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728474207.299069"></a>
      <img src="https://avatars.slack-edge.com/2017-08-20/228447816352_649181907e06ec450c64_72.jpg" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728474207.299069" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Stefan Lesser</b>
<span style="margin:2em; color:#606060">2024-10-09 04:43</span><br/>
<span style="background-color:#ccf">@Jack Rusher</span> I think you should read it. I’d love to hear your thoughts on that taking into account what they write about exactly this. I think they are very thorough in their definition and use of these words.<br/><br/>The paragraph I chose to quote I did for grabbing attention. That’s what social media taught me to do. I realize that in your case that had the opposite effect, and I regret the error.<br/><br/>From what I know about you based on your contributions here, I don’t think you’d let your assessment from above stand after reading it. Or you would at least have a profound insight about why you’d still think so.<br/><br/>On the other hand I also totally understand if you don’t have time for reading dense 20 pages about something that may only be tangentially interesting to you.<br/><br/>Btw, I think a concise answer to the question I asked you would be, “Write exactly that paper.”
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728479246.414369"></a>
      <img src="https://avatars.slack-edge.com/2021-03-12/1859691333940_e169f54bbaf8b9b36b12_72.png" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728479246.414369" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Konrad Hinsen</b>
<span style="margin:2em; color:#606060">2024-10-09 06:07</span><br/>
I see a lot of miscommunication in this space due to people applying specific interpretations "computational" without checking that others' interpretation is sufficiently close.<br/><br/>This paper (which I read a while ago, so I don't remember the details) uses "computation" in the Church-Turing sense, and under that interpretation I agree with the authors. And there are indeed people who make weird claims about life being "just computation" based on the same interpretation, so the criticism is somewhat justified. But then, there are also people with a wider view of computation. I used to be one of them, but I have moved to using less loaded terms (e.g. "information processing") just in order to avoid misunderstandings.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728486457.389659"></a>
      <img src="https://avatars.slack-edge.com/2017-08-20/228447816352_649181907e06ec450c64_72.jpg" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728486457.389659" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Stefan Lesser</b>
<span style="margin:2em; color:#606060">2024-10-09 08:07</span><br/>
<span style="background-color:#ccf">@Konrad Hinsen</span> Can you say more about what exactly this misunderstanding is about? What makes you yearn for a different and less loaded term for computation or a wider view on it?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728486865.483669"></a>
      <img src="https://avatars.slack-edge.com/2017-08-20/228447816352_649181907e06ec450c64_72.jpg" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728486865.483669" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Stefan Lesser</b>
<span style="margin:2em; color:#606060">2024-10-09 08:14</span><br/>
And am I the only one who thinks we’re discussing a minor point of that paper (which, I admit, I have pulled into the spotlight to grab attention), when the real insights are really about a pretty elaborate scientific model that brings us closer to understanding what differentiates minds from machines?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728497866.034039"></a>
      <img src="https://avatars.slack-edge.com/2021-03-12/1859691333940_e169f54bbaf8b9b36b12_72.png" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728497866.034039" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Konrad Hinsen</b>
<span style="margin:2em; color:#606060">2024-10-09 11:17</span><br/>
I don't think it's a minor point because computation in the Church-Turing sense is by definition/construction the action of a machine. Brains do information processing, but it's neither fully symbolic, nor fully deterministic, and in particular not decoupled from an organism's agency which is related to it pursuing goals shaped by evolution. Can you still call that "computation"? Some people say yes, others say no. And then there are those, against which the authors argue, who deny there's a difference.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728572930.565789"></a>
      <img src="https://avatars.slack-edge.com/2023-10-13/6057269405632_8ea58fc41bd6baa7dda6_72.png" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728572930.565789" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jack Rusher</b>
<span style="margin:2em; color:#606060">2024-10-10 08:08</span><br/>
I either read this paper as a preprint last year, or read a nearly identical set of arguments from the same authors. It is, in my opinion, a load of wooly metaphysics that doesn’t advance anyone’s understanding of anything. I put it in the same drawer as Wolfram’s philosophical stuff. Unfortunately, doing a proper job of explaining the ways in which it is <em>not even wrong</em> is a non-trivial undertaking (see <a href="https://en.wikipedia.org/wiki/Brandolini%27s_law">https://en.wikipedia.org/wiki/Brandolini%27s_law</a>). My best attempt at <em>extremely</em> lossy compression:<br/><br/>I am sympathetic to — and frequently make — related arguments with regards to “AI” claims for the current generation of machine learning systems. They are not agents, and non-agentic things are not intelligent in anything like the definition we use for biological entities. Any attempt to make something actually intelligent would start from <em>drives</em> (something more like what we call <em>emotions</em>) than from simulating what many regard as intelligent activity (“write an essay based on a prompt”, &c). Failure to understand this is part of a long running tendency of clever humans who have been rewarded for “being smart” to over index on tasks for which they were rewarded rather than tasks that allowed 4 billion years of their ancestors to survive. On this general point I think I am in complete agreement with the authors.<br/><br/>But this doesn’t actually argue against the idea that biological entities are made of networks of parts undergoing processes, and that the behaviors of those parts (the nature of those processes) could be encoded in a different chemical substrate. Nor does it suggest that a mechanism that can model arbitrary processes (e.g. Turing machine) cannot model the specific processes going on inside the parts within those networks. The arguments they make against Deutsch-style pancomputationalism hinge on things like determinism/syntactic formal systems that feel completely irrelevant in this context (Turing machines can model stochastic processes, and they are “symbolic” only in the sense that we use symbols to understand/encode them).
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728630327.940339"></a>
      <img src="https://avatars.slack-edge.com/2021-03-12/1859691333940_e169f54bbaf8b9b36b12_72.png" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728630327.940339" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Konrad Hinsen</b>
<span style="margin:2em; color:#606060">2024-10-11 00:05</span><br/>
There's a fine metaphysical line between "Turing machines can model X" and "X <em>is</em> equivalent to a Turing machine". The authors of the paper argue against the second stance, adopting the opposite one. Personally, I am happy to remain uncommitted.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728630878.056879"></a>
      <img src="https://avatars.slack-edge.com/2023-05-25/5325882725604_ccf2efd02f98ce727cf0_72.jpg" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728630878.056879" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Estebe Sylvain</b>
<span style="margin:2em; color:#606060">2024-10-11 00:14</span><br/>
Hello from a cognitive science perspective I can recommend this paper: <a href="https://link.springer.com/article/10.1007/s42113-024-00217-5">https://link.springer.com/article/10.1007/s42113-024-00217-5</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728642232.686449"></a>
      <img src="https://avatars.slack-edge.com/2017-08-20/228447816352_649181907e06ec450c64_72.jpg" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728642232.686449" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Stefan Lesser</b>
<span style="margin:2em; color:#606060">2024-10-11 03:23</span><br/>
<span style="background-color:#ccf">@Jack Rusher</span> Thank you for elaborating on this. I appreciate you taking the time to write this. I am very interested in positions against what they argue to make up my mind of how profound their ideas really are, and being left to my own (and at this point fairly biased) interpretations probably means I’m at risk to overlook something.<br/><br/>So far, however, I only hear criticisms that seem to be rooted in the fear that the authors take some possibility away. I tend to see their attempt in differentiating algorithmic (both symbolic and stochastic) models from a totally different constraint-based dynamical systems approach that provides characteristics that the computational approach can’t as a revelatory insight that, while perhaps putting algorithmic approaches in their slightly more restricted place, doesn’t at all prevent those approaches from continuing to improve their approximations of reality. Which maps nicely to what’s happening in AI, mostly by increasing complexity in the form of increasing both data and compute. That probably also explains why I find their point about computation rather minor, <span style="background-color:#ccf">@Konrad Hinsen</span>.<br/><br/>At the same time it paves the way for a new and different path of exploration that tries to integrate human cognition, which I personally find much more refreshing than the “If we just throw enough data and compute at it” approaches that are so en vogue in AI currently. There’s lots of space (and tons more resources, apparently) to build more and better models the “classic” way. I don’t think anyone is trying to take that away. However, there is also a refined understanding of an alternative path emerging, that seems (to me at least) to be based in good science.<br/><br/>Of course, I am an enthusiastic amateur at best, and my judgement of how good the science is means nothing to anybody else. But having spent a lot of time with some of the adjacent research, mainly relevance realization (Vervaeke) and constraint-based meta-stability in complex dynamical systems (Juarrero), there is something here that endlessly fascinates me. And it is so sad that it is so difficult to share that fascination and excitement with others.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1728674235.425399"></a>
      <img src="https://avatars.slack-edge.com/2023-10-13/6057269405632_8ea58fc41bd6baa7dda6_72.png" style="float:left"/>
      <a href="../linking-together/1728424908.187449.html#1728674235.425399" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Jack Rusher</b>
<span style="margin:2em; color:#606060">2024-10-11 12:17</span><br/>
I seem to completely failed to communicate my point, for which I’m sorry. But I also don’t have enough bandwidth at present to make another pass at it. :man-shrugging::skin-tone-2:
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
