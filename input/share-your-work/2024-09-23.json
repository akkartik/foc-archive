[
    {
        "user": "U07M5DU6Y07",
        "type": "message",
        "ts": "1727083580.324709",
        "edited": {
            "user": "U07M5DU6Y07",
            "ts": "1727083653.000000"
        },
        "client_msg_id": "cbb09a35-3c99-46ba-905a-3b0883ceebf9",
        "text": "Great point! Here are some I'd like to hear more about:\n1. What testing strategies have you used and if stopped using any, why?\n2. What types of testing, practices, tools, and metrics have you used to measure the readiness of a product for release?\n3. What were the most significant challenges you faced during the testing process, coverage, maintenance, or automation? How were these addressed?\n 4.  Who was responsible for what portion of testing in your teams?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "7eaa7645002c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-09-20\/7746220227543_7eaa7645002c33f9306a_72.jpg",
            "first_name": "saba",
            "real_name": "saba",
            "display_name": "saba",
            "team": "T5TCAFTA9",
            "name": "khur.saba",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1726851058.609769",
        "parent_user_id": "U07M5DU6Y07",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "1eRqY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Great point! Here are some I'd like to hear more about:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "What testing strategies have you used and if stopped using any, why?"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "What types of testing, practices, tools, and metrics have you used to measure the readiness of a product for release?"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "What were the most significant challenges you faced during the testing process, coverage, maintenance, or automation? How were these addressed?"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": " 4.  Who was responsible for what portion of testing in your teams?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0296ACR13M",
        "type": "message",
        "ts": "1727156421.751639",
        "edited": {
            "user": "U0296ACR13M",
            "ts": "1727156817.000000"
        },
        "client_msg_id": "a0e29935-8a96-48c6-954e-81833380edff",
        "text": "Okay, well I can try to say something about 1.\n\nSo over the years I've only worked in one project that did automated testing by the book: unit testing, integration testing automated UI testing. There was a dedicated person working on automated UI testing and couple people doing manual testing part-time. Probably about half of the effort in the project went into testing in different forms. It was cool, but I didn't really feel the payback was necessary there for a system on which no ones life depends on. Code quality of the tests was bit of an issue and maintaining them was certainly a pain at times. Now days I suppose LLMs could be useful here.\n\nAnyway, I do vouch for integration tests much more than for unit testing. When you're testing bigger pieces of your system it's usually possible to work with APIs that very very rarely change. Like testing that your rest API gives the correct response for a query and database state. You'll inject test data in you DB schema (which seldom changes) and read the results from the API response (which seldom changes, or often has to be backwards compatible anyway). I've also built solutions for generating the test data out of a schema and then assert against the generated data. Some would say that it's too complicated code for tests so you can have bugs in your tests, but I see the changes for false positives very low. What I like about tests like this is that you can refactor everything between your database and the API without having to rework tests while still getting valuable results from tests. Additionally these tests serve as a nice debugging setup: set a breakpoint, run a test in degugger and you can start walking your code with your system in a somewhat realistic state.\n\nAnother approach I've found giving good payback for the effort is using quite a bit of asserts throughout your code. So checks on value ranges etc that aren't necessarily run on production but let you know if something that's obviously wrong is happening in your system.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "59de929720a2",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-09-08\/4075674207584_59de929720a2fe0a13d8_72.jpg",
            "first_name": "",
            "real_name": "Jarno Montonen",
            "display_name": "Jarno Montonen",
            "team": "T5TCAFTA9",
            "name": "jarno.montonen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1726851058.609769",
        "parent_user_id": "U07M5DU6Y07",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "x1WnQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Okay, well I can try to say something about 1.\n\nSo over the years I've only worked in one project that did automated testing by the book: unit testing, integration testing automated UI testing. There was a dedicated person working on automated UI testing and couple people doing manual testing part-time. Probably about half of the effort in the project went into testing in different forms. It was cool, but I didn't really feel the payback was necessary there for a system on which no ones life depends on. Code quality of the tests was bit of an issue and maintaining them was certainly a pain at times. Now days I suppose LLMs could be useful here.\n\nAnyway, I do vouch for integration tests much more than for unit testing. When you're testing bigger pieces of your system it's usually possible to work with APIs that very very rarely change. Like testing that your rest API gives the correct response for a query and database state. You'll inject test data in you DB schema (which seldom changes) and read the results from the API response (which seldom changes, or often has to be backwards compatible anyway). I've also built solutions for generating the test data out of a schema and then assert against the generated data. Some would say that it's too complicated code for tests so you can have bugs in your tests, but I see the changes for false positives very low. What I like about tests like this is that you can refactor everything between your database and the API without having to rework tests while still getting valuable results from tests. Additionally these tests serve as a nice debugging setup: set a breakpoint, run a test in degugger and you can start walking your code with your system in a somewhat realistic state.\n\nAnother approach I've found giving good payback for the effort is using quite a bit of asserts throughout your code. So checks on value ranges etc that aren't necessarily run on production but let you know if something that's obviously wrong is happening in your system."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "eyes",
                "users": [
                    "U07M5DU6Y07"
                ],
                "count": 1
            }
        ]
    }
]