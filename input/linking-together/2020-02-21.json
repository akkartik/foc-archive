[
    {
        "user": "UC6997THT",
        "type": "message",
        "ts": "1582296923.129100",
        "edited": {
            "user": "UC6997THT",
            "ts": "1582296974.000000"
        },
        "client_msg_id": "cba5ce5a-10ea-409f-9515-e25707eb1a50",
        "text": "That sounds exactly the opposite of my experience. I didnt' solve quicksort, I learned it. I didn't solve the command pattern, it was introduced to me via a book. I learned bubblesort and file i\/o from my teachers. I learned A* from some article on the net. I learned 3D from friends and articles and books.\n\nI actually feel like that tweet is harmful. Especially when related to the how to teach programming video posted earlier.\n\nThen again, maybe it's just proof I'm not a great programmer if by defintion I needed solve all of those problems instead of just learn them.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "f3eb3ca69d86",
            "image_72": "https:\/\/avatars.slack-edge.com\/2018-08-13\/414472553296_f3eb3ca69d86feb77929_72.png",
            "first_name": "Gregg",
            "real_name": "Gregg Tavares",
            "display_name": "gman",
            "team": "T5TCAFTA9",
            "name": "slack1",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1580910195.109200",
        "parent_user_id": "U5STGTB3J",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "K1G2",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "That sounds exactly the opposite of my experience. I didnt' solve quicksort, I learned it. I didn't solve the command pattern, it was introduced to me via a book. I learned bubblesort and file i\/o from my teachers. I learned A* from some article on the net. I learned 3D from friends and articles and books.\n\nI actually feel like that tweet is harmful. Especially when related to the how to teach programming video posted earlier.\n\nThen again, maybe it's just proof I'm not a great programmer if by defintion I needed solve all of those problems instead of just learn them."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UG0EL18H3",
        "type": "message",
        "ts": "1582305108.130000",
        "client_msg_id": "2d1f4f2d-274b-4fc3-9fce-9314895a82a1",
        "text": "imagine coding inside of \"the volume\", basically a giant LED room: <https:\/\/ascmag.com\/articles\/the-mandalorian>",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "25cc47143833",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-08-01\/702360681283_25cc471438337c72e600_72.jpg",
            "first_name": "Chris",
            "real_name": "Chris Rabl",
            "display_name": "crabl",
            "team": "T5TCAFTA9",
            "name": "chris.rabl",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1582305108.130000",
        "reply_count": 7,
        "reply_users_count": 5,
        "latest_reply": "1582441409.000300",
        "reply_users": [
            "UC2A2ARPT",
            "UE0H4170F",
            "UEQ6M68H0",
            "UA14TGLTC",
            "UC6997THT"
        ],
        "replies": [
            {
                "user": "UC2A2ARPT",
                "ts": "1582307838.130300"
            },
            {
                "user": "UE0H4170F",
                "ts": "1582310894.132800"
            },
            {
                "user": "UE0H4170F",
                "ts": "1582310925.133600"
            },
            {
                "user": "UE0H4170F",
                "ts": "1582310956.134000"
            },
            {
                "user": "UEQ6M68H0",
                "ts": "1582333230.134400"
            },
            {
                "user": "UA14TGLTC",
                "ts": "1582339904.134700"
            },
            {
                "user": "UC6997THT",
                "ts": "1582441409.000300"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "y55+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "imagine coding inside of \"the volume\", basically a giant LED room: "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/ascmag.com\/articles\/the-mandalorian"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "ULM3U6275",
                    "UC2A2ARPT",
                    "UJ6LDMMN0",
                    "UA14TGLTC"
                ],
                "count": 4
            }
        ]
    },
    {
        "user": "UC2A2ARPT",
        "type": "message",
        "ts": "1582307838.130300",
        "client_msg_id": "a9617584-faac-45f9-9197-17ba226bcf20",
        "text": "Yeah, that gives \"room-scale VR\" a whole new meaning.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gf94d2ed5e18",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6f94d2ed5e188be9865a531021b0afcd.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0013-72.png",
            "first_name": "Ivan",
            "real_name": "Ivan Reese",
            "display_name": "Ivan Reese",
            "team": "T5TCAFTA9",
            "name": "ivanreese",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1582305108.130000",
        "parent_user_id": "UG0EL18H3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "9Sr3r",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah, that gives \"room-scale VR\" a whole new meaning."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UE0H4170F",
        "type": "message",
        "ts": "1582310894.132800",
        "client_msg_id": "f3141090-2822-4a78-a249-bf3deaaf75f7",
        "text": "That is cool. I did my PhD inside of something like that, except with the bottom half of the sphere as well. <https:\/\/www.optimistdaily.com\/2018\/10\/enter-the-allosphere-with-dr-joann-kuchera-morin\/>",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g2cfca823894",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/72cfca823894034e7bdbc31623c007d3.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png",
            "first_name": "",
            "real_name": "Charlie Roberts",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "charlie",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1582305108.130000",
        "parent_user_id": "UG0EL18H3",
        "attachments": [
            {
                "service_name": "The Optimist Daily",
                "title": "Enter the AlloSphere with Dr. JoAnn Kuchera-Morin",
                "title_link": "https:\/\/www.optimistdaily.com\/2018\/10\/enter-the-allosphere-with-dr-joann-kuchera-morin\/",
                "text": "[vc_row][vc_column][vc_column_text] New Frontiers: Pushing the Boundaries of the Possible By Sadie Wilbur, Editorial Coordinator Humans are driven to explore the unknown, discover new worlds, push the boundaries of our scientific and technical limits, and then push further. The desire to explore and challenge the boundaries of what we know and where we have been has provided benefits to our society for centuries. Professor JoAnn Kuchera-Morin, a composer, researcher, and pioneer, is driven by passion and an ability to imagine and aspire to what did not yet exist. Over the past three decades, she has grown her creative vision across traditional disciplinary boundaries to embrace complex systems at the far reaches of human understanding.   Kuchera-Morin began her creative life in higher-education as a composer, an innovative and successful one. She earned her Ph.D. in music composition, with a computer music emphasis, from the Eastman School of Music at the University of Rochester in New York. Shortly after graduating, she came to the University of California, Santa Barbara and designed the Center for Research in Electronic Art Technology (CREATE). She has served as the Center’s Director since its creation in 1984. The center provides a dynamic environment for students, researchers, and media artists to pursue diverse research projects and realize a wide array of works. In the early 90’s, Professor Kuchera-Morin became the Associate Dean of Computing for the College of Letters and Sciences. As the Associate Dean, she built the Letters and Sciences Information Technology Services Center, redesigned the campuses research infrastructure, and was then called on by the UC Office of the President to build a multimillion-dollar sponsored digital media research program. And that’s exactly what she did. It is called the Digital Media Innovation Program (DiMI) and Professor Kuchera-Morin was Director and Chief Scientist from 1998 to 2003. \"DiMI integrates the nine University of California campuses and three National Laboratories to create an unbiased resource, enabling partnerships to fuel core technology development across multiple application areas,\" Kuchera-Morin explains. After a decade of research, Professor Kuchera-Morin and two other researchers developed the Media Arts &amp; Technology (MAT) graduate program, which brought together graduate students and faculty from the visual and spatial arts, music, electrical engineering, and computer science fields to create a transdisciplinary program at the frontier of media arts. In this program, students can attach themselves across disciplines, and that’s the idea. “What we are doing is creating a new kind of hybrid student,” said Kuchera-Morin. The culmination of Kuchera-Morin’s creative work is the AlloSphere, a 3-story-high spherical research instrument completed in 2007, that takes data too small to see or hear and visually and sonically magnifies it to the human scale, allowing scientists and engineers to interact with complex data like artists: creatively and intuitively. As researchers use the full capacity of their senses to explore new modes of expression and discovery, they forge a new frontier of research at the intersection of science, art, and engineering. Leading the way is JoAnn Kuchera-Morin, a professor of Media Arts and Technology and Music at UC Santa Barbara. Kuchera-Morin began her creative life in higher education as an innovative composer, and she approached the design of the AlloSphere in much the same way that she composes a piece of music. In a recent interview, Kuchera-Morin, director of the research lab, discussed the importance of holistic thinking and a return to the learning-by-doing that the AlloSphere enables. Q. What question or challenge were you setting out to address when you started your work here at UC Santa Barbara? A. I've always been looking to answer one question that will never be answered, which is primarily, I think, what most artists do. That’s why there are artists; most of what they do deals with constantly searching for the meaning of life. Quantum mechanics, understanding how and why the world works, has always fascinated me, but I didn’t have any kind of training in that area. So, it’s always exciting for me to be able to explore those areas of the unknown and I've had the opportunity to do that throughout my time here. In day to day life, we intuitively understand how the world works and throughout my research, I’ve tried to extend this intuitive understand from the simple to the incredibly complex. To make the impossible, possible, or the unthinkable, thinkable. And as an artist, what has helped me do this is mathematics. Q. Can you explain how mathematics has helped you in your research? A. The one thing that most people don't understand is that music is all mathematics. Everything you do is mathematics. When I started working with what we call electroacoustic music composition, using the computer plus instruments, I started expanding that technology, expanding my mathematics. When I wanted to push the boundaries with my compositions, I did that by extending mathematical principles, not only sonically, but also visually and interactively. Q. It takes courage to explore a new frontier, and to push the boundaries of a genre — be it in art, science or engineering. What motivates you to get up in the morning and pursue your research, every day? What excites you about your work? A. UC Santa Barbara is a highly interdisciplinary campus and it affords you the opportunities to explore in ways that you typically can't explore in other places, so that has been very exciting for me. In the 35 years that I've been here, absolutely nothing has ever been boring. As a matter fact, every day I come into the University, I hope I can teach the students that are in my midst because they're incredibly brilliant and hybrid in many ways. It’s a wonderful environment for me to be able to never be comfortable and always evolve and explore. One example is the Media Arts and Technology (MAT) graduate program, which my colleagues and I launched in 2000. The program brings together four disciplines: Art, Computer Science, Electrical and Computer Engineering, and Music. In the program, it’s all about making and creating, and doing the research to build these complex systems. And then it’s about going from the high-level research to outreach, to engaging the community and educating the future. Q. What is the importance of the AlloSphere and projects of this kind? A. When you can interact with complex systems—visually, sonically, interactively—and play with it in your mind, you're going to comprehend it in ways like never before. You're going to understand how to apply it and it's going to take on a new level of importance for you since it is no longer something abstract. We believe this is beginning a new era of teaching and reformation, which is learning by doing and understanding by seeing. Ted Talk: Stunning data visualization in the AlloSphere [\/vc_column_text][vc_video link=\"<https:\/\/www.youtube.com\/embed\/u-D-zEToJQ4>\" align=\"center\"][\/vc_column][\/vc_row]",
                "fallback": "The Optimist Daily: Enter the AlloSphere with Dr. JoAnn Kuchera-Morin",
                "image_url": "https:\/\/www.optimistdaily.com\/wp-content\/uploads\/moon-allosphere.jpg",
                "ts": 1540070157,
                "from_url": "https:\/\/www.optimistdaily.com\/2018\/10\/enter-the-allosphere-with-dr-joann-kuchera-morin\/",
                "image_width": 388,
                "image_height": 250,
                "image_bytes": 200119,
                "service_icon": "https:\/\/www.optimistdaily.com\/wp-content\/themes\/magazine-pro\/images\/favicon.ico",
                "id": 1,
                "original_url": "https:\/\/www.optimistdaily.com\/2018\/10\/enter-the-allosphere-with-dr-joann-kuchera-morin\/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "lVw7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "That is cool. I did my PhD inside of something like that, except with the bottom half of the sphere as well. "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/www.optimistdaily.com\/2018\/10\/enter-the-allosphere-with-dr-joann-kuchera-morin\/"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UE0H4170F",
        "type": "message",
        "ts": "1582310925.133600",
        "client_msg_id": "c86d73ac-e294-4ce6-9ab3-105f42d9fc94",
        "text": "…and it was stereo, and mostly used realtime rendering.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g2cfca823894",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/72cfca823894034e7bdbc31623c007d3.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png",
            "first_name": "",
            "real_name": "Charlie Roberts",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "charlie",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1582305108.130000",
        "parent_user_id": "UG0EL18H3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Ekm",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "…and it was stereo, and mostly used realtime rendering."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UE0H4170F",
        "type": "message",
        "ts": "1582310956.134000",
        "client_msg_id": "4b9008be-5484-4583-9fea-1b2d74bc6759",
        "text": "worth seeing if you’re in Santa Barbara",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g2cfca823894",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/72cfca823894034e7bdbc31623c007d3.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0002-72.png",
            "first_name": "",
            "real_name": "Charlie Roberts",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "charlie",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1582305108.130000",
        "parent_user_id": "UG0EL18H3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "nByql",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "worth seeing if you’re in Santa Barbara"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEQ6M68H0",
        "type": "message",
        "ts": "1582333230.134400",
        "client_msg_id": "d61ec18d-c9ba-4dc3-a0e0-665fd7659572",
        "text": "amazing technology.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "326328f75c3f",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-02-05\/542651515888_326328f75c3f2a08544c_72.jpg",
            "first_name": "Edward",
            "real_name": "Edward de Jong",
            "display_name": "Edward de Jong \/ Beads Project",
            "team": "T5TCAFTA9",
            "name": "magicmouse94937",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1582305108.130000",
        "parent_user_id": "UG0EL18H3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+T1v",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "amazing technology."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UA14TGLTC",
        "type": "message",
        "ts": "1582339904.134700",
        "client_msg_id": "bb7c5c2b-ee80-45f3-9c4a-4026aab71932",
        "text": "\"Due to the 10-12 frames (roughly half a second) of latency from the time Profile’s system received camera-position information to Unreal’s rendering of the new position on the LED wall, if the camera moved ahead of the rendered frustum (a term defining the virtual field of view of the camera) on the screen, the transition line between the high-quality perspective render window and the lower-quality main render would be visible. To avoid this, the frustum was projected an average of 40-percent larger than the actual field of view of the camera\/lens combination, to allow some safety margin for camera moves. In some cases, if the lens’ field of view — and therefore the frustum — was too wide, the system could not render an image high-res enough in real time; the production would then use the image on the LED screen simply as lighting, and composite the image in post [with a greenscreen added behind the actors]. In those instances, the backgrounds were already created, and the match was seamless because those actual backgrounds had been used at the time of photography [to light the scene].\"",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gae6d55db9d1",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png",
            "first_name": "",
            "real_name": "William Taysom",
            "display_name": "wtaysom",
            "team": "T5TCAFTA9",
            "name": "wtaysom",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1582305108.130000",
        "parent_user_id": "UG0EL18H3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "jYP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\"Due to the 10-12 frames (roughly half a second) of latency from the time Profile’s system received camera-position information to Unreal’s rendering of the new position on the LED wall, if the camera moved ahead of the rendered frustum (a term defining the virtual field of view of the camera) on the screen, the transition line between the high-quality perspective render window and the lower-quality main render would be visible. To avoid this, the frustum was projected an average of 40-percent larger than the actual field of view of the camera\/lens combination, to allow some safety margin for camera moves. In some cases, if the lens’ field of view — and therefore the frustum — was too wide, the system could not render an image high-res enough in real time; the production would then use the image on the LED screen simply as lighting, and composite the image in post [with a greenscreen added behind the actors]. In those instances, the backgrounds were already created, and the match was seamless because those actual backgrounds had been used at the time of photography [to light the scene].\""
                            }
                        ]
                    }
                ]
            }
        ]
    }
]