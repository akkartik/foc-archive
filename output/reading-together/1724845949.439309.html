<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #reading-together</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <a href="../reading-together/1724845949.439309.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Nilesh Trivedi</b>
<span style="margin:2em; color:#606060">2024-08-28 04:52</span><br/>
LLMs are forcing me to think about non-deterministic yet rational "computation".<br/><br/>Agents are beyond what traditionally computation has been. When an agent starts performing a task, and the environment changes, they need to find the balance between too much rethinking (classical decision theory) and not enough rethinking (computation).<br/><br/><a href="https://web.archive.org/web/20110604050051/https://www.aaai.org/Papers/ICMAS/1995/ICMAS95-042.pdf">https://web.archive.org/web/20110604050051/https://www.aaai.&hellip;</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1724955744.917389"></a>
      <img src="https://secure.gravatar.com/avatar/7744be691cc012a06105570b02701e0c.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png" style="float:left"/>
      <a href="../reading-together/1724845949.439309.html#1724955744.917389" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Kyle Beechly</b>
<span style="margin:2em; color:#606060">2024-08-29 11:22</span><br/>
Yes! Thank you for the link - bookmarking to read later
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
