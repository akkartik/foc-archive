[
    {
        "text": "Big milestone. Three minute video, shows my system using LLM code generation to generate visual logic code representing sections of a law, based only on the text of the law. (play at 2x, there's a lot of waiting)",
        "files": [
            {
                "id": "F06DN1E6Q22",
                "mode": "hidden_by_limit"
            }
        ],
        "upload": false,
        "user": "U02U0AS3J49",
        "display_as_bot": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "w6d5x",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Big milestone. Three minute video, shows my system using LLM code generation to generate visual logic code representing sections of a law, based only on the text of the law. (play at 2x, there's a lot of waiting)"
                            }
                        ]
                    }
                ]
            }
        ],
        "type": "message",
        "ts": "1705261172.593959",
        "edited": {
            "user": "U02U0AS3J49",
            "ts": "1705261203.000000"
        },
        "client_msg_id": "45f5064e-a768-4e6c-a126-3aa2da4eac0f",
        "thread_ts": "1705261172.593959",
        "reply_count": 3,
        "reply_users_count": 3,
        "latest_reply": "1705377885.636469",
        "reply_users": [
            "U0123H7JRDM",
            "U02U0AS3J49",
            "U04JY2BF24E"
        ],
        "replies": [
            {
                "user": "U0123H7JRDM",
                "ts": "1705265137.689809"
            },
            {
                "user": "U02U0AS3J49",
                "ts": "1705268865.581039"
            },
            {
                "user": "U04JY2BF24E",
                "ts": "1705377885.636469"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "fire",
                "users": [
                    "U0123H7JRDM",
                    "U0296ACR13M",
                    "U03E4LY27FS"
                ],
                "count": 3
            }
        ]
    },
    {
        "user": "U0123H7JRDM",
        "type": "message",
        "ts": "1705265137.689809",
        "client_msg_id": "1E86A901-7A8C-4B8A-B6CE-16D73735D015",
        "text": "Which LLM are you using?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "533c1a6943bf",
            "image_72": "https:\/\/avatars.slack-edge.com\/2025-03-16\/8613805779220_533c1a6943bfc0b7f150_72.jpg",
            "first_name": "Maikel",
            "real_name": "Maikel van de Lisdonk",
            "display_name": "Maikel",
            "team": "T5TCAFTA9",
            "name": "maikel",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1705261172.593959",
        "parent_user_id": "U02U0AS3J49",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "bwboh",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Which LLM are you using?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U02U0AS3J49",
        "type": "message",
        "ts": "1705268865.581039",
        "client_msg_id": "785ae451-f1f9-433f-8fd1-4c610cfd5529",
        "text": "The latest GPT4. As the complexity of the language it can handle increases I'm anticipating needing the increased context space because JSON code expressions are very token heavy, and GPT4 is better than anything else I have tried at generating JSON according to a schema.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "g5247a9c6cbb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/5247a9c6cbb943683c9e2e2cef6eba79.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0022-72.png",
            "first_name": "Jason",
            "real_name": "Jason Morris",
            "display_name": "",
            "team": "T5TCAFTA9",
            "name": "jason",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1705261172.593959",
        "parent_user_id": "U02U0AS3J49",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "IQnAp",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The latest GPT4. As the complexity of the language it can handle increases I'm anticipating needing the increased context space because JSON code expressions are very token heavy, and GPT4 is better than anything else I have tried at generating JSON according to a schema."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]