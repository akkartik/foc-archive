[
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1670236130.859509",
        "edited": {
            "user": "UJBAJNFLK",
            "ts": "1670236159.000000"
        },
        "client_msg_id": "f1a6bb63-aca4-4b96-8db1-cd15e49acf2c",
        "text": "Some random thoughts on this:\n1. Programming, like all automation, is an amplifier for decisions. This makes it difficult to foresee the consequences of the decisions, and that is the root cause of all the trouble humanity has had with industrialization and now with computing.\n  2. In the interest of safety, decision amplification requires one of\n      a. a limited scope of automation (sandboxing, ...)\n      b. regular validation of execution by an agent that has an incentive not to do harm (liability, ...)\n      c. provable predictability of consequences (matematical proof, ...)\n\nSo... which amplifiable decisions can we safely delegate to today's AIs? I'd say none. So the questions becomes: how do AIs need to evolve so that we can safely delegate amplifiable decisions to them?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670152748.796319",
        "parent_user_id": "UJFN50C00",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "YxI2x",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Some random thoughts on this:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Programming, like all automation, is an amplifier for decisions. This makes it difficult to foresee the consequences of the decisions, and that is the root cause of all the trouble humanity has had with industrialization and now with computing."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "  2. In the interest of safety, decision amplification requires one of\n      a. a limited scope of automation (sandboxing, ...)\n      b. regular validation of execution by an agent that has an incentive not to do harm (liability, ...)\n      c. provable predictability of consequences (matematical proof, ...)\n\nSo... which amplifiable decisions can we safely delegate to today's AIs? I'd say none. So the questions becomes: how do AIs need to evolve so that we can safely delegate amplifiable decisions to them?"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "point_up_2",
                "users": [
                    "UJFN50C00"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1670236269.788779",
        "client_msg_id": "c98e7d36-68e5-4f07-8652-aa87ca9eda8b",
        "text": "Something we can safely do even now is use AI for generating propositions that are validated by a human programmer. Make AI a replacement for looking up documentation and copy-pasting boilerplate code. But that's not what I see people discussing.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670152748.796319",
        "parent_user_id": "UJFN50C00",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "nBd",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Something we can safely do even now is use AI for generating propositions that are validated by a human programmer. Make AI a replacement for looking up documentation and copy-pasting boilerplate code. But that's not what I see people discussing."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJFN50C00",
        "type": "message",
        "ts": "1670236812.147459",
        "client_msg_id": "4E51EC2C-0095-4B67-AB8F-68E5103AA967",
        "text": "But even making suggestions will influence the end result. But I would agree that there is a strong search for a use case when there is not really one",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e35958b94f07",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-05-06\/616300651267_e35958b94f07da17cf17_72.png",
            "first_name": "Andreas",
            "real_name": "Andreas S.",
            "display_name": "curious_reader",
            "team": "T5TCAFTA9",
            "name": "andreas.scheinert",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670152748.796319",
        "parent_user_id": "UJFN50C00",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "V7Yl",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "But even making "
                            },
                            {
                                "type": "text",
                                "text": "suggestions"
                            },
                            {
                                "type": "text",
                                "text": " will "
                            },
                            {
                                "type": "text",
                                "text": "influence"
                            },
                            {
                                "type": "text",
                                "text": " the end result. But "
                            },
                            {
                                "type": "text",
                                "text": "I"
                            },
                            {
                                "type": "text",
                                "text": " would agree that there is a "
                            },
                            {
                                "type": "text",
                                "text": "strong"
                            },
                            {
                                "type": "text",
                                "text": " search for a use case "
                            },
                            {
                                "type": "text",
                                "text": "when"
                            },
                            {
                                "type": "text",
                                "text": " there is not "
                            },
                            {
                                "type": "text",
                                "text": "really"
                            },
                            {
                                "type": "text",
                                "text": " one"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03GBV8B58V",
        "type": "message",
        "ts": "1670240076.951139",
        "client_msg_id": "0d6fcbf9-0fe6-4673-8cd5-65781954a3f2",
        "text": "Provenance of content will be a huge challenge due to recent advancements in AI\/ML. My immediate thought was \"but code is in Git etc. and we know the author\", but that's all void if the actual author of the code was a tool like ChatGPT\/Co-Pilot and the dev was just the one that pushed it.\n\nMaybe AI will be what brings about next-gen versioning systems where content provenance is managed at the AST node level during code authoring, and not just by whoever pushed the code after the fact.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "3e8345518ba8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-05-21\/3558879757875_3e8345518ba82b825c6d_72.jpg",
            "first_name": "Jim",
            "real_name": "Jim Meyer",
            "display_name": "Jim Meyer",
            "team": "T5TCAFTA9",
            "name": "jimkyndemeyer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "reply_count": 17,
        "reply_users_count": 4,
        "latest_reply": "1670380342.208799",
        "reply_users": [
            "U018S42NMMM",
            "U03GBV8B58V",
            "UNS7QDKFV",
            "UA14TGLTC"
        ],
        "replies": [
            {
                "user": "U018S42NMMM",
                "ts": "1670240212.422879"
            },
            {
                "user": "U03GBV8B58V",
                "ts": "1670240552.221889"
            },
            {
                "user": "U03GBV8B58V",
                "ts": "1670240604.404989"
            },
            {
                "user": "U018S42NMMM",
                "ts": "1670240775.411709"
            },
            {
                "user": "U03GBV8B58V",
                "ts": "1670240868.058109"
            },
            {
                "user": "U018S42NMMM",
                "ts": "1670240984.234009"
            },
            {
                "user": "U03GBV8B58V",
                "ts": "1670241124.331109"
            },
            {
                "user": "U018S42NMMM",
                "ts": "1670241252.681229"
            },
            {
                "user": "U03GBV8B58V",
                "ts": "1670241304.171919"
            },
            {
                "user": "U018S42NMMM",
                "ts": "1670241558.697079"
            },
            {
                "user": "U03GBV8B58V",
                "ts": "1670242095.570469"
            },
            {
                "user": "U018S42NMMM",
                "ts": "1670242165.099499"
            },
            {
                "user": "U03GBV8B58V",
                "ts": "1670242186.521569"
            },
            {
                "user": "U03GBV8B58V",
                "ts": "1670242985.762439"
            },
            {
                "user": "U03GBV8B58V",
                "ts": "1670243084.896449"
            },
            {
                "user": "UNS7QDKFV",
                "ts": "1670258014.203649"
            },
            {
                "user": "UA14TGLTC",
                "ts": "1670380342.208799"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "p08En",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Provenance of content will be a huge challenge due to recent advancements in AI\/ML. My immediate thought was \"but code is in Git etc. and we know the author\", but that's all void if the actual author of the code was a tool like ChatGPT\/Co-Pilot and the dev was just the one that pushed it.\n\nMaybe AI will be what brings about next-gen versioning systems where content provenance is managed at the AST node level during code authoring, and not just by whoever pushed the code after the fact."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U018S42NMMM",
        "type": "message",
        "ts": "1670240212.422879",
        "client_msg_id": "f71f8634-0222-4e0c-a701-26179367cf7e",
        "text": "Why does provenance matter? If it's good enough to pass a human review, then it's good enough. So quality\/accuracy will matter more than provenance.\n\nOr did you have copyright liability in mind?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "972d4c887a7c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-10\/4782052692709_972d4c887a7c689aae4a_72.jpg",
            "first_name": "",
            "real_name": "Nilesh Trivedi",
            "display_name": "Nilesh Trivedi",
            "team": "T5TCAFTA9",
            "name": "nilesh.tr",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RF0dI",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Why does provenance matter? If it's good enough to pass a human review, then it's good enough. So quality\/accuracy will matter more than provenance.\n\nOr did you have copyright liability in mind?"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U03GBV8B58V",
        "type": "message",
        "ts": "1670240552.221889",
        "edited": {
            "user": "U03GBV8B58V",
            "ts": "1670240584.000000"
        },
        "client_msg_id": "969aa29c-0e93-4221-b9ce-4cf0e76902d3",
        "text": "I think the review aspect is that weak part of the link. More people, with less programming knowledge will be adding code that was written by AI, and even developers are busy and will accept code that looks correct. All that code is then fed into the training set of the next round, and you've got a positive feedback loop.\n\nIt's the same as self-driving cars. Humans learn to trust the system, relax, and then it's all fine until it's not. I do think we'll eventually get to a good place, but right now we're in the gap between two worlds, and that's when the damage happens.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "3e8345518ba8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-05-21\/3558879757875_3e8345518ba82b825c6d_72.jpg",
            "first_name": "Jim",
            "real_name": "Jim Meyer",
            "display_name": "Jim Meyer",
            "team": "T5TCAFTA9",
            "name": "jimkyndemeyer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "X17a",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think the review aspect is that weak part of the link. More people, with less programming knowledge will be adding code that was written by AI, and even developers are busy and will accept code that looks correct. All that code is then fed into the training set of the next round, and you've got a positive feedback loop.\n\nIt's the same as self-driving cars. Humans learn to trust the system, relax, and then it's all fine until it's not. I do think we'll eventually get to a good place, but right now we're in the gap between two worlds, and that's when the damage happens."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03GBV8B58V",
        "type": "message",
        "ts": "1670240604.404989",
        "client_msg_id": "342abdc3-b6df-4e6f-8109-afeac43acb99",
        "text": "The thread that inspired this: <https:\/\/twitter.com\/v21\/status\/1599571365556006915>",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "3e8345518ba8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-05-21\/3558879757875_3e8345518ba82b825c6d_72.jpg",
            "first_name": "Jim",
            "real_name": "Jim Meyer",
            "display_name": "Jim Meyer",
            "team": "T5TCAFTA9",
            "name": "jimkyndemeyer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "attachments": [
            {
                "from_url": "https:\/\/twitter.com\/v21\/status\/1599571365556006915",
                "ts": 1670202506,
                "id": 1,
                "original_url": "https:\/\/twitter.com\/v21\/status\/1599571365556006915",
                "fallback": "<https:\/\/twitter.com\/v21|@v21>: it seems very possible that we are now exiting the brief window where a good fraction of all of human knowledge was searchable &amp; instantly available. a window that starts with the invention of the search engine &amp; ends with the invention of large language models.",
                "text": "it seems very possible that we are now exiting the brief window where a good fraction of all of human knowledge was searchable &amp; instantly available. a window that starts with the invention of the search engine &amp; ends with the invention of large language models.",
                "author_name": "v buckenham",
                "author_link": "https:\/\/twitter.com\/v21\/status\/1599571365556006915",
                "author_icon": "https:\/\/pbs.twimg.com\/profile_images\/1390755064688660490\/PijO-E7W_normal.jpg",
                "author_subname": "@v21",
                "service_name": "twitter",
                "service_url": "https:\/\/twitter.com\/",
                "footer": "Twitter",
                "footer_icon": "https:\/\/a.slack-edge.com\/80588\/img\/services\/twitter_pixel_snapped_32.png"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "BtG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The thread that inspired this: "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/twitter.com\/v21\/status\/1599571365556006915"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U018S42NMMM",
        "type": "message",
        "ts": "1670240775.411709",
        "edited": {
            "user": "U018S42NMMM",
            "ts": "1670240867.000000"
        },
        "client_msg_id": "876498ae-1cc4-441a-bdde-de0d3e05f39a",
        "text": "Speaking only as a developer, we _cannot_ accept code that just looks correct because we have quality review infra in place. Any code needs to pass the test cases. Can it pass test cases while being incorrect? May be, but then that's equally likely with a human.\n\nSo, generated code is fine. But *generated prose* is a different matter. We will need accuracy-checker, bullshit-checker etc kind of systems.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "972d4c887a7c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-10\/4782052692709_972d4c887a7c689aae4a_72.jpg",
            "first_name": "",
            "real_name": "Nilesh Trivedi",
            "display_name": "Nilesh Trivedi",
            "team": "T5TCAFTA9",
            "name": "nilesh.tr",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "g621I",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Speaking only as a developer, we "
                            },
                            {
                                "type": "text",
                                "text": "cannot",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " accept code that just looks correct because we have quality review infra in place. Any code needs to pass the test cases. Can it pass test cases while being incorrect? May be, but then that's equally likely with a human.\n\nSo, generated code is fine. But "
                            },
                            {
                                "type": "text",
                                "text": "generated prose",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " is a different matter. We will need accuracy-checker, bullshit-checker etc kind of systems."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03GBV8B58V",
        "type": "message",
        "ts": "1670240868.058109",
        "edited": {
            "user": "U03GBV8B58V",
            "ts": "1670240886.000000"
        },
        "client_msg_id": "2271847c-af15-44f6-8bf0-2192dfd43706",
        "text": "How will the AI know the difference between well-tested code and code that's not during its training?",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "3e8345518ba8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-05-21\/3558879757875_3e8345518ba82b825c6d_72.jpg",
            "first_name": "Jim",
            "real_name": "Jim Meyer",
            "display_name": "Jim Meyer",
            "team": "T5TCAFTA9",
            "name": "jimkyndemeyer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "5cQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "How will the AI know the difference between well-tested code and code that's not during its training?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U018S42NMMM",
        "type": "message",
        "ts": "1670240984.234009",
        "client_msg_id": "9f8809e4-3ebe-4595-b281-a5d1b453fc32",
        "text": "Not the AI, but the AI training team will very likely put quality filters for the training set. Instead of training on entire github or stackoverflow, you only train on the highly-rated repos or answers.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "972d4c887a7c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-10\/4782052692709_972d4c887a7c689aae4a_72.jpg",
            "first_name": "",
            "real_name": "Nilesh Trivedi",
            "display_name": "Nilesh Trivedi",
            "team": "T5TCAFTA9",
            "name": "nilesh.tr",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "E9pC",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Not the AI, but the AI training team will very likely put quality filters for the training set. Instead of training on entire github or stackoverflow, you only train on the highly-rated repos or answers."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U03GBV8B58V",
        "type": "message",
        "ts": "1670241124.331109",
        "client_msg_id": "559eb913-6934-4bea-9166-181b35add875",
        "text": "I see your point, but highly-rated is a simple metric, that might be more related to popularity\/hype than code-quality\/correctness. It's a super difficult problem.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "3e8345518ba8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-05-21\/3558879757875_3e8345518ba82b825c6d_72.jpg",
            "first_name": "Jim",
            "real_name": "Jim Meyer",
            "display_name": "Jim Meyer",
            "team": "T5TCAFTA9",
            "name": "jimkyndemeyer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "=h5P",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I see your point, but highly-rated is a simple metric, that might be more related to popularity\/hype than code-quality\/correctness. It's a super difficult problem."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U018S42NMMM",
        "type": "message",
        "ts": "1670241252.681229",
        "client_msg_id": "078d2750-1d2a-4a2c-b962-fc31eb945746",
        "text": "My point is, when it comes to code, the vicious cycle of bad quality content -&gt; bad model -&gt; bad quality content is just not there. Because our quality\/rating systems work.\n\nFor prose, yes, this is absolutely true.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "972d4c887a7c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-10\/4782052692709_972d4c887a7c689aae4a_72.jpg",
            "first_name": "",
            "real_name": "Nilesh Trivedi",
            "display_name": "Nilesh Trivedi",
            "team": "T5TCAFTA9",
            "name": "nilesh.tr",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3b5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "My point is, when it comes to code, the vicious cycle of bad quality content -> bad model -> bad quality content is just not there. Because our quality\/rating systems work.\n\nFor prose, yes, this is absolutely true."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03GBV8B58V",
        "type": "message",
        "ts": "1670241304.171919",
        "client_msg_id": "bd58ae94-0338-493a-889a-f96f2ff5c147",
        "text": "Interesting. I think code and prose are the same in that regard :smile:",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "3e8345518ba8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-05-21\/3558879757875_3e8345518ba82b825c6d_72.jpg",
            "first_name": "Jim",
            "real_name": "Jim Meyer",
            "display_name": "Jim Meyer",
            "team": "T5TCAFTA9",
            "name": "jimkyndemeyer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RcLU",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Interesting. I think code and prose are the same in that regard "
                            },
                            {
                                "type": "emoji",
                                "name": "smile",
                                "unicode": "1f604"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U018S42NMMM",
        "type": "message",
        "ts": "1670241558.697079",
        "client_msg_id": "e5bb093c-20b5-45d2-8198-a762a9cf8c8b",
        "text": "Not really. Spam on the web is mostly prose. There are both incentives as well as lack of quality filter tools. Nobody is spamming github with incorrect code.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "972d4c887a7c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-10\/4782052692709_972d4c887a7c689aae4a_72.jpg",
            "first_name": "",
            "real_name": "Nilesh Trivedi",
            "display_name": "Nilesh Trivedi",
            "team": "T5TCAFTA9",
            "name": "nilesh.tr",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tgq",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Not really. Spam on the web is mostly prose. There are both incentives as well as lack of quality filter tools. Nobody is spamming github with incorrect code."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03GBV8B58V",
        "type": "message",
        "ts": "1670242095.570469",
        "client_msg_id": "d7694ba1-3fe8-4823-bcc7-7e458efaabcb",
        "text": "Ah, yep, agreed. they're different in terms of scale and incentives.\n\nI was thinking from a more fundamental level: Quality assurance of language content at scale (both code and prose are symbolic, and use\/construct abstractions). They're similar problems in that regard, but we might be lucky that the incentives make training on code a less complicated practical problem.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "3e8345518ba8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-05-21\/3558879757875_3e8345518ba82b825c6d_72.jpg",
            "first_name": "Jim",
            "real_name": "Jim Meyer",
            "display_name": "Jim Meyer",
            "team": "T5TCAFTA9",
            "name": "jimkyndemeyer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xoJDS",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Ah, yep, agreed. they're different in terms of scale and incentives.\n\nI was thinking from a more fundamental level: Quality assurance of language content at scale (both code and prose are symbolic, and use\/construct abstractions). They're similar problems in that regard, but we might be lucky that the incentives make training on code a less complicated practical problem."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U018S42NMMM",
        "type": "message",
        "ts": "1670242165.099499",
        "client_msg_id": "8d8daac1-517b-4f0f-a19c-dfbb7fbb37dd",
        "text": "Meanwhile, StackOverflow has temporarily banned answers by ChatGPT because they're too inaccurate: <https:\/\/meta.stackoverflow.com\/questions\/421831\/temporary-policy-chatgpt-is-banned>",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "972d4c887a7c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-10\/4782052692709_972d4c887a7c689aae4a_72.jpg",
            "first_name": "",
            "real_name": "Nilesh Trivedi",
            "display_name": "Nilesh Trivedi",
            "team": "T5TCAFTA9",
            "name": "nilesh.tr",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WUp+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Meanwhile, StackOverflow has temporarily banned answers by ChatGPT because they're too inaccurate: "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/meta.stackoverflow.com\/questions\/421831\/temporary-policy-chatgpt-is-banned"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03GBV8B58V",
        "type": "message",
        "ts": "1670242186.521569",
        "client_msg_id": "3f653232-ba23-4000-bce1-b57ccdad064a",
        "text": "Haha, yep it sure is confident, even while wrong :smile:",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "3e8345518ba8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-05-21\/3558879757875_3e8345518ba82b825c6d_72.jpg",
            "first_name": "Jim",
            "real_name": "Jim Meyer",
            "display_name": "Jim Meyer",
            "team": "T5TCAFTA9",
            "name": "jimkyndemeyer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "CfbBm",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Haha, yep it sure is confident, even while wrong "
                            },
                            {
                                "type": "emoji",
                                "name": "smile",
                                "unicode": "1f604"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03GBV8B58V",
        "type": "message",
        "ts": "1670242985.762439",
        "edited": {
            "user": "U03GBV8B58V",
            "ts": "1670242998.000000"
        },
        "client_msg_id": "a7cc92c3-bcd0-40cf-a762-37735ba5db5c",
        "text": "This actually feeds back to my initial worry. Code alone is not enough to train systems like ChatGTP. It won't know how to map natural language onto code. That comes from training on sources like StackOverflow. See how this spam makes prose and code not so different? The social systems and incentives do appear to have some overlap. This policy change is needed, but difficult to enforce at scale. Same as QA'ing spam\/prose because it requires a lot of effort to know whether something is a good answer.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "3e8345518ba8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-05-21\/3558879757875_3e8345518ba82b825c6d_72.jpg",
            "first_name": "Jim",
            "real_name": "Jim Meyer",
            "display_name": "Jim Meyer",
            "team": "T5TCAFTA9",
            "name": "jimkyndemeyer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hX7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This actually feeds back to my initial worry. Code alone is not enough to train systems like ChatGTP. It won't know how to map natural language onto code. That comes from training on sources like StackOverflow. See how this spam makes prose and code not so different? The social systems and incentives do appear to have some overlap. This policy change is needed, but difficult to enforce at scale. Same as QA'ing spam\/prose because it requires a lot of effort to know whether something is a good answer."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U03GBV8B58V",
        "type": "message",
        "ts": "1670243084.896449",
        "client_msg_id": "872917e7-1787-462d-9d85-1aa5264ed451",
        "text": "Humans talking about code -&gt; Social systems\/incentives -&gt; Humans gaming the systems with AI",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "3e8345518ba8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-05-21\/3558879757875_3e8345518ba82b825c6d_72.jpg",
            "first_name": "Jim",
            "real_name": "Jim Meyer",
            "display_name": "Jim Meyer",
            "team": "T5TCAFTA9",
            "name": "jimkyndemeyer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "D41C",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Humans talking about code -> Social systems\/incentives -> Humans gaming the systems with AI"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJFN50C00",
        "type": "message",
        "ts": "1670254714.236239",
        "client_msg_id": "91BE760B-1D4C-4777-8EF3-E392FE7E4F46",
        "text": "Ah there things like that:\n<https:\/\/twitter.com\/swardley\/status\/1599182593383190529|https:\/\/twitter.com\/swardley\/status\/1599182593383190529>",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e35958b94f07",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-05-06\/616300651267_e35958b94f07da17cf17_72.png",
            "first_name": "Andreas",
            "real_name": "Andreas S.",
            "display_name": "curious_reader",
            "team": "T5TCAFTA9",
            "name": "andreas.scheinert",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670152748.796319",
        "parent_user_id": "UJFN50C00",
        "attachments": [
            {
                "from_url": "https:\/\/twitter.com\/swardley\/status\/1599182593383190529",
                "ts": 1670109816,
                "image_url": "https:\/\/pbs.twimg.com\/media\/FjFvzkvXEAEXQ1h.jpg",
                "image_width": 807,
                "image_height": 223,
                "image_bytes": 45666,
                "id": 1,
                "original_url": "https:\/\/twitter.com\/swardley\/status\/1599182593383190529",
                "fallback": "<https:\/\/twitter.com\/swardley|@swardley>: X : Do you think it could lie?\nMe : I spent 20 minutes with ChatGPT telling me something that was clearly untrue and constantly pretending the quotes it was making up about an article came from the article. Sure, ChatGPT will lie. Just like people.",
                "text": "X : Do you think it could lie?\nMe : I spent 20 minutes with ChatGPT telling me something that was clearly untrue and constantly pretending the quotes it was making up about an article came from the article. Sure, ChatGPT will lie. Just like people.",
                "author_name": "Simon Wardley",
                "author_link": "https:\/\/twitter.com\/swardley\/status\/1599182593383190529",
                "author_icon": "https:\/\/pbs.twimg.com\/profile_images\/180727117\/Simon_normal.jpg",
                "author_subname": "@swardley",
                "service_name": "twitter",
                "service_url": "https:\/\/twitter.com\/",
                "footer": "Twitter",
                "footer_icon": "https:\/\/a.slack-edge.com\/80588\/img\/services\/twitter_pixel_snapped_32.png"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "vbllI",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Ah"
                            },
                            {
                                "type": "text",
                                "text": " there things like that:\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/twitter.com\/swardley\/status\/1599182593383190529",
                                "text": "https:\/\/twitter.com\/swardley\/status\/1599182593383190529"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UNS7QDKFV",
        "type": "message",
        "ts": "1670258014.203649",
        "client_msg_id": "18c5e26b-5627-4483-98a3-3721bec396c5",
        "text": "AI systems based on large language models are prone to human-like errors, both in solving logic puzzles and in writing program code.  Which gives me less confidence in code review as a quality check on AI-written code - both the AI and the human are okay with code that \"looks good\".   The advances in the scientific method come from developing techniques to work around limitations and drawbacks in human reasoning.  We'll need to apply these (and new ones) to AI systems.   In my view, the test suite is going to be the most important part of the code base, since an AI will write the code. (Until the AI's can write the test suite as well :slightly_smiling_face: ).",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "gbc993d98fe7",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/bc993d98fe7bf26c048ac0818a598d4d.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "Mark Dewing",
            "display_name": "Mark Dewing",
            "team": "T5TCAFTA9",
            "name": "markdewing",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1670240076.951139",
        "parent_user_id": "U03GBV8B58V",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "iii6u",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "AI systems based on large language models are prone to human-like errors, both in solving logic puzzles and in writing program code.  Which gives me less confidence in code review as a quality check on AI-written code - both the AI and the human are okay with code that \"looks good\".   The advances in the scientific method come from developing techniques to work around limitations and drawbacks in human reasoning.  We'll need to apply these (and new ones) to AI systems.   In my view, the test suite is going to be the most important part of the code base, since an AI will write the code. (Until the AI's can write the test suite as well "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            },
                            {
                                "type": "text",
                                "text": " )."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]