[
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1714549747.103569",
        "client_msg_id": "f8e1e8d4-36f0-4e59-b787-048f20bd5607",
        "text": "<@U5STGTB3J> <@U06BUK2M2RH> Thanks a lot for your feedback! Gibson's affordances are definitely a concept I should refer to. There's a difference, however, which matters to me: my notion of comprehensibility includes not only \"what can this tool do for me\" but also \"does this tool do anything behind my back that I am not aware of\".  Spyware would be the obvious case but I have also seen many well-meant small automatisations in computational science that turned out to be in contradiction to the expectations of some users.\n\nThe relationality of the concept is very much intended. It may well be interesting as well to judge the amount of information that a system makes accessible independently of what the observer can make of it, but for now I prefer to concentrate on the human-computer interaction aspect.\n\n<@U5STGTB3J> I just re-read the essays you referred to. Good observations, there's definitely a \"sweet spot\" in complexity, rather than \"the less the better\". On the other hand, for the specific case of symbolic reasoning (mathematics, software), I can't come up with an example for \"too boring because not complex enough\". Elegance in mathematics has always been about minimalism, even though different people value different aspects of it differently (e.g. size of a symbolic expression vs. number\/complexity of the definitions and theorems required to support it).",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714490368.887299",
        "parent_user_id": "UJBAJNFLK",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "wnbVR",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U5STGTB3J"
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "user",
                                "user_id": "U06BUK2M2RH"
                            },
                            {
                                "type": "text",
                                "text": " Thanks a lot for your feedback! Gibson's affordances are definitely a concept I should refer to. There's a difference, however, which matters to me: my notion of comprehensibility includes not only \"what can this tool do for me\" but also \"does this tool do anything behind my back that I am not aware of\".  Spyware would be the obvious case but I have also seen many well-meant small automatisations in computational science that turned out to be in contradiction to the expectations of some users.\n\nThe relationality of the concept is very much intended. It may well be interesting as well to judge the amount of information that a system makes accessible independently of what the observer can make of it, but for now I prefer to concentrate on the human-computer interaction aspect.\n\n"
                            },
                            {
                                "type": "user",
                                "user_id": "U5STGTB3J"
                            },
                            {
                                "type": "text",
                                "text": " I just re-read the essays you referred to. Good observations, there's definitely a \"sweet spot\" in complexity, rather than \"the less the better\". On the other hand, for the specific case of symbolic reasoning (mathematics, software), I can't come up with an example for \"too boring because not complex enough\". Elegance in mathematics has always been about minimalism, even though different people value different aspects of it differently (e.g. size of a symbolic expression vs. number\/complexity of the definitions and theorems required to support it)."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U5STGTB3J",
        "type": "message",
        "ts": "1714579801.713009",
        "client_msg_id": "9590d70c-af42-4523-9f80-f4cdddc5ac63",
        "text": "<@UJBAJNFLK> This is super interesting to me, sorry if I take this somewhere weird or not that interesting from your perspective:\n\nWhen I think of intuition in mathematics, I imagine things like understanding the term rewriting steps of the proof of say Pythagoras’ Theorem through symbol manipulation as an analytical\/mechanical understanding. Whereas I’d say understanding a geometric proof of the same theorem is at least utilizing some of our intuitive\/experiential understanding.\n\nWhile I’m at it, let me add another example from another domain I know little about. :slightly_smiling_face: The way I understand moldable development I would assume that you relatively quickly notice that the same data structure with the same data in it in different visualizations has a vast range of how easy\/difficult the data and its structure can be interpreted and understood. So in your words, if I understand correctly, some of those representations have a larger _cognitive surface_ than others.\n\nI just wonder, and would love to hear your thoughts on this: In mathematics, is it really the nature of mathematics, or more specifically the nature of formal systems and reasoning, that it is just about mechanical\/analytical complexity, or have we just settled on a default representation that primarily _affords_ mechanical\/analytical reasoning and understanding? And as a consequence we (are led to) ignore (overlook?) intuitive aspects of it?\n\nAsking for a tech philosopher who is worried that in software development we are doing exactly the same…",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "649181907e06",
            "image_72": "https:\/\/avatars.slack-edge.com\/2017-08-20\/228447816352_649181907e06ec450c64_72.jpg",
            "first_name": "Stefan",
            "real_name": "Stefan Lesser",
            "display_name": "Stefan",
            "team": "T5TCAFTA9",
            "name": "stefanlesser",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714490368.887299",
        "parent_user_id": "UJBAJNFLK",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "sr41V",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UJBAJNFLK"
                            },
                            {
                                "type": "text",
                                "text": " This is super interesting to me, sorry if I take this somewhere weird or not that interesting from your perspective:\n\nWhen I think of intuition in mathematics, I imagine things like understanding the term rewriting steps of the proof of say Pythagoras’ Theorem through symbol manipulation as an analytical\/mechanical understanding. Whereas I’d say understanding a geometric proof of the same theorem is at least utilizing some of our intuitive\/experiential understanding.\n\nWhile I’m at it, let me add another example from another domain I know little about. "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            },
                            {
                                "type": "text",
                                "text": " The way I understand moldable development I would assume that you relatively quickly notice that the same data structure with the same data in it in different visualizations has a vast range of how easy\/difficult the data and its structure can be interpreted and understood. So in your words, if I understand correctly, some of those representations have a larger "
                            },
                            {
                                "type": "text",
                                "text": "cognitive surface",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " than others.\n\nI just wonder, and would love to hear your thoughts on this: In mathematics, is it really the nature of mathematics, or more specifically the nature of formal systems and reasoning, that it is just about mechanical\/analytical complexity, or have we just settled on a default representation that primarily "
                            },
                            {
                                "type": "text",
                                "text": "affords",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " mechanical\/analytical reasoning and understanding? And as a consequence we (are led to) ignore (overlook?) intuitive aspects of it?\n\nAsking for a tech philosopher who is worried that in software development we are doing exactly the same…"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1714589783.753059",
        "client_msg_id": "fd344043-e2d6-4746-8b71-c819d755b80f",
        "text": "<@U5STGTB3J> Lots of good questions...\n\nEasy one first: yes, I do believe that different visualizations of the same data structure have different cognitive surfaces, but this depends on the application context and not just on the data structure.\n\nIf you talk to professional mathematicians, they regularly point out the importance of intuition in their work. In particular the discovery of interesting relations is mostly a matter of intuition. Formal systems have two roles: (1) supporting intuition for filling in the details, and (2) constructing proofs. Proofs are extremely important because they allow to convert the intuition of individuals into collectively accepted knowledge. That's also why the mathematical literature heavily emphasizes formal approaches.\n\nComputing has inherited this tradition, via Church, Turing, and others. It's not just a matter of symbolic representation affording this type of reasoning, I'd say it's baked even into our hardware. There are lots of different ways to process information. Biological organisms process information contextually, meaning informally. With AI we are making first steps into technological information processing that is contextual rather then formal. I guess we will see more of that. But I also believe that symbolic reasoning in the tradition of mathematics is here to stay. It's just too useful.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714490368.887299",
        "parent_user_id": "UJBAJNFLK",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "f7hNB",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U5STGTB3J"
                            },
                            {
                                "type": "text",
                                "text": " Lots of good questions...\n\nEasy one first: yes, I do believe that different visualizations of the same data structure have different cognitive surfaces, but this depends on the application context and not just on the data structure.\n\nIf you talk to professional mathematicians, they regularly point out the importance of intuition in their work. In particular the discovery of interesting relations is mostly a matter of intuition. Formal systems have two roles: (1) supporting intuition for filling in the details, and (2) constructing proofs. Proofs are extremely important because they allow to convert the intuition of individuals into collectively accepted knowledge. That's also why the mathematical literature heavily emphasizes formal approaches.\n\nComputing has inherited this tradition, via Church, Turing, and others. It's not just a matter of symbolic representation affording this type of reasoning, I'd say it's baked even into our hardware. There are lots of different ways to process information. Biological organisms process information contextually, meaning informally. With AI we are making first steps into technological information processing that is contextual rather then formal. I guess we will see more of that. But I also believe that symbolic reasoning in the tradition of mathematics is here to stay. It's just too useful."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U5STGTB3J",
        "type": "message",
        "ts": "1714592465.902259",
        "client_msg_id": "6840b21b-f875-4d57-890e-3890a2e9c26c",
        "text": "Oh, yes, it’s not either-or. Symbolic reasoning isn’t bad or wrong, it is obviously useful. It’s more like a “too much of a good thing…” situation, as we neglect other important things.\n\nPolarization also comes primarily from analytic thinking: If there are two polar opposites, it must mean either or, as if we can pick only one. But (1) in complex systems polar opposites are just a model, an oversimplified approximation of what’s really going on, and (2) it’s about… well… some people would use the word balance, you used the term “sweet spot”, but that’s still too static. It’s a dynamic context-dependent balance that can be different based on context, so we need more than just intelligence to know what we’re talking about, but also the wisdom to decide how much of each is needed in which situation.\n\nContext, however, is what we usually try to avoid; in science in favor of discovering context-independent _universal_ rules, and in programming in favor of reuse and scale. I’m optimistic though, as it seems that we slowly wake up to the limitations of trying to brute-force everything with pure logical reasoning and as little context as we get away with. Maybe that’s just because I’m reading <https:\/\/mitpress.mit.edu\/author\/alicia-juarrero-3467\/|this> at the moment…",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "649181907e06",
            "image_72": "https:\/\/avatars.slack-edge.com\/2017-08-20\/228447816352_649181907e06ec450c64_72.jpg",
            "first_name": "Stefan",
            "real_name": "Stefan Lesser",
            "display_name": "Stefan",
            "team": "T5TCAFTA9",
            "name": "stefanlesser",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714490368.887299",
        "parent_user_id": "UJBAJNFLK",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "eZO\/1",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Oh, yes, it’s not either-or. Symbolic reasoning isn’t bad or wrong, it is obviously useful. It’s more like a “too much of a good thing…” situation, as we neglect other important things.\n\nPolarization also comes primarily from analytic thinking: If there are two polar opposites, it must mean either or, as if we can pick only one. But (1) in complex systems polar opposites are just a model, an oversimplified approximation of what’s really going on, and (2) it’s about… well… some people would use the word balance, you used the term “sweet spot”, but that’s still too static. It’s a dynamic context-dependent balance that can be different based on context, so we need more than just intelligence to know what we’re talking about, but also the wisdom to decide how much of each is needed in which situation.\n\nContext, however, is what we usually try to avoid; in science in favor of discovering context-independent "
                            },
                            {
                                "type": "text",
                                "text": "universal",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " rules, and in programming in favor of reuse and scale. I’m optimistic though, as it seems that we slowly wake up to the limitations of trying to brute-force everything with pure logical reasoning and as little context as we get away with. Maybe that’s just because I’m reading "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/mitpress.mit.edu\/author\/alicia-juarrero-3467\/",
                                "text": "this"
                            },
                            {
                                "type": "text",
                                "text": " at the moment…"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U5STGTB3J",
        "type": "message",
        "ts": "1714593949.269889",
        "edited": {
            "user": "U5STGTB3J",
            "ts": "1714593979.000000"
        },
        "client_msg_id": "47ddc60e-5dcf-452e-aed7-c3f2b7ca7c36",
        "text": "Oh, and if that wasn’t clear, I’m also optimistic because I read your post pointing out the importance of context, the relational nature of comprehensibility, and potential issues with epistemic opacity. _Did you just add that? Miraculously, I hadn’t heard this term before, otherwise I probably would’ve used it in half of my writing._",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "649181907e06",
            "image_72": "https:\/\/avatars.slack-edge.com\/2017-08-20\/228447816352_649181907e06ec450c64_72.jpg",
            "first_name": "Stefan",
            "real_name": "Stefan Lesser",
            "display_name": "Stefan",
            "team": "T5TCAFTA9",
            "name": "stefanlesser",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714490368.887299",
        "parent_user_id": "UJBAJNFLK",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "1YAaK",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Oh, and if that wasn’t clear, I’m also optimistic because I read your post pointing out the importance of context, the relational nature of comprehensibility, and potential issues with epistemic opacity. "
                            },
                            {
                                "type": "text",
                                "text": "Did you just add that? Miraculously, I hadn’t heard this term before, otherwise I probably would’ve used it in half of my writing.",
                                "style": {
                                    "italic": true
                                }
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U5STGTB3J",
        "type": "message",
        "ts": "1714595484.467759",
        "client_msg_id": "9865a449-e1c0-48c6-8f3c-81fadc256743",
        "text": "Fascinating! The segregation between scientifically so closely related domains is mind-boggling. Turns out there is a subset of computer science that reinvents a subset of cognitive science. And judging from the list of references they have never heard of each other, which explains the different terms used. Also explains why I never came across any of these interesting sounding papers. This is wild! I now believe in parallel universes.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "649181907e06",
            "image_72": "https:\/\/avatars.slack-edge.com\/2017-08-20\/228447816352_649181907e06ec450c64_72.jpg",
            "first_name": "Stefan",
            "real_name": "Stefan Lesser",
            "display_name": "Stefan",
            "team": "T5TCAFTA9",
            "name": "stefanlesser",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714490368.887299",
        "parent_user_id": "UJBAJNFLK",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "\/AVKD",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Fascinating! The segregation between scientifically so closely related domains is mind-boggling. Turns out there is a subset of computer science that reinvents a subset of cognitive science. And judging from the list of references they have never heard of each other, which explains the different terms used. Also explains why I never came across any of these interesting sounding papers. This is wild! I now believe in parallel universes."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05TJD2V4P2",
        "type": "message",
        "ts": "1714609418.045629",
        "client_msg_id": "c57f3992-51ff-4b2e-8a6e-cd496c4216ae",
        "text": "I used to TA a compiler\/PL design course and we would tell students that using their language should feel more like verbs than nouns.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "c62c43b01fd5",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-09-18\/5926088433521_c62c43b01fd5b63ec214_72.jpg",
            "first_name": "Jacob",
            "real_name": "Jacob Zimmerman",
            "display_name": "Jacob Zimmerman",
            "team": "T5TCAFTA9",
            "name": "jacob.zimmerman135",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714062480.601149",
        "parent_user_id": "U04JY2BF24E",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "TkOvZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I used to TA a compiler\/PL design course and we would tell students that using their language should feel more like verbs than nouns."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "eyes",
                "users": [
                    "U04JY2BF24E"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UJBAJNFLK",
        "type": "message",
        "ts": "1714628574.599479",
        "edited": {
            "user": "UJBAJNFLK",
            "ts": "1714662928.000000"
        },
        "client_msg_id": "0611eb15-2067-4a51-ae1e-d88185215227",
        "text": "By now I could compile a book listing parallel universes in research. Everyone talks about \"interdisciplinary\", and yet the dividing lines between disciplines are stronger than ever before.\n\nIt looks like we pretty much agree on the importance of context and the limitations of formal reasoning. And my impression is that that's where many disciplines are heading, each at its own pace. It goes well with another slow movement I am seeing towards perspectival realism as a philosophical basis for science.",
        "team": "T5TCAFTA9",
        "user_team": "T5TCAFTA9",
        "source_team": "T5TCAFTA9",
        "user_profile": {
            "avatar_hash": "e169f54bbaf8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-03-12\/1859691333940_e169f54bbaf8b9b36b12_72.png",
            "first_name": "Konrad",
            "real_name": "Konrad Hinsen",
            "display_name": "Konrad Hinsen",
            "team": "T5TCAFTA9",
            "name": "konrad.hinsen",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714490368.887299",
        "parent_user_id": "UJBAJNFLK",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "syP6e",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "By now I could compile a book listing parallel universes in research. Everyone talks about \"interdisciplinary\", and yet the dividing lines between disciplines are stronger than ever before.\n\nIt looks like we pretty much agree on the importance of context and the limitations of formal reasoning. And my impression is that that's where many disciplines are heading, each at its own pace. It goes well with another slow movement I am seeing towards perspectival realism as a philosophical basis for science."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]