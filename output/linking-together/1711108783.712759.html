<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #linking-together</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <img src="https://avatars.slack-edge.com/2017-08-20/228447816352_649181907e06ec450c64_72.jpg" style="float:left"/>
      <a href="../linking-together/1711108783.712759.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Stefan Lesser</b>
<span style="margin:2em; color:#606060">2024-03-22 04:59</span><br/>
Some speculation by <span style="background-color:#ccf">@Matt Webb</span> about <a href="https://interconnected.org/home/2024/03/20/agents">the not so far out future of AI agents</a> and how we can/need to prepare for it. <br/>In the other corner, some judgy comments about <a href="https://www.garbageday.email/p/clout-world">AI’s Looming Reputation Crisis</a> (scroll down to the middle to find that bit).<br/><br/>I read both this morning and I know these are different use cases, however they beautifully cover the whole optimism/pessimism spectrum on AI.<br/><br/>Where do people here fall on that spectrum? Are there use cases that are obviously good/bad, or does that depend on… well… what? And are we going to outsource most of our lives soon to AI assistants while simultaneously drowning in mediocre generated bullsh*t trying to scam us?<br/><br/>Gosh, I miss the time of the early internet when I was excited about everything tech. Somehow I can’t find back into that mindset these days. Can someone convince me that the future is going to be universally great, like it used to be 20 years ago?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1711114305.996379"></a>
      <img src="https://avatars.slack-edge.com/2018-12-18/508431502471_8073c43d5d8dd3d3b4b2_72.jpg" style="float:left"/>
      <a href="../linking-together/1711108783.712759.html#1711114305.996379" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Duncan Cragg</b>
<span style="margin:2em; color:#606060">2024-03-22 06:31</span><br/>
I was blown away by the sudden appearance and then rapid development of AI, having followed the field at a medium distance all my life. But, like cryptocurrencies, I quickly filed it into "interesting, follow quite closely, not my core thing"
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1711114335.348539"></a>
      <img src="https://avatars.slack-edge.com/2018-12-18/508431502471_8073c43d5d8dd3d3b4b2_72.jpg" style="float:left"/>
      <a href="../linking-together/1711108783.712759.html#1711114335.348539" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Duncan Cragg</b>
<span style="margin:2em; color:#606060">2024-03-22 06:32</span><br/>
I do get that excitement with "my core thing", though!
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1711130279.535749"></a>
      <img src="https://avatars.slack-edge.com/2019-03-21/584465935395_b7c63cc07373326ec6ea_72.jpg" style="float:left"/>
      <a href="../linking-together/1711108783.712759.html#1711130279.535749" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Shalabh</b>
<span style="margin:2em; color:#606060">2024-03-22 10:57</span><br/>
I've generally been skeptical of AI/ML but have come around a little bit. I've been very impressed with some specific applications, eg image and text generation, pattern recognition, etc.<br/><br/>In applications that need rigor, I'm very skeptical and actually think an ML based approach is completely backwards. Specifically for things like coding, engineering, maths and so on, a foundation of statistical correlation based on pre-existing text is... completely wrong (and why this is not blindingly obvious to everyone remains a mystery to me). You want to start with a semantic (not statistical) model. In any case I do find it easier to ask chatgpt about how to use an api for a specific purpose, and then validate that it actually works. People say LLMs sometimes hallucinate but in reality they <em>only</em> hallucinate: is just so happens the hallucination sometimes matches reality.<br/><br/>Side notes:<br/>I really don't like that the model makers dont reveal their training data. <em>Release your training data you cowards!</em> <br/><br/>AI/ML in decision making may help humans shrug away responsibility, which is also a major concern and I think we should stop talking about it as a magical entity that's different from a typical program. I think 'automation' is a great word, suggested by Emily Bender in this video: <a href="https://www.youtube.com/watch?v=eK0md9tQ1KY">https://www.youtube.com/watch?v=eK0md9tQ1KY</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1711147147.783859"></a>
      <img src="https://avatars.slack-edge.com/2018-12-18/508431502471_8073c43d5d8dd3d3b4b2_72.jpg" style="float:left"/>
      <a href="../linking-together/1711108783.712759.html#1711147147.783859" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Duncan Cragg</b>
<span style="margin:2em; color:#606060">2024-03-22 15:39</span><br/>
&gt; People say LLMs sometimes hallucinate but in reality they <em>only</em> hallucinate: is just so happens the hallucination sometimes matches reality.<br/>Well the same can be said of the human mind: the abstraction of our senses to our conscious experience is a hallucination that is tightly constrained by incoming sense input. When we dream (or, well, when we hallucinate), those constraints are absent.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1711150928.222419"></a>
      <img src="https://avatars.slack-edge.com/2019-03-21/584465935395_b7c63cc07373326ec6ea_72.jpg" style="float:left"/>
      <a href="../linking-together/1711108783.712759.html#1711150928.222419" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Shalabh</b>
<span style="margin:2em; color:#606060">2024-03-22 16:42</span><br/>
fair point. I guess hallucination is the wrong word to use here because it implies a kind of perception.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1718720289.514349"></a>
      <img src="https://avatars.slack-edge.com/2023-09-18/5922641047217_60e6ebbc4a9a68a57656_72.png" style="float:left"/>
      <a href="../linking-together/1711108783.712759.html#1718720289.514349" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Alex McLean</b>
<span style="margin:2em; color:#606060">2024-06-18 07:18</span><br/>
I am also reserving my human right not to be interested in AI
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
