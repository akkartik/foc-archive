<html>
<head><meta charset="UTF-8"></head><h2>Archives, <a href="https://futureofcoding.org/community">Future of Coding Community</a>, #thinking-together</h2>
  <table>
  <tr>
    <td style="width:72px; vertical-align:top; padding-bottom:1em">
      <img src="https://avatars.slack-edge.com/2019-05-06/616300651267_e35958b94f07da17cf17_72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Andreas S.</b>
<span style="margin:2em; color:#606060">2022-12-04 03:19</span><br/>
Hello :wave: everyone,<br/>As you may have noticed but also <span style="background-color:#ccf">@William Taysom</span> showed in another channel, Open AI - Chat Gpt seems to generate a lot of buzz. <br/><a href="https://twitter.com/rshoukhin/status/1598714847255855108">https://twitter.com/rshoukhin/status/1598714847255855108</a><br/>Looking at this I’m questioning myself if “framework” rewrites will be less common in the industry now?<br/>Will it have a deeper impact than this?<br/>Is this a development in the lines of Peter Novig’s - as we may program?<br/><a href="https://vimeo.com/215418110">https://vimeo.com/215418110</a><br/><br/>What are your thoughts :thought_balloon: on this?<br/>Thank you :pray: 
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670207927.978549"></a>
      <img src="https://secure.gravatar.com/avatar/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670207927.978549" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>William Taysom</b>
<span style="margin:2em; color:#606060">2022-12-04 18:38</span><br/>
As I contemplate practical uses of this tech, they seem to center around interfacing with institutions: filling out paperwork, customer support, augmenting websites ("Just renew the library books that are to."  "Order the same groceries that I get every time here."  "When I search for dishwasher detergent, do not show me 'effing laundry detergent.") and probably programming too.<br/><br/>A feedback loop could result in a quick improvement to these systems.  I've just looked at dozens of Twitter threads where people prompt engineer ChatGPT into giving extremely good answers.  Use that as training data and in short order, this software could be as uncanny at answering questions as... as... a well trained 20 question answering AI.  For example <a href="http://www.20q.net/">http://www.20q.net/</a> guessed "koala" correctly with my son a moment ago despite him saying a koala weighs less than a duck and would be a good gift, which 20Q says it did not expect.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670236130.859509"></a>
      <img src="https://avatars.slack-edge.com/2021-03-12/1859691333940_e169f54bbaf8b9b36b12_72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670236130.859509" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Konrad Hinsen</b>
<span style="margin:2em; color:#606060">2022-12-05 02:28</span><br/>
Some random thoughts on this:<br/>1. Programming, like all automation, is an amplifier for decisions. This makes it difficult to foresee the consequences of the decisions, and that is the root cause of all the trouble humanity has had with industrialization and now with computing.<br/>  2. In the interest of safety, decision amplification requires one of<br/>      a. a limited scope of automation (sandboxing, ...)<br/>      b. regular validation of execution by an agent that has an incentive not to do harm (liability, ...)<br/>      c. provable predictability of consequences (matematical proof, ...)<br/><br/>So... which amplifiable decisions can we safely delegate to today's AIs? I'd say none. So the questions becomes: how do AIs need to evolve so that we can safely delegate amplifiable decisions to them?
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670236269.788779"></a>
      <img src="https://avatars.slack-edge.com/2021-03-12/1859691333940_e169f54bbaf8b9b36b12_72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670236269.788779" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Konrad Hinsen</b>
<span style="margin:2em; color:#606060">2022-12-05 02:31</span><br/>
Something we can safely do even now is use AI for generating propositions that are validated by a human programmer. Make AI a replacement for looking up documentation and copy-pasting boilerplate code. But that's not what I see people discussing.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670236812.147459"></a>
      <img src="https://avatars.slack-edge.com/2019-05-06/616300651267_e35958b94f07da17cf17_72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670236812.147459" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Andreas S.</b>
<span style="margin:2em; color:#606060">2022-12-05 02:40</span><br/>
But even making suggestions will influence the end result. But I would agree that there is a strong search for a use case when there is not really one
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670254714.236239"></a>
      <img src="https://avatars.slack-edge.com/2019-05-06/616300651267_e35958b94f07da17cf17_72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670254714.236239" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Andreas S.</b>
<span style="margin:2em; color:#606060">2022-12-05 07:38</span><br/>
Ah there things like that:<br/><a href="https://twitter.com/swardley/status/1599182593383190529">https://twitter.com/swardley/status/1599182593383190529</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670316791.030989"></a>
      <img src="https://avatars.slack-edge.com/2019-05-06/616300651267_e35958b94f07da17cf17_72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670316791.030989" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Andreas S.</b>
<span style="margin:2em; color:#606060">2022-12-06 00:53</span><br/>
And some more this time related to proofs: <a href="https://twitter.com/lmeyerov/status/1599663686884679682">https://twitter.com/lmeyerov/status/1599663686884679682</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670441345.889659"></a>
      <img src="https://avatars.slack-edge.com/2021-09-13/2508698086192_565c54a4fa91a0c8c75a_72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670441345.889659" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Tom Lieber</b>
<span style="margin:2em; color:#606060">2022-12-07 11:29</span><br/>
I’m bullish! ChatGPT has been incredible for the documentation use case <span style="background-color:#ccf">@Konrad Hinsen</span> mentioned, and it’s actually all anyone in my filter bubble is talking about. <a href="https://twitter.com/alltom/status/1600170846190014464?s=46&amp;t=O3eGUBiI0I72J2QcK6b_MQ">https://twitter.com/alltom/status/1600170846190014464</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670441573.280089"></a>
      <img src="https://avatars.slack-edge.com/2021-09-13/2508698086192_565c54a4fa91a0c8c75a_72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670441573.280089" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Tom Lieber</b>
<span style="margin:2em; color:#606060">2022-12-07 11:32</span><br/>
It’s really hard for us to describe our systems to each other. Unrelatable documentation is the main reason I struggle to keep up with FoC projects.<br/><br/>ChatGPT shows that, as long as we can describe them well enough for an AI to understand, the AI has a shot of transforming that information to make it digestible for whoever needs it.
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670441792.724659"></a>
      <img src="https://avatars.slack-edge.com/2021-09-13/2508698086192_565c54a4fa91a0c8c75a_72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670441792.724659" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Tom Lieber</b>
<span style="margin:2em; color:#606060">2022-12-07 11:36</span><br/>
I do think it’s critical to make the answers more grounded. The most tedious part of using ChatGPT today is checking the answers, because it doesn’t show its work! <a href="https://twitter.com/alltom/status/1599742037271937024?s=46&amp;t=O3eGUBiI0I72J2QcK6b_MQ">https://twitter.com/alltom/status/1599742037271937024</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670496674.255509"></a>
      <img src="https://avatars.slack-edge.com/2019-05-06/616300651267_e35958b94f07da17cf17_72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670496674.255509" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>Andreas S.</b>
<span style="margin:2em; color:#606060">2022-12-08 02:51</span><br/>
Half truths on software engineering:<br/><a href="https://twitter.com/grady_booch/status/1600623026730545153">https://twitter.com/grady_booch/status/1600623026730545153</a>
    </td>
  </tr>
  <tr>
    <td style="vertical-align:top; padding-bottom:1em">
      <a name="1670577496.554869"></a>
      <img src="https://secure.gravatar.com/avatar/3ae6d55db9d15b79bc683a8031fc2588.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0009-72.png" style="float:left"/>
      <a href="../thinking-together/1670152748.796319.html#1670577496.554869" style="color:#aaa">#</a>
    </td>
    <td style="vertical-align:top; padding-bottom:1em; padding-left:1em">
<b>William Taysom</b>
<span style="margin:2em; color:#606060">2022-12-09 01:18</span><br/>
Correctness is certainly a problem people are working on.  This came across my radar, "We also find that [our technique] cuts prompt sensitivity in half and continues to maintain high accuracy even when models are prompted to generate incorrect answers. Our results provide an initial step toward discovering what language models know, distinct from what they say, even when we don't have access to explicit ground truth labels."<br/><br/>Another technique that comes to mind is having the LLM carry on a conversation with an oracle.  For instance, if it's trying to write code, it will try running it before coming back to the human user.
    </td>
  </tr>
  </table>
<hr>
<a href="https://akkartik.name/foc-archive.zip">download this site</a> (~25MB)<br/>
<a href="https://github.com/akkartik/foc-archive">Git repo</a>
</html>
